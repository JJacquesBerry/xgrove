{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import platform\n",
    "# print(platform.architecture())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jpype\n",
    "# jpype.startJVM()  # Startet die JVM\n",
    "# print(\"JVM erfolgreich gestartet!\")\n",
    "# jpype.shutdownJVM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jpmml_evaluator import make_evaluator\n",
    "\n",
    "# # Teste, ob die JVM erfolgreich gestartet werden kann\n",
    "# try:\n",
    "#     evaluator = make_evaluator('../models/analyzed_model.pmml')  # Verwende einen einfachen PMML-Pfad\n",
    "#     evaluator.verify()\n",
    "#     print(\"JVM erfolgreich gestartet und PMML-Modell erfolgreich geladen.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Fehler: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"START\")\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from pypmml import Model\n",
    "\n",
    "# # Pfad zur PMML-Datei und zur CSV-Datei\n",
    "# pmml_file_path = '/mnt/data/analyzed_model.pmml'\n",
    "# csv_file_path = 'models/generated_data.csv'  # Passe den Pfad zur CSV-Datei bei Bedarf an\n",
    "\n",
    "# # Funktion zum Laden des Modells mit verbesserter Fehlerbehandlung\n",
    "# def load_model(file_path):\n",
    "#     try:\n",
    "#         # Modell mit pypmml laden\n",
    "#         loaded_model = Model.load(file_path)\n",
    "#         if loaded_model is not None:\n",
    "#             print(\"Modell erfolgreich geladen.\")\n",
    "#             return loaded_model\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden des PMML-Modells: {e}\")\n",
    "#     return None\n",
    "\n",
    "# # Modell laden\n",
    "# loaded_model = load_model(pmml_file_path)\n",
    "\n",
    "# if loaded_model is not None:\n",
    "#     # Lade die generierten Daten\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "    \n",
    "#     # Vorverarbeitung: Sicherstellen, dass kategorische Variablen als solche erkannt werden\n",
    "#     data['Geschlecht'] = data['Geschlecht'].astype('category')\n",
    "#     data['Kategorie'] = data['Kategorie'].astype('category')\n",
    "\n",
    "#     # Vorhersagen durchführen\n",
    "#     predictions = loaded_model.predict(data)\n",
    "#     print(predictions)  # Ergebnisse anzeigen\n",
    "    \n",
    "# else:\n",
    "#     print(\"Das Modell konnte nicht geladen werden.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.tree import DecisionTreeRegressor  # Verwende DecisionTreeRegressor\n",
    "# from sklearn2pmml.pipeline import PMMLPipeline\n",
    "# from sklearn2pmml import sklearn2pmml\n",
    "# from jpmml_evaluator import make_evaluator\n",
    "\n",
    "# # PMML-Dateipfad und CSV-Dateipfad\n",
    "# pmml_file_path = '../models/analyzed_model.pmml'\n",
    "# csv_file_path = '../models/generated_data.csv'\n",
    "\n",
    "# # Schritt 1: Modell erstellen, trainieren und als PMML speichern\n",
    "# def train_and_save_model():\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "#     X = data.drop(columns=['Zielwert'])  # Ersetze 'Zielwert' mit dem tatsächlichen Zielnamen\n",
    "#     y = data['Zielwert']  # Ersetze 'Zielwert' mit dem tatsächlichen Zielnamen\n",
    "\n",
    "#     # Umwandeln der kategorischen Variablen in Dummy-Variablen\n",
    "#     X = pd.get_dummies(X)\n",
    "\n",
    "#     # Pipeline erstellen und trainieren\n",
    "#     pipeline = PMMLPipeline([\n",
    "#         (\"regressor\", DecisionTreeRegressor())  # Verwende DecisionTreeRegressor\n",
    "#     ])\n",
    "#     pipeline.fit(X, y)\n",
    "\n",
    "#     # Modell in PMML-Datei speichern\n",
    "#     sklearn2pmml(pipeline, pmml_file_path, with_repr=True)\n",
    "#     print(f\"Modell erfolgreich gespeichert als {pmml_file_path}.\")\n",
    "\n",
    "# # Schritt 2: Modell laden\n",
    "# def load_model(file_path):\n",
    "#     try:\n",
    "#         evaluator = make_evaluator(file_path)\n",
    "#         evaluator.verify()  # Überprüfen des Modells\n",
    "#         print(\"Modell erfolgreich geladen mit jpmml-evaluator.\")\n",
    "#         return evaluator\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden des PMML-Modells mit jpmml-evaluator: {e}\")\n",
    "#     return None\n",
    "\n",
    "# # Schritt 3: Modell verwenden, um Vorhersagen zu machen\n",
    "# def make_predictions(evaluator):\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "#     # Umwandeln der kategorischen Variablen in Dummy-Variablen\n",
    "#     data = pd.get_dummies(data)\n",
    "\n",
    "#     # Vorhersagen durchführen\n",
    "#     predictions = evaluator.evaluate(data.to_dict(orient='records'))  # Daten ins Dictionary umwandeln\n",
    "\n",
    "#     # Die Ergebnisse hier direkt verwenden\n",
    "#     print(\"Vorhersagen:\", predictions)  # Vorhersagen ausgeben\n",
    "\n",
    "# # Hauptlogik\n",
    "# if __name__ == \"__main__\":\n",
    "#     train_and_save_model()  # Trainiere und speichere das Modell\n",
    "#     loaded_model = load_model(pmml_file_path)  # Lade das Modell\n",
    "\n",
    "#     if loaded_model is not None:\n",
    "#         make_predictions(loaded_model)  # Mache Vorhersagen\n",
    "#     else:\n",
    "#         print(\"Das Modell konnte nicht geladen werden.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from jpmml_evaluator import make_evaluator\n",
    "# from xgrove import grove  # Importiere die Grove-Klasse aus dem xgrove Paket\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Setze den Pfad für Graphviz\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "\n",
    "# def debug_model_loading(pmml_file_path):\n",
    "#     \"\"\"Versucht, das PMML-Modell zu laden und zu validieren.\"\"\"\n",
    "#     try:\n",
    "#         evaluator = make_evaluator(pmml_file_path)\n",
    "#         evaluator.verify()\n",
    "#         print(\"PMML-Modell erfolgreich geladen und verifiziert.\")\n",
    "#         return evaluator\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden des PMML-Modells: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def debug_data_loading(csv_file_path):\n",
    "#     \"\"\"Lädt die CSV-Daten und gibt eine Warnung, falls NaN-Werte vorhanden sind.\"\"\"\n",
    "#     try:\n",
    "#         data = pd.read_csv(csv_file_path)\n",
    "#         print(f\"Daten erfolgreich geladen: {data.head()}\")\n",
    "        \n",
    "#         # Überprüfen auf NaN-Werte und leere Strings\n",
    "#         print(f\"NaN-Werte in den Daten: {data.isna().sum()}\")\n",
    "#         print(f\"Leere Strings in den Daten: {(data == '').sum()}\")\n",
    "        \n",
    "#         # Entferne NaN-Werte\n",
    "#         if data.isna().sum().sum() > 0:\n",
    "#             print(\"Warnung: Es gibt NaN-Werte in den Eingabedaten. Diese werden entfernt.\")\n",
    "#             data = data.dropna()\n",
    "        \n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden der CSV-Datei: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def preprocess_data(data):\n",
    "#     \"\"\"Bereitet die Eingabedaten vor, indem sie skaliert werden, wenn nötig.\"\"\"\n",
    "#     # Überprüfen auf NaN-Werte nach Entfernen\n",
    "#     print(f\"Datenform nach NaN-Entfernung: {data.shape}\")\n",
    "\n",
    "#     # Skalierung der Daten, falls notwendig\n",
    "#     scaler = StandardScaler()\n",
    "#     data_scaled = data.copy()\n",
    "#     data_scaled['x'] = scaler.fit_transform(data[['x']])\n",
    "\n",
    "#     return data_scaled\n",
    "\n",
    "# def load_and_evaluate_model(pmml_file_path, csv_file_path):\n",
    "#     \"\"\"Lädt das PMML-Modell und erstellt ein Surrogat-Modell mit xgrove.\"\"\"\n",
    "    \n",
    "#     # 1. Lade die Trainingsdaten\n",
    "#     data = debug_data_loading(csv_file_path)\n",
    "#     if data is None:\n",
    "#         return\n",
    "\n",
    "#     # 2. Preprocessiere die Daten\n",
    "#     data = preprocess_data(data)\n",
    "\n",
    "#     # 3. Lade das PMML-Modell\n",
    "#     evaluator = debug_model_loading(pmml_file_path)\n",
    "#     if evaluator is None:\n",
    "#         return\n",
    "\n",
    "#     # 4. Generiere Surrogat-Zielwerte für die Daten\n",
    "#     surrogate_targets = []\n",
    "#     for i, row in data.iterrows():\n",
    "#         input_data = row.to_dict()  # Erstelle ein Dictionary für eine Zeile\n",
    "#         prediction = evaluator.evaluate(input_data)  # Einzeldatensatz bewerten\n",
    "#         surrogate_targets.append(prediction.get('Predicted_y', None))  # Nutze den Rückgabeschlüssel des Modells\n",
    "#         if i % 10 == 0:  # Debugging: Zeige alle 10 Zeilen\n",
    "#             print(f\"Verarbeite Zeile {i+1}/{len(data)}\")\n",
    "\n",
    "#     # 5. Überprüfe auf NaN-Werte in den Surrogat-Zielwerten\n",
    "#     print(\"Überprüfe auf NaN-Werte in den Surrogat-Zielwerten...\")\n",
    "#     surrogate_targets = [val for val in surrogate_targets if val is not None]  # Entferne NaN-Werte\n",
    "#     print(f\"Anzahl der gültigen Surrogat-Zielwerte: {len(surrogate_targets)}\")\n",
    "\n",
    "#     # Wenn nach der Bereinigung keine Surrogat-Zielwerte übrig sind, einen Fehler werfen\n",
    "#     if not surrogate_targets:\n",
    "#         raise ValueError(\"Fehler beim Erstellen der Surrogat-Zielwerte: Keine gültigen Zielwerte vorhanden.\")\n",
    "    \n",
    "#     # Surrogat-Targets in den DataFrame aufnehmen\n",
    "#     data['surrogatetarget'] = surrogate_targets\n",
    "#     print(f\"Surrogat-Zielwerte wurden erfolgreich zum Datensatz hinzugefügt. Datenform: {data.shape}\")\n",
    "\n",
    "#     # 6. Instanziiere die Grove-Klasse mit Surrogat-Targets und dem Modell\n",
    "#     grove_model = grove(model=evaluator, data=data, trained=True)\n",
    "    \n",
    "#     # Berechnung des Surrogat-Modells durchführen\n",
    "#     grove_model.calculateGrove()\n",
    "\n",
    "#     print(\"Berechnungen abgeschlossen.\")\n",
    "#     print(grove_model.get_result())\n",
    "\n",
    "#     # 7. Zusätzliche Modellattribute anzeigen (falls vorhanden)\n",
    "#     model_classes = evaluator.getModelClasses()  # Modellklassen, falls definiert\n",
    "#     print(f\"Model Klassen: {model_classes}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Definiere die Datei- und CSV-Pfade\n",
    "#     pmml_file_path = '../models/linear_model.pmml'\n",
    "#     csv_file_path = '../models/generated_data.csv'\n",
    "\n",
    "#     # Führe das Modell aus\n",
    "#     load_and_evaluate_model(pmml_file_path, csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pypmml import Model\n",
    "\n",
    "# # Lade das PMML-Modell\n",
    "# loaded_model = Model.load(\"random_forest_model.pmml\")\n",
    "\n",
    "# # Beispiel für eine Vorhersage\n",
    "# # Erstelle Beispiel-Daten als DataFrame\n",
    "# import pandas as pd\n",
    "# sample_data = pd.DataFrame({\n",
    "#     \"Sepal.Width\": [3.5],\n",
    "#     \"Petal.Length\": [1.4],\n",
    "#     \"Petal.Width\": [0.2],\n",
    "#     \"Species\": [\"setosa\"]\n",
    "# })\n",
    "\n",
    "# # Vorhersage\n",
    "# predictions = loaded_model.predict(sample_data)\n",
    "# print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# data = pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6]})\n",
    "# print(data.isna().sum())  # Zeigt dir die Anzahl der fehlenden Werte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lxml import etree\n",
    "\n",
    "# # Funktion zur Vorhersage basierend auf der Baumstruktur aus der XML-Datei\n",
    "# def predict_random_forest_from_xml(x_input, xml_tree):\n",
    "#     \"\"\"Trifft Vorhersage basierend auf einem Random Forest-Modell aus einer XML-Datei\"\"\"\n",
    "#     # Extrahiere alle Bäume (falls vorhanden)\n",
    "#     models = xml_tree.findall(\".//TreeModel\", namespaces=namespaces)\n",
    "\n",
    "#     # Liste zur Speicherung der Vorhersagen für jeden Baum\n",
    "#     predictions = []\n",
    "    \n",
    "#     for model in models:\n",
    "#         try:\n",
    "#             # Durchlaufe die Baumstruktur des aktuellen Baums\n",
    "#             prediction = traverse_tree_for_prediction(model, x_input)\n",
    "#             predictions.append(prediction)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Fehler beim Durchlaufen des Baums: {e}\")\n",
    "\n",
    "#     # Debug-Ausgabe der Vorhersagen\n",
    "#     print(f\"Vorhersagen von allen Bäumen: {predictions}\")\n",
    "    \n",
    "#     # Durchschnitt der Vorhersagen (für Regression) oder Mehrheitsvotum (für Klassifikation)\n",
    "#     if len(predictions) > 0:\n",
    "#         if len(set(predictions)) == 1:\n",
    "#             return predictions[0]  # Wenn alle Bäume dasselbe vorhersagen, gebe das Ergebnis zurück\n",
    "#         else:\n",
    "#             return max(set(predictions), key=predictions.count)  # Mehrheitsvotum für Klassifikation\n",
    "#     else:\n",
    "#         raise ValueError(\"Keine Vorhersagen von den Bäumen erhalten.\")\n",
    "\n",
    "# def traverse_tree_for_prediction(tree_model, x_input):\n",
    "#     \"\"\"Durchlaufe einen einzelnen Entscheidungsbaum und triff Vorhersage\"\"\"\n",
    "#     # Suche nach den Knoten des Entscheidungsbaums\n",
    "#     nodes = tree_model.findall(\".//Node\", namespaces=namespaces)\n",
    "    \n",
    "#     # Wenn keine Knoten vorhanden sind, dann gibt es ein Problem mit der Baumstruktur\n",
    "#     if not nodes:\n",
    "#         raise ValueError(\"Der Entscheidungsbaum enthält keine Knoten.\")\n",
    "    \n",
    "#     # Der erste Knoten ist immer die Wurzel\n",
    "#     current_node = nodes[0]\n",
    "    \n",
    "#     # Durchlaufe die Baumstruktur und gebe alle Knoten aus, um den Baum zu analysieren\n",
    "#     print(\"Baumstruktur:\")\n",
    "#     for node in nodes:\n",
    "#         print(node.attrib)\n",
    "    \n",
    "#     while True:\n",
    "#         # Hole die Bedingungen des aktuellen Knotens (if-Bedingung)\n",
    "#         if_condition = current_node.find(\".//True//SimplePredicate\", namespaces=namespaces)\n",
    "        \n",
    "#         if if_condition is not None:\n",
    "#             # Extrahiere die Bedingung und den Wert\n",
    "#             field = if_condition.attrib['field']\n",
    "#             value = float(if_condition.attrib['value'])\n",
    "            \n",
    "#             # Bestimme den Zweig des Baumes basierend auf der Bedingung\n",
    "#             if x_input <= value:\n",
    "#                 next_node_id = current_node.attrib['trueBranch']\n",
    "#             else:\n",
    "#                 next_node_id = current_node.attrib['falseBranch']\n",
    "#         else:\n",
    "#             # Wenn kein 'True'-Element gefunden wird, ist dies ein Blattknoten (Vorhersage)\n",
    "#             print(\"Blattknoten gefunden:\", current_node.attrib)  # Debug: Ausgabe der Attribute des Blattknotens\n",
    "            \n",
    "#             # Untersuche die Attribute des Blattknotens, um den Vorhersagewert zu finden\n",
    "#             if 'score' in current_node.attrib:\n",
    "#                 return int(current_node.attrib['score'])  # Verwende 'score' als Vorhersage (0 oder 1)\n",
    "#             else:\n",
    "#                 # Dies ist der Fall, wenn der Blattknoten keine Vorhersage enthält\n",
    "#                 raise ValueError(f\"Unklarer Blattknoten gefunden ohne Vorhersage-Attribut. Knoten: {current_node.attrib}\")\n",
    "        \n",
    "#         # Finde den nächsten Knoten\n",
    "#         next_node = next((node for node in nodes if node.attrib['id'] == next_node_id), None)\n",
    "        \n",
    "#         if next_node is None:\n",
    "#             raise ValueError(f\"Fehler: Der nächste Knoten (ID: {next_node_id}) konnte nicht gefunden werden.\")\n",
    "        \n",
    "#         current_node = next_node\n",
    "\n",
    "# # Lade die XML-Datei (Aktueller Pfad zu deiner Datei)\n",
    "# xml_file_path = \"../models/random_forest_model_pmml.xml\"  # Der tatsächliche Pfad zur XML-Datei\n",
    "# tree = etree.parse(xml_file_path)\n",
    "# root = tree.getroot()\n",
    "\n",
    "# # Definiere den Namensraum für XPath\n",
    "# namespaces = {\n",
    "#     'pmml': 'http://www.dmg.org/PMML-4_4'\n",
    "# }\n",
    "\n",
    "# # Extrahiere den Modelltyp\n",
    "# model_type = root.find(\".//pmml:MiningModel\", namespaces=namespaces)\n",
    "# if model_type is not None:\n",
    "#     print(f\"Modelltyp: {model_type.attrib.get('functionName')}\")\n",
    "\n",
    "# # Extrahiere die Eingabefelder aus dem XML\n",
    "# input_fields = root.findall(\".//pmml:DataField\", namespaces=namespaces)\n",
    "# print(\"Eingabefelder:\", [field.attrib.get('name') for field in input_fields])\n",
    "\n",
    "# # Extrahiere die Zielvariable aus dem MiningSchema\n",
    "# target_field = root.xpath(\".//pmml:MiningSchema/pmml:MiningField[@usageType='predicted']\", namespaces=namespaces)\n",
    "# if target_field:\n",
    "#     print(f\"Zielvariable: {target_field[0].attrib.get('name')}\")\n",
    "# else:\n",
    "#     print(\"Zielvariable nicht gefunden.\")\n",
    "\n",
    "# # Beispiel Vorhersage für eine Eingabe (z.B. x = 30)\n",
    "# x_input = 30\n",
    "# try:\n",
    "#     prediction = predict_random_forest_from_xml(x_input, root)\n",
    "#     print(f\"Vorhersage für x = {x_input}: Klasse {prediction}\")\n",
    "# except ValueError as e:\n",
    "#     print(f\"Fehler bei der Vorhersage: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lxml import etree\n",
    "\n",
    "# # Funktion zur Vorhersage basierend auf der Baumstruktur aus der PMML-Datei\n",
    "# def predict_random_forest_from_pmml(x_input, pmml_tree):\n",
    "#     \"\"\"Trifft Vorhersage basierend auf einem Random Forest-Modell aus PMML\"\"\"\n",
    "#     # Extrahiere alle Bäume (falls vorhanden)\n",
    "#     models = pmml_tree.findall(\".//pmml:TreeModel\", namespaces=namespaces)\n",
    "\n",
    "#     # Liste zur Speicherung der Vorhersagen für jeden Baum\n",
    "#     predictions = []\n",
    "    \n",
    "#     for model in models:\n",
    "#         # Durchlaufe die Baumstruktur des aktuellen Baums\n",
    "#         prediction = traverse_tree_for_prediction(model, x_input)\n",
    "#         predictions.append(prediction)\n",
    "    \n",
    "#     # Durchschnitt der Vorhersagen (für Regression) oder Mehrheitsvotum (für Klassifikation)\n",
    "#     if len(set(predictions)) == 1:\n",
    "#         return predictions[0]  # Wenn alle Bäume dasselbe vorhersagen, gebe das Ergebnis zurück\n",
    "#     else:\n",
    "#         return max(set(predictions), key=predictions.count)  # Mehrheitsvotum für Klassifikation\n",
    "\n",
    "# def traverse_tree_for_prediction(tree_model, x_input):\n",
    "#     \"\"\"Durchlaufe einen einzelnen Entscheidungsbaum und triff Vorhersage\"\"\"\n",
    "#     # Suche nach den Knoten des Entscheidungsbaums\n",
    "#     nodes = tree_model.findall(\".//pmml:Node\", namespaces=namespaces)\n",
    "    \n",
    "#     # Der erste Knoten ist immer die Wurzel\n",
    "#     current_node = nodes[0]\n",
    "    \n",
    "#     # Durchlaufe die Baumstruktur und gebe alle Knoten aus, um den Baum zu analysieren\n",
    "#     print(\"Baumstruktur:\")\n",
    "#     for node in nodes:\n",
    "#         print(node.attrib)\n",
    "    \n",
    "#     while True:\n",
    "#         # Hole die Bedingungen des aktuellen Knotens (if-Bedingung)\n",
    "#         if_condition = current_node.find(\".//pmml:True/pmml:SimplePredicate\", namespaces=namespaces)\n",
    "        \n",
    "#         if if_condition is not None:\n",
    "#             # Extrahiere die Bedingung und den Wert\n",
    "#             field = if_condition.attrib['field']\n",
    "#             value = float(if_condition.attrib['value'])\n",
    "            \n",
    "#             # Bestimme den Zweig des Baumes basierend auf der Bedingung\n",
    "#             if x_input <= value:\n",
    "#                 next_node_id = current_node.attrib['trueBranch']\n",
    "#             else:\n",
    "#                 next_node_id = current_node.attrib['falseBranch']\n",
    "#         else:\n",
    "#             # Wenn kein 'True'-Element gefunden wird, ist dies ein Blattknoten (Vorhersage)\n",
    "#             print(\"Blattknoten gefunden:\", current_node.attrib)  # Debug: Ausgabe der Attribute des Blattknotens\n",
    "            \n",
    "#             # Untersuche die Attribute des Blattknotens, um den Vorhersagewert zu finden\n",
    "#             score = current_node.attrib.get('score', None)\n",
    "            \n",
    "#             if score is not None:\n",
    "#                 return int(score)  # Verwende 'score' als Vorhersage (0 oder 1)\n",
    "#             else:\n",
    "#                 # Falls der Blattknoten keinen 'score' hat, gehe davon aus, dass er ein innerer Knoten ist\n",
    "#                 print(f\"Blattknoten ohne 'score' gefunden (ID: {current_node.attrib['id']}). Weiter mit nächstem Knoten.\")\n",
    "#                 # Gehe zur nächsten Node, falls keine Vorhersage im aktuellen Knoten\n",
    "#                 next_node_id = current_node.attrib.get('trueBranch', None) or current_node.attrib.get('falseBranch', None)\n",
    "#                 if next_node_id:\n",
    "#                     # Suche den nächsten Knoten\n",
    "#                     current_node = next((node for node in nodes if node.attrib['id'] == next_node_id), None)\n",
    "#                     continue\n",
    "#                 else:\n",
    "#                     raise ValueError(f\"Kein gültiger 'trueBranch' oder 'falseBranch' im Blattknoten gefunden. Knoten: {current_node.attrib}\")\n",
    "\n",
    "#         # Finde den nächsten Knoten\n",
    "#         next_node = next((node for node in nodes if node.attrib['id'] == next_node_id), None)\n",
    "        \n",
    "#         if next_node is None:\n",
    "#             raise ValueError(f\"Fehler: Der nächste Knoten (ID: {next_node_id}) konnte nicht gefunden werden.\")\n",
    "        \n",
    "#         current_node = next_node\n",
    "\n",
    "# # Lade die PMML-Datei\n",
    "# pmml_file_path = \"models/random_forest_model_pmml.xml\"  # Der tatsächliche Pfad zur XML-Datei\n",
    "# tree = etree.parse(pmml_file_path)\n",
    "# root = tree.getroot()\n",
    "\n",
    "# # Definiere den Namensraum für XPath\n",
    "# namespaces = {\n",
    "#     'pmml': 'http://www.dmg.org/PMML-4_4'\n",
    "# }\n",
    "\n",
    "# # Extrahiere den Modelltyp\n",
    "# model_type = root.find(\".//pmml:MiningModel\", namespaces=namespaces)\n",
    "# if model_type is not None:\n",
    "#     print(f\"Modelltyp: {model_type.attrib.get('functionName')}\")\n",
    "\n",
    "# # Extrahiere die Eingabefelder aus dem XML\n",
    "# input_fields = root.findall(\".//pmml:DataField\", namespaces=namespaces)\n",
    "# print(\"Eingabefelder:\", [field.attrib.get('name') for field in input_fields])\n",
    "\n",
    "# # Extrahiere die Zielvariable aus dem MiningSchema\n",
    "# target_field = root.xpath(\".//pmml:MiningSchema/pmml:MiningField[@usageType='predicted']\", namespaces=namespaces)\n",
    "# if target_field:\n",
    "#     print(f\"Zielvariable: {target_field[0].attrib.get('name')}\")\n",
    "# else:\n",
    "#     print(\"Zielvariable nicht gefunden.\")\n",
    "\n",
    "# # Beispiel Vorhersage für eine Eingabe (z.B. x = 30)\n",
    "# x_input = 30\n",
    "# prediction = predict_random_forest_from_pmml(x_input, root)\n",
    "# print(f\"Vorhersage für x = {x_input}: Klasse {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from pypmml import Model  # Verwenden von pypmml\n",
    "\n",
    "# # Definiere den PMML-Dateipfad\n",
    "# pmml_path = \"../models/linear_model.pmml\"\n",
    "\n",
    "# # Lade das trainierte PMML-Modell (aus R gespeichert)\n",
    "# pmml_model = Model.load(pmml_path)  # Laden des trainierten Modells\n",
    "\n",
    "# # Neue Eingabedaten (die für die Vorhersagen verwendet werden)\n",
    "# input_data = pd.DataFrame({\n",
    "#     'Feature1': [0.5, -1.2, 0.3],\n",
    "#     'Feature2': [1.1, -0.8, 0.2]\n",
    "# })\n",
    "\n",
    "# # Vorhersagen machen\n",
    "# predictions = pmml_model.predict(input_data)\n",
    "\n",
    "# # Zeige die Vorhersagen an\n",
    "# print(f\"Vorhersagen: {predictions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame before grouping:     variable  upper_bound_left levels_left     pleft    pright\n",
      "0   Feature1         -0.719046        <NA>  0.628180 -0.110855\n",
      "1   Feature1         -1.179427        <NA>  0.216107  0.988743\n",
      "2   Feature2         -1.620043        <NA> -0.715082  0.371305\n",
      "3   Feature2         -0.336475        <NA>  1.367506  0.357473\n",
      "4   Feature1          2.178145        <NA> -0.132965  1.746387\n",
      "5   Feature2         -0.763120        <NA> -0.438737 -0.024466\n",
      "6   Feature2         -1.255713        <NA>  0.416533 -0.056800\n",
      "7   Feature2         -1.377347        <NA>  0.167610  1.163304\n",
      "8   Feature2         -1.543406        <NA>  0.487628 -0.232413\n",
      "9   Feature1          0.638642        <NA>  0.584579  2.320755\n",
      "10  Feature2         -1.016253        <NA> -0.647703 -0.013563\n",
      "11  Feature1         -0.487557        <NA> -0.204827 -0.869141\n",
      "12  Feature2          0.305817        <NA>  0.107482 -0.223374\n",
      "13  Feature1          0.666508        <NA>  0.063864 -0.181765\n",
      "14  Feature1          0.227337        <NA> -0.053146  0.456188\n",
      "15  Feature1         -0.035709        <NA>  0.053542 -0.554576\n",
      "16  Feature2          1.353868        <NA>  0.354533  2.082669\n",
      "17  Feature1          0.886630        <NA> -0.891058  0.031023\n",
      "18  Feature2          1.615723        <NA> -0.961791 -0.537395\n",
      "19  Feature2         -0.039547        <NA> -0.236292  0.431994\n",
      "20  Feature1         -0.691358        <NA> -0.229823  0.047072\n",
      "21  Feature2          2.684746        <NA> -0.306193  0.992093\n",
      "22  Feature2          0.632387        <NA> -0.204490 -1.018115\n",
      "23  Feature1         -0.657379        <NA>  0.993252  0.023710\n",
      "24  Feature2         -0.560781        <NA>  0.592620  1.393885\n",
      "25  Feature2          0.484183        <NA>  0.086991 -0.157095\n",
      "NaN counts after handling: variable            0\n",
      "upper_bound_left    0\n",
      "levels_left         0\n",
      "pleft               0\n",
      "pright              0\n",
      "dtype: int64\n",
      "df_small grouped:     variable  upper_bound_left levels_left     pleft    pright\n",
      "0   Feature1         -1.179427     default  0.216107  0.988743\n",
      "1   Feature1         -0.719046     default  0.628180 -0.110855\n",
      "2   Feature1         -0.691358     default -0.229823  0.047072\n",
      "3   Feature1         -0.657379     default  0.993252  0.023710\n",
      "4   Feature1         -0.487557     default -0.204827 -0.869141\n",
      "5   Feature1         -0.035709     default  0.053542 -0.554576\n",
      "6   Feature1          0.227337     default -0.053146  0.456188\n",
      "7   Feature1          0.638642     default  0.584579  2.320755\n",
      "8   Feature1          0.666508     default  0.063864 -0.181765\n",
      "9   Feature1          0.886630     default -0.891058  0.031023\n",
      "10  Feature1          2.178145     default -0.132965  1.746387\n",
      "11  Feature2         -1.620043     default -0.715082  0.371305\n",
      "12  Feature2         -1.543406     default  0.487628 -0.232413\n",
      "13  Feature2         -1.377347     default  0.167610  1.163304\n",
      "14  Feature2         -1.255713     default  0.416533 -0.056800\n",
      "15  Feature2         -1.016253     default -0.647703 -0.013563\n",
      "16  Feature2         -0.763120     default -0.438737 -0.024466\n",
      "17  Feature2         -0.560781     default  0.592620  1.393885\n",
      "18  Feature2         -0.336475     default  1.367506  0.357473\n",
      "19  Feature2         -0.039547     default -0.236292  0.431994\n",
      "20  Feature2          0.305817     default  0.107482 -0.223374\n",
      "21  Feature2          0.484183     default  0.086991 -0.157095\n",
      "22  Feature2          0.632387     default -0.204490 -1.018115\n",
      "23  Feature2          1.353868     default  0.354533  2.082669\n",
      "24  Feature2          1.615723     default -0.961791 -0.537395\n",
      "25  Feature2          2.684746     default -0.306193  0.992093\n",
      "df_small after concatenation:      variable  upper_bound_left levels_left                     pleft  \\\n",
      "0   Intercept               NaN         NaN  [2.4424906541753444e-17]   \n",
      "1    Feature1         -1.179427     default                  0.216107   \n",
      "2    Feature1         -0.719046     default                   0.62818   \n",
      "3    Feature1         -0.691358     default                 -0.229823   \n",
      "4    Feature1         -0.657379     default                  0.993252   \n",
      "5    Feature1         -0.487557     default                 -0.204827   \n",
      "6    Feature1         -0.035709     default                  0.053542   \n",
      "7    Feature1          0.227337     default                 -0.053146   \n",
      "8    Feature1          0.638642     default                  0.584579   \n",
      "9    Feature1          0.666508     default                  0.063864   \n",
      "10   Feature1          0.886630     default                 -0.891058   \n",
      "11   Feature1          2.178145     default                 -0.132965   \n",
      "12   Feature2         -1.620043     default                 -0.715082   \n",
      "13   Feature2         -1.543406     default                  0.487628   \n",
      "14   Feature2         -1.377347     default                   0.16761   \n",
      "15   Feature2         -1.255713     default                  0.416533   \n",
      "16   Feature2         -1.016253     default                 -0.647703   \n",
      "17   Feature2         -0.763120     default                 -0.438737   \n",
      "18   Feature2         -0.560781     default                   0.59262   \n",
      "19   Feature2         -0.336475     default                  1.367506   \n",
      "20   Feature2         -0.039547     default                 -0.236292   \n",
      "21   Feature2          0.305817     default                  0.107482   \n",
      "22   Feature2          0.484183     default                  0.086991   \n",
      "23   Feature2          0.632387     default                  -0.20449   \n",
      "24   Feature2          1.353868     default                  0.354533   \n",
      "25   Feature2          1.615723     default                 -0.961791   \n",
      "26   Feature2          2.684746     default                 -0.306193   \n",
      "\n",
      "                      pright  \n",
      "0   [2.4424906541753444e-17]  \n",
      "1                   0.988743  \n",
      "2                  -0.110855  \n",
      "3                   0.047072  \n",
      "4                    0.02371  \n",
      "5                  -0.869141  \n",
      "6                  -0.554576  \n",
      "7                   0.456188  \n",
      "8                   2.320755  \n",
      "9                  -0.181765  \n",
      "10                  0.031023  \n",
      "11                  1.746387  \n",
      "12                  0.371305  \n",
      "13                 -0.232413  \n",
      "14                  1.163304  \n",
      "15                   -0.0568  \n",
      "16                 -0.013563  \n",
      "17                 -0.024466  \n",
      "18                  1.393885  \n",
      "19                  0.357473  \n",
      "20                  0.431994  \n",
      "21                 -0.223374  \n",
      "22                 -0.157095  \n",
      "23                 -1.018115  \n",
      "24                  2.082669  \n",
      "25                 -0.537395  \n",
      "26                  0.992093  \n",
      "DataFrame before grouping:     variable  upper_bound_left levels_left     pleft    pright\n",
      "0   Feature1         -0.719046        <NA>  0.628180 -0.110855\n",
      "1   Feature1         -1.179427        <NA>  0.216107  0.988743\n",
      "2   Feature2         -1.620043        <NA> -0.715082  0.371305\n",
      "3   Feature2         -0.336475        <NA>  1.367506  0.357473\n",
      "4   Feature1          2.178145        <NA> -0.132965  1.746387\n",
      "..       ...               ...         ...       ...       ...\n",
      "73  Feature1         -2.137893        <NA>  0.473905 -0.371777\n",
      "74  Feature1         -1.826655        <NA> -1.211689 -0.231792\n",
      "75  Feature1         -1.069807        <NA>  0.612897  0.010030\n",
      "76  Feature1         -1.097450        <NA>  0.417538  0.808255\n",
      "77  Feature2         -1.609709        <NA>  0.424450  0.000612\n",
      "\n",
      "[78 rows x 5 columns]\n",
      "NaN counts after handling: variable            0\n",
      "upper_bound_left    0\n",
      "levels_left         0\n",
      "pleft               0\n",
      "pright              0\n",
      "dtype: int64\n",
      "df_small grouped:     variable  upper_bound_left levels_left     pleft    pright\n",
      "0   Feature1         -2.137893     default  0.473905 -0.371777\n",
      "1   Feature1         -1.826655     default -1.211689 -0.231792\n",
      "2   Feature1         -1.384735     default  0.963351  0.007492\n",
      "3   Feature1         -1.265229     default  0.730216 -0.130625\n",
      "4   Feature1         -1.179427     default  0.432214  1.977487\n",
      "5   Feature1         -1.130623     default -0.266067  0.023136\n",
      "6   Feature1         -1.097450     default  0.417538  0.808255\n",
      "7   Feature1         -1.069807     default  0.612897  0.010030\n",
      "8   Feature1         -0.719046     default  1.256360 -0.221711\n",
      "9   Feature1         -0.691358     default -0.459647  0.094145\n",
      "10  Feature1         -0.657379     default  1.986505  0.047420\n",
      "11  Feature1         -0.612649     default -0.078411  0.227407\n",
      "12  Feature1         -0.487557     default -0.409655 -1.738282\n",
      "13  Feature1         -0.284987     default -1.008445 -1.086169\n",
      "14  Feature1         -0.275591     default -0.034976  0.257739\n",
      "15  Feature1         -0.212946     default  0.065189 -0.080149\n",
      "16  Feature1         -0.035709     default  0.107084 -1.109152\n",
      "17  Feature1          0.167338     default  0.037736  1.015634\n",
      "18  Feature1          0.198623     default  0.060478 -0.161039\n",
      "19  Feature1          0.227337     default -1.312484  0.782076\n",
      "20  Feature1          0.638642     default  1.169158  4.641509\n",
      "21  Feature1          0.666508     default  0.127727 -0.363531\n",
      "22  Feature1          0.886630     default -1.782117  0.062045\n",
      "23  Feature1          2.178145     default -0.265931  3.492773\n",
      "24  Feature2         -1.620043     default -1.430165  0.742611\n",
      "25  Feature2         -1.609709     default  0.424450  0.000612\n",
      "26  Feature2         -1.543406     default  0.975257 -0.464826\n",
      "27  Feature2         -1.377347     default  0.335220  2.326609\n",
      "28  Feature2         -1.255713     default  0.833067 -0.113600\n",
      "29  Feature2         -1.173634     default  0.094629  0.518714\n",
      "30  Feature2         -1.016253     default -1.295406 -0.027126\n",
      "31  Feature2         -0.921419     default  0.137992 -0.038921\n",
      "32  Feature2         -0.763120     default -0.877474 -0.048931\n",
      "33  Feature2         -0.560781     default  1.185240  2.787769\n",
      "34  Feature2         -0.336475     default  2.735011  0.714945\n",
      "35  Feature2         -0.039547     default -0.472583  0.863988\n",
      "36  Feature2          0.081349     default -0.062606  0.748049\n",
      "37  Feature2          0.100130     default -0.036871 -1.047307\n",
      "38  Feature2          0.166046     default -0.067961  0.126213\n",
      "39  Feature2          0.246135     default  0.206320  0.941402\n",
      "40  Feature2          0.305817     default  0.862332 -0.407394\n",
      "41  Feature2          0.484183     default  0.173983 -0.314190\n",
      "42  Feature2          0.632387     default -0.408980 -2.036230\n",
      "43  Feature2          0.662243     default -0.020937 -1.174141\n",
      "44  Feature2          0.694851     default -0.035001  0.159447\n",
      "45  Feature2          1.197261     default  0.119138  0.422290\n",
      "46  Feature2          1.272823     default  0.258098 -0.190580\n",
      "47  Feature2          1.353868     default  0.709066  4.165337\n",
      "48  Feature2          1.615723     default -1.923582 -1.074789\n",
      "49  Feature2          2.684746     default -0.612387  1.984186\n",
      "df_small after concatenation:      variable  upper_bound_left levels_left                     pleft  \\\n",
      "0   Intercept               NaN         NaN  [2.4424906541753444e-17]   \n",
      "1    Feature1         -2.137893     default                  0.473905   \n",
      "2    Feature1         -1.826655     default                 -1.211689   \n",
      "3    Feature1         -1.384735     default                  0.963351   \n",
      "4    Feature1         -1.265229     default                  0.730216   \n",
      "5    Feature1         -1.179427     default                  0.432214   \n",
      "6    Feature1         -1.130623     default                 -0.266067   \n",
      "7    Feature1         -1.097450     default                  0.417538   \n",
      "8    Feature1         -1.069807     default                  0.612897   \n",
      "9    Feature1         -0.719046     default                   1.25636   \n",
      "10   Feature1         -0.691358     default                 -0.459647   \n",
      "11   Feature1         -0.657379     default                  1.986505   \n",
      "12   Feature1         -0.612649     default                 -0.078411   \n",
      "13   Feature1         -0.487557     default                 -0.409655   \n",
      "14   Feature1         -0.284987     default                 -1.008445   \n",
      "15   Feature1         -0.275591     default                 -0.034976   \n",
      "16   Feature1         -0.212946     default                  0.065189   \n",
      "17   Feature1         -0.035709     default                  0.107084   \n",
      "18   Feature1          0.167338     default                  0.037736   \n",
      "19   Feature1          0.198623     default                  0.060478   \n",
      "20   Feature1          0.227337     default                 -1.312484   \n",
      "21   Feature1          0.638642     default                  1.169158   \n",
      "22   Feature1          0.666508     default                  0.127727   \n",
      "23   Feature1          0.886630     default                 -1.782117   \n",
      "24   Feature1          2.178145     default                 -0.265931   \n",
      "25   Feature2         -1.620043     default                 -1.430165   \n",
      "26   Feature2         -1.609709     default                   0.42445   \n",
      "27   Feature2         -1.543406     default                  0.975257   \n",
      "28   Feature2         -1.377347     default                   0.33522   \n",
      "29   Feature2         -1.255713     default                  0.833067   \n",
      "30   Feature2         -1.173634     default                  0.094629   \n",
      "31   Feature2         -1.016253     default                 -1.295406   \n",
      "32   Feature2         -0.921419     default                  0.137992   \n",
      "33   Feature2         -0.763120     default                 -0.877474   \n",
      "34   Feature2         -0.560781     default                   1.18524   \n",
      "35   Feature2         -0.336475     default                  2.735011   \n",
      "36   Feature2         -0.039547     default                 -0.472583   \n",
      "37   Feature2          0.081349     default                 -0.062606   \n",
      "38   Feature2          0.100130     default                 -0.036871   \n",
      "39   Feature2          0.166046     default                 -0.067961   \n",
      "40   Feature2          0.246135     default                   0.20632   \n",
      "41   Feature2          0.305817     default                  0.862332   \n",
      "42   Feature2          0.484183     default                  0.173983   \n",
      "43   Feature2          0.632387     default                  -0.40898   \n",
      "44   Feature2          0.662243     default                 -0.020937   \n",
      "45   Feature2          0.694851     default                 -0.035001   \n",
      "46   Feature2          1.197261     default                  0.119138   \n",
      "47   Feature2          1.272823     default                  0.258098   \n",
      "48   Feature2          1.353868     default                  0.709066   \n",
      "49   Feature2          1.615723     default                 -1.923582   \n",
      "50   Feature2          2.684746     default                 -0.612387   \n",
      "\n",
      "                      pright  \n",
      "0   [2.4424906541753444e-17]  \n",
      "1                  -0.371777  \n",
      "2                  -0.231792  \n",
      "3                   0.007492  \n",
      "4                  -0.130625  \n",
      "5                   1.977487  \n",
      "6                   0.023136  \n",
      "7                   0.808255  \n",
      "8                    0.01003  \n",
      "9                  -0.221711  \n",
      "10                  0.094145  \n",
      "11                   0.04742  \n",
      "12                  0.227407  \n",
      "13                 -1.738282  \n",
      "14                 -1.086169  \n",
      "15                  0.257739  \n",
      "16                 -0.080149  \n",
      "17                 -1.109152  \n",
      "18                  1.015634  \n",
      "19                 -0.161039  \n",
      "20                  0.782076  \n",
      "21                  4.641509  \n",
      "22                 -0.363531  \n",
      "23                  0.062045  \n",
      "24                  3.492773  \n",
      "25                  0.742611  \n",
      "26                  0.000612  \n",
      "27                 -0.464826  \n",
      "28                  2.326609  \n",
      "29                   -0.1136  \n",
      "30                  0.518714  \n",
      "31                 -0.027126  \n",
      "32                 -0.038921  \n",
      "33                 -0.048931  \n",
      "34                  2.787769  \n",
      "35                  0.714945  \n",
      "36                  0.863988  \n",
      "37                  0.748049  \n",
      "38                 -1.047307  \n",
      "39                  0.126213  \n",
      "40                  0.941402  \n",
      "41                 -0.407394  \n",
      "42                  -0.31419  \n",
      "43                  -2.03623  \n",
      "44                 -1.174141  \n",
      "45                  0.159447  \n",
      "46                   0.42229  \n",
      "47                  -0.19058  \n",
      "48                  4.165337  \n",
      "49                 -1.074789  \n",
      "50                  1.984186  \n",
      "DataFrame before grouping:      variable  upper_bound_left levels_left     pleft    pright\n",
      "0    Feature1         -0.719046        <NA>  0.628180 -0.110855\n",
      "1    Feature1         -1.179427        <NA>  0.216107  0.988743\n",
      "2    Feature2         -1.620043        <NA> -0.715082  0.371305\n",
      "3    Feature2         -0.336475        <NA>  1.367506  0.357473\n",
      "4    Feature1          2.178145        <NA> -0.132965  1.746387\n",
      "..        ...               ...         ...       ...       ...\n",
      "173  Feature1         -0.260237        <NA> -0.012064 -0.314112\n",
      "174  Feature1         -0.391678        <NA>  0.003652 -0.079416\n",
      "175  Feature1         -0.212946        <NA>  0.209346 -0.001326\n",
      "176  Feature1         -0.219231        <NA>  0.117010  0.486354\n",
      "177  Feature1         -0.173404        <NA> -0.358478  0.004940\n",
      "\n",
      "[178 rows x 5 columns]\n",
      "NaN counts after handling: variable            0\n",
      "upper_bound_left    0\n",
      "levels_left         0\n",
      "pleft               0\n",
      "pright              0\n",
      "dtype: int64\n",
      "df_small grouped:     variable  upper_bound_left levels_left     pleft    pright\n",
      "0   Feature1         -2.137893     default  0.947809 -0.743554\n",
      "1   Feature1         -1.826655     default -2.423379 -0.463584\n",
      "2   Feature1         -1.384735     default  1.926703  0.014984\n",
      "3   Feature1         -1.265229     default  1.460432 -0.261251\n",
      "4   Feature1         -1.179427     default  0.648322  2.966230\n",
      "..       ...               ...         ...       ...       ...\n",
      "86  Feature2          1.197261     default  0.238276  0.844580\n",
      "87  Feature2          1.272823     default  0.516195 -0.381161\n",
      "88  Feature2          1.353868     default  1.063598  6.248006\n",
      "89  Feature2          1.615723     default -2.885373 -1.612184\n",
      "90  Feature2          2.684746     default -0.919104  3.156927\n",
      "\n",
      "[91 rows x 5 columns]\n",
      "df_small after concatenation:      variable  upper_bound_left levels_left                     pleft  \\\n",
      "0   Intercept               NaN         NaN  [2.4424906541753444e-17]   \n",
      "1    Feature1         -2.137893     default                  0.947809   \n",
      "2    Feature1         -1.826655     default                 -2.423379   \n",
      "3    Feature1         -1.384735     default                  1.926703   \n",
      "4    Feature1         -1.265229     default                  1.460432   \n",
      "..        ...               ...         ...                       ...   \n",
      "87   Feature2          1.197261     default                  0.238276   \n",
      "88   Feature2          1.272823     default                  0.516195   \n",
      "89   Feature2          1.353868     default                  1.063598   \n",
      "90   Feature2          1.615723     default                 -2.885373   \n",
      "91   Feature2          2.684746     default                 -0.919104   \n",
      "\n",
      "                      pright  \n",
      "0   [2.4424906541753444e-17]  \n",
      "1                  -0.743554  \n",
      "2                  -0.463584  \n",
      "3                   0.014984  \n",
      "4                  -0.261251  \n",
      "..                       ...  \n",
      "87                   0.84458  \n",
      "88                 -0.381161  \n",
      "89                  6.248006  \n",
      "90                 -1.612184  \n",
      "91                  3.156927  \n",
      "\n",
      "[92 rows x 5 columns]\n",
      "DataFrame before grouping:      variable  upper_bound_left levels_left     pleft    pright\n",
      "0    Feature1         -0.719046        <NA>  0.628180 -0.110855\n",
      "1    Feature1         -1.179427        <NA>  0.216107  0.988743\n",
      "2    Feature2         -1.620043        <NA> -0.715082  0.371305\n",
      "3    Feature2         -0.336475        <NA>  1.367506  0.357473\n",
      "4    Feature1          2.178145        <NA> -0.132965  1.746387\n",
      "..        ...               ...         ...       ...       ...\n",
      "364  Feature2          0.081349        <NA> -0.030297  0.004829\n",
      "365  Feature1         -1.826655        <NA>  0.040182 -0.000820\n",
      "366  Feature1         -2.137893        <NA>  0.044517  0.035847\n",
      "367  Feature1         -1.617723        <NA> -0.054014 -0.000272\n",
      "368  Feature1          0.167338        <NA> -0.004557  0.004681\n",
      "\n",
      "[369 rows x 5 columns]\n",
      "NaN counts after handling: variable            0\n",
      "upper_bound_left    0\n",
      "levels_left         0\n",
      "pleft               0\n",
      "pright              0\n",
      "dtype: int64\n",
      "df_small grouped:      variable  upper_bound_left levels_left     pleft    pright\n",
      "0    Feature1         -2.137893     default  1.466231 -1.079485\n",
      "1    Feature1         -1.826655     default -3.594886 -0.696196\n",
      "2    Feature1         -1.617723     default -0.054014 -0.000272\n",
      "3    Feature1         -1.476045     default -0.063034  0.019704\n",
      "4    Feature1         -1.384735     default  2.890054  0.022476\n",
      "..        ...               ...         ...       ...       ...\n",
      "145  Feature2          1.353868     default  1.889578  8.310668\n",
      "146  Feature2          1.615723     default -3.847164 -2.149579\n",
      "147  Feature2          1.644206     default -0.014437  0.013461\n",
      "148  Feature2          1.953158     default  0.002854 -0.068498\n",
      "149  Feature2          2.684746     default -1.225822  4.329667\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "df_small after concatenation:       variable  upper_bound_left levels_left                     pleft  \\\n",
      "0    Intercept               NaN         NaN  [2.4424906541753444e-17]   \n",
      "1     Feature1         -2.137893     default                  1.466231   \n",
      "2     Feature1         -1.826655     default                 -3.594886   \n",
      "3     Feature1         -1.617723     default                 -0.054014   \n",
      "4     Feature1         -1.476045     default                 -0.063034   \n",
      "..         ...               ...         ...                       ...   \n",
      "146   Feature2          1.353868     default                  1.889578   \n",
      "147   Feature2          1.615723     default                 -3.847164   \n",
      "148   Feature2          1.644206     default                 -0.014437   \n",
      "149   Feature2          1.953158     default                  0.002854   \n",
      "150   Feature2          2.684746     default                 -1.225822   \n",
      "\n",
      "                       pright  \n",
      "0    [2.4424906541753444e-17]  \n",
      "1                   -1.079485  \n",
      "2                   -0.696196  \n",
      "3                   -0.000272  \n",
      "4                    0.019704  \n",
      "..                        ...  \n",
      "146                  8.310668  \n",
      "147                 -2.149579  \n",
      "148                  0.013461  \n",
      "149                 -0.068498  \n",
      "150                  4.329667  \n",
      "\n",
      "[151 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jjacq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgrove\\grove.py:589: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([intercept_df, df], ignore_index=True)\n",
      "c:\\Users\\jjacq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgrove\\grove.py:590: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_small = pd.concat([intercept_df, df_small], ignore_index=True)\n",
      "c:\\Users\\jjacq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgrove\\grove.py:589: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([intercept_df, df], ignore_index=True)\n",
      "c:\\Users\\jjacq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgrove\\grove.py:590: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_small = pd.concat([intercept_df, df_small], ignore_index=True)\n",
      "c:\\Users\\jjacq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgrove\\grove.py:589: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([intercept_df, df], ignore_index=True)\n",
      "c:\\Users\\jjacq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgrove\\grove.py:590: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_small = pd.concat([intercept_df, df_small], ignore_index=True)\n",
      "c:\\Users\\jjacq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgrove\\grove.py:589: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([intercept_df, df], ignore_index=True)\n",
      "c:\\Users\\jjacq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgrove\\grove.py:590: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_small = pd.concat([intercept_df, df_small], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame before grouping:      variable  upper_bound_left levels_left         pleft    pright\n",
      "0    Feature1         -0.719046        <NA>  6.281798e-01 -0.110855\n",
      "1    Feature1         -1.179427        <NA>  2.161072e-01  0.988743\n",
      "2    Feature2         -1.620043        <NA> -7.150824e-01  0.371305\n",
      "3    Feature2         -0.336475        <NA>  1.367506e+00  0.357473\n",
      "4    Feature1          2.178145        <NA> -1.329653e-01  1.746387\n",
      "..        ...               ...         ...           ...       ...\n",
      "757  Feature2         -0.241486        <NA> -2.039185e-17 -0.000377\n",
      "758  Feature2         -0.259145        <NA> -3.943233e-05  0.000927\n",
      "759  Feature2         -0.050295        <NA> -9.314242e-04 -0.000100\n",
      "760  Feature2          0.277556        <NA>  2.972777e-03  0.000119\n",
      "761  Feature1         -1.119647        <NA> -4.642864e-04  0.000158\n",
      "\n",
      "[762 rows x 5 columns]\n",
      "NaN counts after handling: variable            0\n",
      "upper_bound_left    0\n",
      "levels_left         0\n",
      "pleft               0\n",
      "pright              0\n",
      "dtype: int64\n",
      "df_small grouped:      variable  upper_bound_left levels_left     pleft    pright\n",
      "0    Feature1         -2.137893     default  1.984653 -1.415416\n",
      "1    Feature1         -1.826655     default -4.766393 -0.928808\n",
      "2    Feature1         -1.617723     default -0.108028 -0.000543\n",
      "3    Feature1         -1.476045     default -0.126068  0.039407\n",
      "4    Feature1         -1.407075     default  0.001074 -0.000045\n",
      "..        ...               ...         ...       ...       ...\n",
      "240  Feature2          1.876483     default  0.001141  0.034250\n",
      "241  Feature2          1.953158     default  0.005292 -0.152687\n",
      "242  Feature2          2.048661     default -0.026580 -0.033576\n",
      "243  Feature2          2.114280     default -0.030078 -0.000357\n",
      "244  Feature2          2.684746     default -1.533885  5.503038\n",
      "\n",
      "[245 rows x 5 columns]\n",
      "df_small after concatenation:       variable  upper_bound_left levels_left                     pleft  \\\n",
      "0    Intercept               NaN         NaN  [2.4424906541753444e-17]   \n",
      "1     Feature1         -2.137893     default                  1.984653   \n",
      "2     Feature1         -1.826655     default                 -4.766393   \n",
      "3     Feature1         -1.617723     default                 -0.108028   \n",
      "4     Feature1         -1.476045     default                 -0.126068   \n",
      "..         ...               ...         ...                       ...   \n",
      "241   Feature2          1.876483     default                  0.001141   \n",
      "242   Feature2          1.953158     default                  0.005292   \n",
      "243   Feature2          2.048661     default                  -0.02658   \n",
      "244   Feature2          2.114280     default                 -0.030078   \n",
      "245   Feature2          2.684746     default                 -1.533885   \n",
      "\n",
      "                       pright  \n",
      "0    [2.4424906541753444e-17]  \n",
      "1                   -1.415416  \n",
      "2                   -0.928808  \n",
      "3                   -0.000543  \n",
      "4                    0.039407  \n",
      "..                        ...  \n",
      "241                   0.03425  \n",
      "242                 -0.152687  \n",
      "243                 -0.033576  \n",
      "244                 -0.000357  \n",
      "245                  5.503038  \n",
      "\n",
      "[246 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jjacq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgrove\\grove.py:589: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([intercept_df, df], ignore_index=True)\n",
      "c:\\Users\\jjacq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgrove\\grove.py:590: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_small = pd.concat([intercept_df, df_small], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame before grouping:       variable  upper_bound_left levels_left         pleft        pright\n",
      "0     Feature1         -0.719046        <NA>  6.281798e-01 -1.108553e-01\n",
      "1     Feature1         -1.179427        <NA>  2.161072e-01  9.887433e-01\n",
      "2     Feature2         -1.620043        <NA> -7.150824e-01  3.713054e-01\n",
      "3     Feature2         -0.336475        <NA>  1.367506e+00  3.574727e-01\n",
      "4     Feature1          2.178145        <NA> -1.329653e-01  1.746387e+00\n",
      "...        ...               ...         ...           ...           ...\n",
      "1546  Feature1         -0.052391        <NA>  6.800576e-08 -3.394888e-08\n",
      "1547  Feature2          0.720866        <NA>  4.169823e-08  3.179272e-07\n",
      "1548  Feature1         -0.011391        <NA> -6.985798e-07 -7.884927e-09\n",
      "1549  Feature2          1.953158        <NA> -5.622609e-07 -1.236725e-07\n",
      "1550  Feature2          2.048661        <NA> -1.990017e-07 -9.856279e-08\n",
      "\n",
      "[1551 rows x 5 columns]\n",
      "NaN counts after handling: variable            0\n",
      "upper_bound_left    0\n",
      "levels_left         0\n",
      "pleft               0\n",
      "pright              0\n",
      "dtype: int64\n",
      "df_small grouped:      variable  upper_bound_left levels_left     pleft    pright\n",
      "0    Feature1         -2.137893     default  2.503199 -1.751346\n",
      "1    Feature1         -1.826655     default -5.937901 -1.161420\n",
      "2    Feature1         -1.617723     default -0.162155 -0.000820\n",
      "3    Feature1         -1.476045     default -0.189100  0.059112\n",
      "4    Feature1         -1.407075     default  0.002149 -0.000090\n",
      "..        ...               ...         ...       ...       ...\n",
      "321  Feature2          1.920538     default -0.000034  0.000049\n",
      "322  Feature2          1.953158     default  0.007621 -0.236873\n",
      "323  Feature2          2.048661     default -0.053159 -0.067152\n",
      "324  Feature2          2.114280     default -0.060154 -0.000825\n",
      "325  Feature2          2.684746     default -1.841948  6.676410\n",
      "\n",
      "[326 rows x 5 columns]\n",
      "df_small after concatenation:       variable  upper_bound_left levels_left                     pleft  \\\n",
      "0    Intercept               NaN         NaN  [2.4424906541753444e-17]   \n",
      "1     Feature1         -2.137893     default                  2.503199   \n",
      "2     Feature1         -1.826655     default                 -5.937901   \n",
      "3     Feature1         -1.617723     default                 -0.162155   \n",
      "4     Feature1         -1.476045     default                   -0.1891   \n",
      "..         ...               ...         ...                       ...   \n",
      "322   Feature2          1.920538     default                 -0.000034   \n",
      "323   Feature2          1.953158     default                  0.007621   \n",
      "324   Feature2          2.048661     default                 -0.053159   \n",
      "325   Feature2          2.114280     default                 -0.060154   \n",
      "326   Feature2          2.684746     default                 -1.841948   \n",
      "\n",
      "                       pright  \n",
      "0    [2.4424906541753444e-17]  \n",
      "1                   -1.751346  \n",
      "2                    -1.16142  \n",
      "3                    -0.00082  \n",
      "4                    0.059112  \n",
      "..                        ...  \n",
      "322                  0.000049  \n",
      "323                 -0.236873  \n",
      "324                 -0.067152  \n",
      "325                 -0.000825  \n",
      "326                   6.67641  \n",
      "\n",
      "[327 rows x 5 columns]\n",
      "\n",
      "Explanation:\n",
      "   trees  rules   upsilon       cor\n",
      "0      4     27  0.611438  0.782310\n",
      "1      8     51  0.930383  0.965496\n",
      "2     16     92  0.997633  0.998818\n",
      "3     32    151  0.999998  0.999999\n",
      "4     64    246  1.000000  1.000000\n",
      "5    128    327  1.000000  1.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jjacq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgrove\\grove.py:589: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df = pd.concat([intercept_df, df], ignore_index=True)\n",
      "c:\\Users\\jjacq\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgrove\\grove.py:590: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  df_small = pd.concat([intercept_df, df_small], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pypmml import Model  # Importiere pypmml für das Modell\n",
    "import xgrove.grove as grove\n",
    "\n",
    "# Definiere den PMML-Dateipfad und den CSV-Datenpfad\n",
    "pmml_path = \"../models/linear_model.pmml\"\n",
    "data_path = \"../models/generated_data.csv\"\n",
    "\n",
    "# Lade das trainierte PMML-Modell (aus R gespeichert)\n",
    "pmml_model = Model.load(pmml_path)  # Laden des trainierten Modells\n",
    "\n",
    "# Lade die Eingabedaten aus der CSV-Datei\n",
    "input_data = pd.read_csv(data_path)\n",
    "\n",
    "# Entferne die Zielvariable 'Target' aus den Eingabedaten\n",
    "target = input_data[\"Target\"]\n",
    "input_data = input_data.drop(columns=[\"Target\"])\n",
    "\n",
    "# Erstelle ein grove-Objekt mit dem geladenen Modell und den bearbeiteten Eingabedaten\n",
    "grove_instance = grove(model=pmml_model, \n",
    "                       data=input_data, \n",
    "                       b_frac=1, \n",
    "                       shrink=1,  \n",
    "                       tar = target, \n",
    "                       seed=42)\n",
    "\n",
    "# Führe die Berechnung durch\n",
    "grove_instance.calculateGrove()\n",
    "\n",
    "# Ausgabe des Resultats und der Explanation\n",
    "# print(\"Result:\")\n",
    "# print(grove_instance.result)\n",
    "\n",
    "print(\"\\nExplanation:\")\n",
    "print(grove_instance.explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN counts in df before grouping:\n",
      "variable              0\n",
      "upper_bound_left      0\n",
      "levels_left         100\n",
      "pleft                 0\n",
      "pright                0\n",
      "dtype: int64\n",
      "   variable  upper_bound_left levels_left     pleft    pright\n",
      "0  Feature1             -1.97     default  0.784093 -0.160800\n",
      "1  Feature1             -1.87     default  0.284063 -0.896637\n",
      "2  Feature1             -1.82     default -0.524725  0.140122\n",
      "3  Feature1             -1.69     default -0.678384 -0.458335\n",
      "4  Feature1             -1.65     default  0.344271  0.872310\n",
      "   variable  upper_bound_left levels_left     pleft    pright\n",
      "0  Feature1             -1.97     default  0.784093 -0.160800\n",
      "1  Feature1             -1.87     default  0.284063 -0.896637\n",
      "2  Feature1             -1.82     default -0.524725  0.140122\n",
      "3  Feature1             -1.69     default -0.678384 -0.458335\n",
      "4  Feature1             -1.65     default  0.344271  0.872310\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Beispiel DataFrame mit zufälligen Werten\n",
    "np.random.seed(42)\n",
    "data = {\n",
    "    'variable': np.random.choice(['Feature1', 'Feature2'], size=100),  # 'Feature1' oder 'Feature2'\n",
    "    'upper_bound_left': np.random.uniform(-2, 2, size=100).round(2),  # Zufällige Werte für upper_bound_left\n",
    "    'levels_left': [None] * 100,  # Alle Werte auf None gesetzt\n",
    "    'pleft': np.random.uniform(-1, 1, size=100),  # Zufällige Werte für pleft\n",
    "    'pright': np.random.uniform(-1, 1, size=100)  # Zufällige Werte für pright\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Überprüfen auf NaN-Werte\n",
    "print(f\"NaN counts in df before grouping:\\n{df.isna().sum()}\")\n",
    "\n",
    "# Entfernen von NaN-Werten (falls nötig)\n",
    "df_cleaned = df.dropna(subset=['variable', 'upper_bound_left', 'pleft', 'pright'])\n",
    "\n",
    "# Gruppieren nach den Spalten 'variable', 'upper_bound_left' und 'levels_left'\n",
    "# Dann berechnen wir die Summe von 'pleft' und 'pright' für jede Gruppe\n",
    "# Setze 'levels_left' auf einen sinnvollen Standardwert (z. B. \"default\")\n",
    "df['levels_left'] = df['levels_left'].fillna('default')\n",
    "\n",
    "# Gruppieren nach 'variable', 'upper_bound_left' und 'levels_left'\n",
    "df_grouped = df.groupby(['variable', 'upper_bound_left', 'levels_left'], as_index=False).agg({\n",
    "    'pleft': 'sum',\n",
    "    'pright': 'sum'\n",
    "})\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "print(df_grouped.head())\n",
    "\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "print(df_grouped.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from jpmml_evaluator import make_evaluator\n",
    "# from xgrove import grove\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Setze den Pfad für Graphviz\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "\n",
    "# def debug_model_loading(pmml_file_path):\n",
    "#     \"\"\"Versucht, das PMML-Modell zu laden und zu validieren.\"\"\"\n",
    "#     try:\n",
    "#         evaluator = make_evaluator(pmml_file_path)\n",
    "#         evaluator.verify()\n",
    "#         print(\"PMML-Modell erfolgreich geladen und verifiziert.\")\n",
    "#         return evaluator\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden des PMML-Modells: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def debug_data_loading(csv_file_path):\n",
    "#     \"\"\"Lädt die CSV-Daten und gibt eine Warnung, falls NaN-Werte vorhanden sind.\"\"\"\n",
    "#     try:\n",
    "#         data = pd.read_csv(csv_file_path)\n",
    "#         print(f\"Daten erfolgreich geladen: {data.head()}\")\n",
    "        \n",
    "#         # Überprüfen auf NaN-Werte und leere Strings\n",
    "#         print(f\"NaN-Werte in den Daten: {data.isna().sum()}\")\n",
    "#         print(f\"Leere Strings in den Daten: {(data == '').sum()}\")\n",
    "        \n",
    "#         # Entferne NaN-Werte\n",
    "#         if data.isna().sum().sum() > 0:\n",
    "#             print(\"Warnung: Es gibt NaN-Werte in den Eingabedaten. Diese werden entfernt.\")\n",
    "#             data = data.dropna()\n",
    "        \n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden der CSV-Datei: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def preprocess_data(data):\n",
    "#     \"\"\"Bereitet die Eingabedaten vor, indem sie skaliert werden, wenn nötig.\"\"\"\n",
    "#     print(f\"Datenform nach NaN-Entfernung: {data.shape}\")\n",
    "\n",
    "#     # Skalierung der Daten, falls notwendig\n",
    "#     scaler = StandardScaler()\n",
    "#     data_scaled = data.copy()\n",
    "#     features = data.columns  # Hier wird davon ausgegangen, dass alle Spalten skaliert werden müssen.\n",
    "#     data_scaled[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "#     return data_scaled\n",
    "\n",
    "# def load_and_evaluate_model(pmml_file_path, csv_file_path):\n",
    "#     \"\"\"Lädt das PMML-Modell und erstellt ein Surrogat-Modell mit xgrove.\"\"\"\n",
    "    \n",
    "#     # 1. Lade die Trainingsdaten\n",
    "#     data = debug_data_loading(csv_file_path)\n",
    "#     if data is None:\n",
    "#         return\n",
    "\n",
    "#     # 2. Preprocessiere die Daten\n",
    "#     data = preprocess_data(data)\n",
    "\n",
    "#     # 3. Lade das PMML-Modell\n",
    "#     evaluator = debug_model_loading(pmml_file_path)\n",
    "#     if evaluator is None:\n",
    "#         return\n",
    "\n",
    "#     # 4. Generiere Surrogat-Zielwerte für die Daten\n",
    "#     surrogate_targets = []\n",
    "#     for i, row in data.iterrows():\n",
    "#         input_data = row.to_dict()  # Erstelle ein Dictionary für eine Zeile\n",
    "#         prediction = evaluator.evaluate(input_data)  # Einzeldatensatz bewerten\n",
    "#         surrogate_targets.append(prediction.get('Predicted_y', None))  # Nutze den Rückgabeschlüssel des Modells\n",
    "#         if i % 10 == 0:  # Debugging: Zeige alle 10 Zeilen\n",
    "#             print(f\"Verarbeite Zeile {i+1}/{len(data)}\")\n",
    "\n",
    "#     # 5. Überprüfe auf NaN-Werte in den Surrogat-Zielwerten\n",
    "#     print(\"Überprüfe auf NaN-Werte in den Surrogat-Zielwerten...\")\n",
    "#     surrogate_targets = [val for val in surrogate_targets if val is not None]  # Entferne NaN-Werte\n",
    "#     print(f\"Anzahl der gültigen Surrogat-Zielwerte: {len(surrogate_targets)}\")\n",
    "\n",
    "#     # Wenn nach der Bereinigung keine Surrogat-Zielwerte übrig sind, einen Fehler werfen\n",
    "#     if not surrogate_targets:\n",
    "#         raise ValueError(\"Fehler beim Erstellen der Surrogat-Zielwerte: Keine gültigen Zielwerte vorhanden.\")\n",
    "    \n",
    "#     # Surrogat-Targets in den DataFrame aufnehmen\n",
    "#     data['surrogatetarget'] = surrogate_targets\n",
    "#     print(f\"Surrogat-Zielwerte wurden erfolgreich zum Datensatz hinzugefügt. Datenform: {data.shape}\")\n",
    "\n",
    "#     # 6. Instanziiere die Grove-Klasse mit Surrogat-Targets und dem Modell\n",
    "#     grove_model = grove(model=evaluator, data=data, trained=True)\n",
    "    \n",
    "#     # Berechnung des Surrogat-Modells durchführen\n",
    "#     grove_model.calculateGrove()\n",
    "\n",
    "#     print(\"Berechnungen abgeschlossen.\")\n",
    "#     print(grove_model.get_result())\n",
    "\n",
    "#     # 7. Zusätzliche Modellattribute anzeigen (falls vorhanden)\n",
    "#     model_classes = evaluator.getModelClasses()  # Modellklassen, falls definiert\n",
    "#     print(f\"Model Klassen: {model_classes}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Definiere die Datei- und CSV-Pfade\n",
    "#     pmml_file_path = '../models/linear_model.pmml'\n",
    "#     csv_file_path = '../models/generated_data.csv'\n",
    "\n",
    "#     # Führe das Modell aus\n",
    "#     load_and_evaluate_model(pmml_file_path, csv_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
