{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten geladen:\n",
      "   Feature1  Feature2  Target\n",
      "0        48        72      48\n",
      "1       100        84      60\n",
      "2        64        42       0\n",
      "3        24        57      16\n",
      "4        73        71      32\n",
      "Die Vorhersagen wurden erfolgreich zu 'predictions.csv' hinzugefügt.\n",
      "df_small grouped:    variable  upper_bound_left levels_left   pleft  pright\n",
      "0  Feature1              22.0     default -1.2246  0.4082\n",
      "1  Feature1              58.0     default -1.4405  2.2532\n",
      "2  Feature2              60.5     default  0.4030 -0.6304\n",
      "df_small grouped:    variable  upper_bound_left levels_left   pleft  pright\n",
      "0  Feature1               6.0     default -0.6433  0.0795\n",
      "1  Feature1              22.0     default -1.2246  0.4082\n",
      "2  Feature1              37.5     default -0.3196  0.2315\n",
      "3  Feature1              58.0     default -1.2261  1.9179\n",
      "4  Feature1              90.5     default -0.1635  0.7984\n",
      "5  Feature2              60.5     default  0.4030 -0.6304\n",
      "df_small grouped:    variable  upper_bound_left levels_left   pleft  pright\n",
      "0  Feature1               6.0     default -0.6433  0.0795\n",
      "1  Feature1              22.0     default -0.9762  0.3254\n",
      "2  Feature1              30.0     default -0.1482  0.0798\n",
      "3  Feature1              37.5     default -0.3196  0.2315\n",
      "4  Feature1              40.5     default -0.1499  0.1226\n",
      "5  Feature1              58.0     default -0.8594  1.3444\n",
      "6  Feature1              77.0     default -0.1170  0.2865\n",
      "7  Feature1              90.5     default -0.1635  0.7984\n",
      "8  Feature2              28.5     default  0.2509 -0.0928\n",
      "9  Feature2              60.5     default  0.4030 -0.6304\n",
      "df_small grouped:     variable  upper_bound_left levels_left   pleft  pright\n",
      "0   Feature1               6.0     default -0.6433  0.0795\n",
      "1   Feature1              13.0     default -0.1576  0.0278\n",
      "2   Feature1              22.0     default -0.6450  0.2150\n",
      "3   Feature1              30.0     default -0.2516  0.1355\n",
      "4   Feature1              37.5     default -0.3196  0.2315\n",
      "5   Feature1              40.5     default -0.2054  0.1680\n",
      "6   Feature1              44.0     default -0.1021  0.0942\n",
      "7   Feature1              58.0     default -0.6919  1.0825\n",
      "8   Feature1              77.0     default -0.1925  0.4713\n",
      "9   Feature1              90.5     default -0.1635  0.7984\n",
      "10  Feature1              96.5     default -0.0188  0.1696\n",
      "11  Feature2              12.5     default  0.1934 -0.0239\n",
      "12  Feature2              28.5     default  0.2509 -0.0928\n",
      "13  Feature2              59.5     default -0.1102  0.1652\n",
      "14  Feature2              60.5     default  0.4030 -0.6304\n",
      "15  Feature2              87.5     default  0.0460 -0.2606\n",
      "df_small grouped:     variable  upper_bound_left levels_left   pleft  pright\n",
      "0   Feature1               6.0     default -0.6433  0.0795\n",
      "1   Feature1              13.0     default -0.1576  0.0278\n",
      "2   Feature1              14.5     default -0.0858  0.0163\n",
      "3   Feature1              16.0     default -0.0499  0.0102\n",
      "4   Feature1              22.0     default -0.4599  0.1533\n",
      "5   Feature1              24.5     default -0.0390  0.0159\n",
      "6   Feature1              27.0     default -0.0474  0.0223\n",
      "7   Feature1              30.0     default -0.2516  0.1355\n",
      "8   Feature1              37.5     default -0.3196  0.2315\n",
      "9   Feature1              40.5     default -0.2054  0.1680\n",
      "10  Feature1              44.0     default -0.1395  0.1288\n",
      "11  Feature1              50.5     default -0.0636  0.0748\n",
      "12  Feature1              58.0     default -0.5148  0.8054\n",
      "13  Feature1              71.0     default -0.0475  0.1010\n",
      "14  Feature1              72.5     default -0.0236  0.0526\n",
      "15  Feature1              77.0     default -0.2178  0.5333\n",
      "16  Feature1              81.5     default -0.0369  0.1051\n",
      "17  Feature1              85.5     default -0.0144  0.0510\n",
      "18  Feature1              90.5     default -0.1157  0.5646\n",
      "19  Feature1              95.0     default -0.0101  0.0817\n",
      "20  Feature1              96.5     default -0.0188  0.1696\n",
      "21  Feature2              12.5     default  0.1934 -0.0239\n",
      "22  Feature2              28.5     default  0.2509 -0.0928\n",
      "23  Feature2              35.0     default  0.0508 -0.0286\n",
      "24  Feature2              48.5     default  0.0469 -0.0451\n",
      "25  Feature2              59.5     default -0.1102  0.1652\n",
      "26  Feature2              60.5     default  0.3441 -0.5382\n",
      "27  Feature2              81.5     default  0.0188 -0.0753\n",
      "28  Feature2              87.5     default  0.0460 -0.2606\n",
      "df_small grouped:     variable  upper_bound_left levels_left   pleft  pright\n",
      "0   Feature1               6.0     default -0.5644  0.0698\n",
      "1   Feature1               8.5     default -0.0298  0.0045\n",
      "2   Feature1              13.0     default -0.1926  0.0340\n",
      "3   Feature1              14.5     default -0.0858  0.0163\n",
      "4   Feature1              16.0     default -0.0499  0.0102\n",
      "5   Feature1              18.0     default -0.0886  0.0236\n",
      "6   Feature1              22.0     default -0.3227  0.1076\n",
      "7   Feature1              24.5     default -0.0893  0.0364\n",
      "8   Feature1              27.0     default -0.0474  0.0223\n",
      "9   Feature1              30.0     default -0.2516  0.1355\n",
      "10  Feature1              37.5     default -0.3196  0.2315\n",
      "11  Feature1              40.5     default -0.2054  0.1680\n",
      "12  Feature1              44.0     default -0.1395  0.1288\n",
      "13  Feature1              50.5     default -0.0768  0.0903\n",
      "14  Feature1              52.5     default -0.0168  0.0206\n",
      "15  Feature1              53.5     default -0.0218  0.0277\n",
      "16  Feature1              58.0     default -0.3692  0.5779\n",
      "17  Feature1              65.5     default -0.0638  0.1085\n",
      "18  Feature1              67.5     default -0.0160  0.0284\n",
      "19  Feature1              71.0     default -0.0475  0.1010\n",
      "20  Feature1              72.5     default -0.0236  0.0526\n",
      "21  Feature1              77.0     default -0.2178  0.5333\n",
      "22  Feature1              81.5     default -0.0369  0.1051\n",
      "23  Feature1              84.0     default -0.0163  0.0546\n",
      "24  Feature1              85.5     default -0.0144  0.0510\n",
      "25  Feature1              86.5     default -0.0109  0.0409\n",
      "26  Feature1              90.5     default -0.0861  0.4200\n",
      "27  Feature1              91.5     default -0.0056  0.0373\n",
      "28  Feature1              95.0     default -0.0160  0.1295\n",
      "29  Feature1              96.5     default -0.0188  0.1696\n",
      "30  Feature2              12.5     default  0.1934 -0.0239\n",
      "31  Feature2              15.5     default  0.0316 -0.0060\n",
      "32  Feature2              19.5     default  0.0236 -0.0048\n",
      "33  Feature2              28.5     default  0.2509 -0.0928\n",
      "34  Feature2              29.5     default -0.0408  0.0159\n",
      "35  Feature2              33.5     default  0.0128 -0.0069\n",
      "36  Feature2              35.0     default  0.0508 -0.0286\n",
      "37  Feature2              48.5     default  0.1065 -0.1024\n",
      "38  Feature2              59.5     default -0.1102  0.1652\n",
      "39  Feature2              60.5     default  0.2902 -0.4537\n",
      "40  Feature2              61.5     default -0.0396  0.0705\n",
      "41  Feature2              71.5     default  0.0249 -0.0578\n",
      "42  Feature2              78.0     default  0.0135 -0.0428\n",
      "43  Feature2              79.5     default  0.0111 -0.0373\n",
      "44  Feature2              81.5     default  0.0188 -0.0753\n",
      "45  Feature2              87.5     default  0.0460 -0.2606\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Benötigte Bibliotheken importieren\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgrove as xg\n",
    "\n",
    "# Schritt 1: CSV-Datei einlesen (Daten aus der bestehenden Datei)\n",
    "data_path = \"../models/generated_data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Anzeige der ersten Zeilen, um sicherzustellen, dass die Daten korrekt geladen wurden\n",
    "print(\"Daten geladen:\")\n",
    "print(data.head())\n",
    "\n",
    "# Schritt 2: Lineares Regressionsmodell erstellen\n",
    "X = data[['Feature1', 'Feature2']]  # Unabhängige Variablen\n",
    "y = data['Target']  # Zielvariable\n",
    "\n",
    "# Modell erstellen und trainieren\n",
    "lm_model = LinearRegression()\n",
    "lm_model.fit(X, y)\n",
    "\n",
    "# Anzeige der Koeffizienten und des Intercepts\n",
    "# print(f\"Koeffizienten: {lm_model.coef_}\")\n",
    "# print(f\"Intercept: {lm_model.intercept_}\")\n",
    "\n",
    "# Schritt 3: Vorhersage mit dem Modell machen\n",
    "predictions_lm_new = lm_model.predict(X)\n",
    "\n",
    "# Die bestehende CSV-Datei einlesen\n",
    "predictions_df = pd.read_csv('../models/predictions.csv', dtype={'predicted_tar_lm': np.float64})\n",
    "\n",
    "# Vorhersagen für lm_model als neue Spalte hinzufügen\n",
    "predictions_df['predicted_tar_py'] = predictions_lm_new\n",
    "\n",
    "# Die aktualisierte Datei speichern (anfügen und nicht überschreiben)\n",
    "predictions_df.to_csv('../models/predictions.csv', index=False)  # Maximale Genauigkeit von 16 Dezimalstellen\n",
    "\n",
    "# Bestätigung der Speicherung\n",
    "print(\"Die Vorhersagen wurden erfolgreich zu 'predictions.csv' hinzugefügt.\")\n",
    "\n",
    "# Schritt 4: Berechnung der durchschnittlichen Abweichung\n",
    "# abweichung = np.mean(np.abs(y - predictions_lm_new))\n",
    "# print(f\"Durchschnittliche Abweichung: {abweichung}\")\n",
    "\n",
    "grove = xg.grove(data = data.drop(\"Target\", axis=1), seed=42, model=lm_model)\n",
    "grove.calculateGrove()\n",
    "grove.get_result()\n",
    "grove.plot_xgrove()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASE: 0.021999999999999985\n",
      "ASE0: 7.760000000000001\n",
      "Upsilon: 0.9971649484536083\n",
      "Correlation: 0.998665120881617\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Simulierte Testdaten\n",
    "surrTar = np.array([3, 2, 7, 8, 1])  # tatsächliche Zielwerte\n",
    "pexp = np.array([2.8, 2.1, 6.9, 8.1, 1.2])  # Vorhersagen des Modells\n",
    "\n",
    "# Berechnung von ASE und ASE0\n",
    "ASE = np.mean((surrTar - pexp) ** 2)\n",
    "ASE0 = np.mean((surrTar - np.mean(surrTar)) ** 2)\n",
    "\n",
    "# Berechnung von Upsilon\n",
    "upsilon = 1 - ASE / ASE0\n",
    "\n",
    "# Korrelation\n",
    "# correlation = np.corrcoef(surrTar, pexp)[0, 1]\n",
    "correlation, _ = pearsonr(surrTar, pexp)\n",
    "\n",
    "print(f\"ASE: {ASE}\")\n",
    "print(f\"ASE0: {ASE0}\")\n",
    "print(f\"Upsilon: {upsilon}\")\n",
    "print(f\"Correlation: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from pypmml import Model  # Importiere pypmml für das Modell\n",
    "# import xgrove.grove as grove\n",
    "\n",
    "# # Definiere den PMML-Dateipfad und den CSV-Datenpfad\n",
    "# pmml_path = \"../models/linear_model.pmml\"\n",
    "# data_path = \"../models/generated_data.csv\"\n",
    "\n",
    "# # Lade das trainierte PMML-Modell (aus R gespeichert)\n",
    "# pmml_model = Model.load(pmml_path)  # Laden des trainierten Modells\n",
    "\n",
    "# # Lade die Eingabedaten aus der CSV-Datei\n",
    "# input_data = pd.read_csv(data_path)\n",
    "\n",
    "# # Entferne die Zielvariable 'Target' aus den Eingabedaten\n",
    "# target = input_data[\"Target\"]\n",
    "# input_data = input_data.drop(columns=[\"Target\"])\n",
    "\n",
    "# # Erstelle ein grove-Objekt mit dem geladenen Modell und den bearbeiteten Eingabedaten\n",
    "# grove_instance = grove(model=pmml_model, \n",
    "#                        data=input_data, \n",
    "#                        b_frac=1,  \n",
    "#                        tar = target, \n",
    "#                        seed=42)\n",
    "\n",
    "# # Führe die Berechnung durch\n",
    "# grove_instance.calculateGrove()\n",
    "\n",
    "# # Beispielwerte der Mittelwerte und Standardabweichungen (ersetzen durch die aus R exportierten Werte)\n",
    "# means_r = [input_data.iloc[0], input_data.iloc[1]]  # Ersetze durch die Mittelwerte der Spalten aus R\n",
    "# sds_r = [input_data.iloc[0], input_data.iloc[1]]     # Ersetze durch die Standardabweichungen der Spalten aus R\n",
    "\n",
    "# # Skalierung der Daten in Python\n",
    "# input_data_scaled = (input_data - means_r) / sds_r\n",
    "\n",
    "# # Ausgabe des Resultats und der Explanation\n",
    "# # print(\"Result:\")\n",
    "# # print(grove_instance.result)\n",
    "\n",
    "# print(\"\\nExplanation:\")\n",
    "# print(grove_instance.explanation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Benötigte Bibliotheken importieren\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # Schritt 1: CSV-Datei einlesen (Daten aus der bestehenden Datei)\n",
    "# data_path = \"../models/generated_data.csv\"\n",
    "# data = pd.read_csv(data_path)\n",
    "\n",
    "# # Anzeige der ersten Zeilen, um sicherzustellen, dass die Daten korrekt geladen wurden\n",
    "# print(\"Daten geladen:\")\n",
    "# print(data.head())\n",
    "\n",
    "# # Schritt 2: Lineares Regressionsmodell erstellen\n",
    "# X = data[['Feature1', 'Feature2']]  # Unabhängige Variablen\n",
    "# y = data['Target']  # Zielvariable\n",
    "\n",
    "# # Modell erstellen und trainieren\n",
    "# lm_model = LinearRegression()\n",
    "# lm_model.fit(X, y)\n",
    "\n",
    "# # Anzeige der Koeffizienten und des Intercepts\n",
    "# print(f\"Koeffizienten: {lm_model.coef_}\")\n",
    "# print(f\"Intercept: {lm_model.intercept_}\")\n",
    "\n",
    "# # Schritt 3: Vorhersage mit dem Modell machen\n",
    "# predictions = lm_model.predict(X)\n",
    "\n",
    "# # Schritt 4: Berechnung der durchschnittlichen Abweichung\n",
    "# abweichung = np.mean(np.abs(y - predictions))\n",
    "# print(f\"Durchschnittliche Abweichung: {abweichung}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import statistics\n",
    "# from xgboost import XGBRegressor, DMatrix\n",
    "# import xgboost as xgb\n",
    "# import json\n",
    "\n",
    "# class grove():\n",
    "#     def __init__(self, \n",
    "#                  model, \n",
    "#                  data: pd.DataFrame,\n",
    "#                  ntrees: np.array = np.array([4, 8, 16, 32, 64, 128]), \n",
    "#                  pfun=None, \n",
    "#                  shrink: float = 1, \n",
    "#                  b_frac: float = 1, \n",
    "#                  seed: int = 42,\n",
    "#                  grove_rate: float = 1,\n",
    "#                  trained: bool = False,\n",
    "#                  tar=None):\n",
    "#         self.model = model\n",
    "#         self.data = self.encodeCategorical(data)\n",
    "#         self.ntrees = ntrees\n",
    "#         self.pfun = pfun\n",
    "#         self.shrink = shrink\n",
    "#         self.b_frac = b_frac\n",
    "#         self.seed = seed\n",
    "#         self.grove_rate = grove_rate\n",
    "#         self.trained = trained\n",
    "#         self.tar = tar\n",
    "#         self.surrTar = self.getSurrogateTarget(pfun=self.pfun, tar=self.tar)\n",
    "#         self.surrGrove = self.getGBM()\n",
    "#         self.predictions = []\n",
    "#         self.explanation = []\n",
    "#         self.groves = []\n",
    "#         self.rules = []\n",
    "#         self.result = []\n",
    "\n",
    "#     def encodeCategorical(self, data):\n",
    "#         categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n",
    "#         return pd.get_dummies(data, columns=categorical_columns)\n",
    "\n",
    "#     def getSurrogateTarget(self, pfun, tar):\n",
    "#         if tar is None:\n",
    "#             return self.model.predict(self.data) if self.pfun is None else pfun(model=self.model, data=self.data)\n",
    "#         else:\n",
    "#             return tar\n",
    "\n",
    "#     def getGBM(self):\n",
    "#         params = {\n",
    "#             'objective': 'reg:squarederror',  # Ziel für Regression (quadratische Fehler)\n",
    "#             'max_depth': 1,                   # Maximale Baumtiefe\n",
    "#             'eta': self.shrink,               # Lernrate (Shrinkage)\n",
    "#             'eval_metric': 'rmse',            # Evaluierungsmetrik (Root Mean Squared Error)\n",
    "#             'subsample': self.b_frac,         # Anteil der Trainingsdaten, der verwendet wird\n",
    "#             'random_state': self.seed         # Zufallsgenerator-Seed\n",
    "#         }\n",
    "\n",
    "#         # XGBRegressor mit den definierten Parametern\n",
    "#         grove = XGBRegressor(\n",
    "#             n_estimators=int(max(self.ntrees)),  # Anzahl der Bäume\n",
    "#             **params  # Übergibt das Dictionary mit den Parametern\n",
    "#         )\n",
    "#         grove.fit(self.data, self.surrTar)\n",
    "\n",
    "        \n",
    "#         # if np.array_equal(np.array(self.surrTar), np.array(self.model.predict(self.data))):\n",
    "#         #     print(\"HALLELUJA ITS THE SAME\")\n",
    "#         # else:\n",
    "#         #     print(f\"given target: {self.tar}\")\n",
    "#         #     print(f\"generated target: {self.model.predict(self.data)}\")\n",
    "#         return grove\n",
    "    \n",
    "#     def upsilon(self, pexp):\n",
    "#         surrTar_series = pd.Series(self.surrTar)\n",
    "#         pexp_series = pd.Series(pexp)\n",
    "#         print(f\"pexp: {pexp}\")\n",
    "#         ASE = statistics.mean((surrTar_series - pexp_series) ** 2)\n",
    "#         ASE0 = statistics.mean((surrTar_series - statistics.mean(surrTar_series)) ** 2)\n",
    "#         ups = 1 - ASE / ASE0\n",
    "#         rho = surrTar_series.corr(pexp_series)\n",
    "#         return ups, rho\n",
    "\n",
    "#     def get_result(self):\n",
    "#         return [self.explanation, self.rules, self.groves, self.model]\n",
    "    \n",
    "#     # def consolidate_rules(self, df_small):\n",
    "#     #         # Zugriff auf self.rules und self.data (Daten müssen vorhanden sein)\n",
    "#     #         data = self.data  \n",
    "#     #         i = 1\n",
    "#     #         while i < len(df_small):\n",
    "#     #             drop_rule = False\n",
    "#     #             # Überprüfen, ob der Datentyp der Spalte numerisch ist\n",
    "#     #             if pd.api.types.is_numeric_dtype(data[df_small.iloc[i][\"variable\"]]):\n",
    "#     #                 for j in range(i):\n",
    "#     #                     # Überprüfen, ob die Variable und die Obergrenze gleich sind\n",
    "#     #                     if df_small.iloc[i][\"variable\"] == df_small.iloc[j][\"variable\"]:\n",
    "#     #                         if df_small.iloc[i][\"upper_bound_left\"] == df_small.iloc[j][\"upper_bound_left\"]:\n",
    "#     #                             # Berechnung der crosstab-Tabelle\n",
    "#     #                             v1 = data[df_small.iloc[i][\"variable\"]] <= df_small.iloc[i][\"upper_bound_left\"]\n",
    "#     #                             v2 = data[df_small.iloc[j][\"variable\"]] <= df_small.iloc[j][\"upper_bound_left\"]\n",
    "#     #                             tab = pd.crosstab(v1, v2)\n",
    "                                \n",
    "#     #                             # Überprüfen, ob alle Werte in der Diagonalen übereinstimmen\n",
    "#     #                             if tab.to_numpy().diagonal().sum() == tab.sum().sum():\n",
    "#     #                                 # Konsolidierung der Werte in den Spalten 'pleft' und 'pright'\n",
    "#     #                                 df_small.at[j, \"pleft\"] += df_small.at[i, \"pleft\"]\n",
    "#     #                                 df_small.at[j, \"pright\"] += df_small.at[i, \"pright\"]\n",
    "#     #                                 drop_rule = True\n",
    "#     #                                 break\n",
    "\n",
    "#     #             # Löschen der redundanten Regel\n",
    "#     #             if drop_rule:\n",
    "#     #                 df_small = df_small.drop(i).reset_index(drop=True)\n",
    "#     #             else:\n",
    "#     #                 i += 1\n",
    "\n",
    "#     #         return df_small\n",
    "    \n",
    "#     def extract_rules(self, booster_json):\n",
    "#         rules = []  # Liste, die alle getrennten Regelsets speichert\n",
    "\n",
    "#         # Iteriere durch die ntrees_list und hole die Regeln für jeden Baum-Index\n",
    "#         for nt in self.ntrees:\n",
    "#             tree_rules = []  # Hier speichern wir die Regeln für den aktuellen Wert von nt\n",
    "            \n",
    "#             # Iteriere durch alle Bäume im booster_json\n",
    "#             for index, tree in enumerate(booster_json, start=1):  # start=1 sorgt dafür, dass der Baumindex bei 1 beginnt\n",
    "#                 # print(f\"DEBUG: Baum {index} - Typ von tree: {type(tree)}\")  # Gib den Typ des Baums aus\n",
    "                \n",
    "#                 # print(tree)\n",
    "#                 if isinstance(tree, dict):\n",
    "#                     # print(tree)\n",
    "#                     if 'children' in tree:\n",
    "#                         # print(f\"DEBUG: Baum {index} : {tree}\")\n",
    "#                         # print(f\"DEBUG: Baum {index} und sein split: {tree['split']}\")\n",
    "#                         # print(f\"DEBUG: Baum {index} hat 'children': {tree['children']}\")  # Zeige die Kinder des Baums an\n",
    "#                         # Jeden Split in den Kindern durchgehen und Regel extrahieren\n",
    "                        \n",
    "#                         # print(f\"split_node: {split_node}\")\n",
    "\n",
    "#                         left_value = None\n",
    "#                         right_value = None\n",
    "\n",
    "#                     # Gehe durch die Kindknoten und finde die Blattwerte\n",
    "#                         for child in tree['children']:\n",
    "#                             if 'leaf' in child:\n",
    "#                                 if child['nodeid'] == tree['yes']:  # Prüfe, ob dies der \"yes\"-Pfad ist\n",
    "#                                     left_value = round(child['leaf'], 4)\n",
    "#                                     # print(f\"DEBUG: Left leaf gefunden - Wert: {left_value}\")\n",
    "#                                 elif child['nodeid'] == tree['no']:  # Prüfe, ob dies der \"no\"-Pfad ist\n",
    "#                                     right_value = round(child['leaf'],4)\n",
    "#                                     # print(f\"DEBUG: Right leaf gefunden - Wert: {right_value}\")\n",
    "                        \n",
    "#                             rule = {\n",
    "#                                 'variable': tree.get('split', None),\n",
    "#                                 'threshold': tree.get('split_condition', None),\n",
    "#                                 'pleft': left_value,\n",
    "#                                 'pright': right_value\n",
    "#                             }\n",
    "#                         tree_rules.append(rule)\n",
    "#                     else:\n",
    "#                         print(f\"DEBUG: Baum {index} hat keine 'children'.\")  # Wenn keine 'children' da sind\n",
    "#                 else:\n",
    "#                     print(f\"DEBUG: Baum {index} ist kein Dictionary, sondern: {type(tree)}\")  # Baum ist kein dict\n",
    "\n",
    "#                 # Wenn der aktuelle Baum-Index die Anzahl von `nt` überschreitet, beende den Loop\n",
    "#                 if index >= nt:\n",
    "#                     break  # Wir haben genug Bäume extrahiert, also abbrechen\n",
    "            \n",
    "#             # Füge die extrahierten Regeln für diesen `nt`-Wert zur Gesamtregel-Liste hinzu\n",
    "#             print(f\"tree_rules {index}: {len(tree_rules)}\")\n",
    "#             rules.append(tree_rules)\n",
    "#         outer_shape = len(rules)\n",
    "\n",
    "#         # Anzahl der inneren Listen\n",
    "#         inner_shapes = [len(inner) for inner in rules]\n",
    "#         print(f\"all the Rules: {rules}\")\n",
    "        \n",
    "#         return rules\n",
    "\n",
    "\n",
    "#     def calculateGrove(self):\n",
    "#         explanation = []\n",
    "#         cumulative_rules_list = []\n",
    "#         data = self.data\n",
    "#         dtrain = xgb.DMatrix(data=data, label=self.surrTar)\n",
    "#         # cumulative_rules = pd.DataFrame()\n",
    "#         booster = self.surrGrove.get_booster()\n",
    "#         tree_json = booster.trees_to_dataframe()\n",
    "#         booster_json = booster.get_dump(dump_format=\"json\")\n",
    "#         parsed_trees = [json.loads(tree) for tree in booster_json]\n",
    "#         # print(f\"boosterjson: {booster_json}\")\n",
    "#         # print(f\"parsed_trees: {parsed_trees}\")\n",
    "#         tree1 = booster[0].get_dump(with_stats = True)[0]\n",
    "        \n",
    "#         # print(f\"tree1 = {tree1}\")\n",
    "        \n",
    "#         # for node in tree_json[tree_json['Tree'] == 0].itertuples():\n",
    "#         #     print(f\"Node ID: {node.ID}, Feature: {node.Feature}, Split: {node.Split}, \"\n",
    "#         #         f\"Gain: {node.Gain}, Cover: {node.Cover}\")\n",
    "            \n",
    "#         cumulative_rules_list = self.extract_rules(parsed_trees)\n",
    "        \n",
    "#         rules_df = pd.DataFrame()\n",
    "#         # print(f\"rules_df: {rules_df}\")\n",
    "        \n",
    "#         for nt in self.ntrees:\n",
    "#             # Berechnung von Vorhersagen, Upsilon und Korrelation\n",
    "#             predictions = booster.predict(dtrain, nt)\n",
    "#             upsilon, rho = self.upsilon(pexp=predictions)\n",
    "\n",
    "#             # Initialisierung von temporären Variablen\n",
    "#             vars_temp, splits_temp, csplits_left_temp, pleft_temp, pright_temp = [], [], [], [], []\n",
    "\n",
    "#             # Verarbeitung der Regeln aus cumulative_rules\n",
    "#             for rule_set in cumulative_rules_list:\n",
    "#                 for entry in rule_set:\n",
    "#                     var_name = entry['variable']\n",
    "#                     threshold = entry[\"threshold\"]\n",
    "#                     pleft = entry[\"pleft\"]\n",
    "#                     pright = entry[\"pright\"]\n",
    "#                     vars_temp.append(var_name)\n",
    "\n",
    "#                     if pd.api.types.is_string_dtype(data[var_name]):\n",
    "#                         levels = data[var_name].unique()\n",
    "#                         csplits_left_temp.append(\" | \".join(map(str, levels)))\n",
    "#                         splits_temp.append(\"\")\n",
    "#                     else:\n",
    "#                         splits_temp.append(threshold)\n",
    "#                         csplits_left_temp.append(pd.NA)\n",
    "                    \n",
    "#                     pleft_temp.append(pleft)\n",
    "#                     pright_temp.append(pright)\n",
    "\n",
    "#             # Erstellen des DataFrame für Regeln\n",
    "#             df = pd.DataFrame({\n",
    "#                 \"variable\": vars_temp,\n",
    "#                 \"upper_bound_left\": splits_temp,\n",
    "#                 \"levels_left\": csplits_left_temp,\n",
    "#                 \"pleft\": pleft_temp,\n",
    "#                 \"pright\": pright_temp\n",
    "#             })\n",
    "\n",
    "#             # Hinzufügen eines Intercept-Eintrags\n",
    "#             intercept_df = pd.DataFrame({\n",
    "#                 \"variable\": [\"Intercept\"],\n",
    "#                 \"upper_bound_left\": [pd.NA],\n",
    "#                 \"levels_left\": [pd.NA],\n",
    "#                 \"pleft\": [self.surrGrove.predict(data.iloc[[0]])[0]],\n",
    "#                 \"pright\": [self.surrGrove.predict(data.iloc[[0]])[0]]\n",
    "#             })\n",
    "\n",
    "#             # Konsolidierung und Gruppierung der Regeln\n",
    "#             df = pd.concat([intercept_df, df], ignore_index=True)\n",
    "#             # df = df.dropna(subset=[\"upper_bound_left\", \"levels_left\"], how=\"any\")\n",
    "#             df_small = df.groupby([\"variable\", \"upper_bound_left\", \"levels_left\"], as_index=False).agg({\n",
    "#                 \"pleft\": \"sum\",\n",
    "#                 \"pright\": \"sum\"\n",
    "#             })\n",
    "\n",
    "#             # Debugging-Ausgabe\n",
    "#             print(f\"DEBUG: Konsolidierte Regeln für nt={nt} Bäume:\\n{df_small.head()}\")\n",
    "\n",
    "#             # Ergebnis sammeln\n",
    "#             explanation.append({\n",
    "#                 \"trees\": nt,\n",
    "#                 \"rules\": len(df_small),\n",
    "#                 \"upsilon\": upsilon,\n",
    "#                 \"cor\": rho\n",
    "#             })\n",
    "#             self.rules.append(df_small)\n",
    "\n",
    "#         # Zusammenfassen der Ergebnisse\n",
    "#         self.explanation = pd.DataFrame(explanation)\n",
    "#         self.groves = rules_df\n",
    "#         self.result = self.get_result()\n",
    "#         print(\"DEBUG: Berechnung abgeschlossen. Ergebnisdaten verfügbar.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import statistics\n",
    "# from xgboost import XGBRegressor, DMatrix\n",
    "# import xgboost as xgb\n",
    "# import json\n",
    "\n",
    "# class grove:\n",
    "#     def __init__(self, \n",
    "#                  model, \n",
    "#                  data: pd.DataFrame,\n",
    "#                  ntrees: np.array = np.array([4, 8, 16, 32, 64, 128]), \n",
    "#                  pfun=None, \n",
    "#                  shrink: float = 1, \n",
    "#                  b_frac: float = 1, \n",
    "#                  seed: int = 42,\n",
    "#                  grove_rate: float = 1,\n",
    "#                  trained: bool = False,\n",
    "#                  tar=None):\n",
    "#         self.model = model\n",
    "#         self.data = self.encodeCategorical(data)\n",
    "#         self.ntrees = ntrees\n",
    "#         self.pfun = pfun\n",
    "#         self.shrink = shrink\n",
    "#         self.b_frac = b_frac\n",
    "#         self.seed = seed\n",
    "#         self.grove_rate = grove_rate\n",
    "#         self.trained = trained\n",
    "#         self.tar = tar\n",
    "#         self.surrTar = self.getSurrogateTarget(pfun=self.pfun, tar=self.tar)\n",
    "#         self.surrGrove = self.getGBM()\n",
    "#         self.predictions = []\n",
    "#         self.explanation = []\n",
    "#         self.groves = []\n",
    "#         self.rules = []\n",
    "#         self.result = []\n",
    "\n",
    "#     def encodeCategorical(self, data):\n",
    "#         categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n",
    "#         return pd.get_dummies(data, columns=categorical_columns)\n",
    "\n",
    "#     def getSurrogateTarget(self, pfun, tar):\n",
    "#         if tar is None:\n",
    "#             return self.model.predict(self.data) if self.pfun is None else pfun(model=self.model, data=self.data)\n",
    "#         else:\n",
    "#             return tar\n",
    "    \n",
    "#     def get_result(self):\n",
    "#         return [self.explanation, self.rules, self.groves, self.model]\n",
    "\n",
    "#     def getGBM(self):\n",
    "#         params = {\n",
    "#             'objective': 'reg:squarederror',  \n",
    "#             'max_depth': 1,                   \n",
    "#             'eta': self.shrink,               \n",
    "#             'eval_metric': 'rmse',            \n",
    "#             'subsample': self.b_frac,         \n",
    "#             'random_state': self.seed,\n",
    "#             'gamma': 0         \n",
    "#         }\n",
    "\n",
    "#         grove = XGBRegressor(\n",
    "#             n_estimators=int(max(self.ntrees)),  \n",
    "#             **params\n",
    "#         )\n",
    "#         grove.fit(self.data, self.surrTar)\n",
    "#         return grove\n",
    "    \n",
    "#     def upsilon(self, pexp):\n",
    "#         surrTar_series = pd.Series(self.surrTar)\n",
    "#         pexp_series = pd.Series(pexp)\n",
    "#         ASE = statistics.mean((surrTar_series - pexp_series) ** 2)\n",
    "#         ASE0 = statistics.mean((surrTar_series - statistics.mean(surrTar_series)) ** 2)\n",
    "#         ups = 1 - ASE / ASE0\n",
    "#         rho = surrTar_series.corr(pexp_series)\n",
    "#         return ups, rho\n",
    "\n",
    "#     def extract_rules(self, booster_json):\n",
    "#         rules = []\n",
    "#         for nt in self.ntrees:\n",
    "#             tree_rules = []\n",
    "#             for index, tree in enumerate(booster_json, start=1):\n",
    "#                 if isinstance(tree, dict) and 'children' in tree:\n",
    "#                     left_value, right_value = None, None\n",
    "#                     for child in tree['children']:\n",
    "#                         if 'leaf' in child:\n",
    "#                             if child['nodeid'] == tree['yes']:\n",
    "#                                 left_value = round(child['leaf'], 4)\n",
    "#                             elif child['nodeid'] == tree['no']:\n",
    "#                                 right_value = round(child['leaf'], 4)\n",
    "#                     rule = {\n",
    "#                         'variable': tree.get('split', None),\n",
    "#                         'threshold': tree.get('split_condition', None),\n",
    "#                         \"levels_left\": None,\n",
    "#                         'pleft': left_value,\n",
    "#                         'pright': right_value\n",
    "#                     }\n",
    "#                     tree_rules.append(rule)\n",
    "#                 if index >= nt:\n",
    "#                     break\n",
    "#             rules.append(tree_rules)\n",
    "#         return rules\n",
    "\n",
    "#     def remove_redundant_rules(self, df_small, data):\n",
    "#         \"\"\"\n",
    "#         Entfernt redundante Regeln aus dem DataFrame df_small basierend auf denselben Variablen und Trennbedingungen.\n",
    "        \n",
    "#         Args:\n",
    "#             df_small (pd.DataFrame): DataFrame mit Regeldefinitionen.\n",
    "#             data (pd.DataFrame): Original-Datensatz, um Variablenbedingungen zu überprüfen.\n",
    "        \n",
    "#         Returns:\n",
    "#             pd.DataFrame: Aktualisiertes df_small ohne redundante Regeln.\n",
    "#         \"\"\"\n",
    "#         if len(df_small) > 1:\n",
    "#             i = 1  # Start mit der zweiten Regel (Index in Python ist 0-basiert)\n",
    "\n",
    "#             while i < len(df_small):\n",
    "#                 drop_rule = False\n",
    "#                 # Überprüfen, ob die Variable numerisch ist\n",
    "#                 if pd.api.types.is_numeric_dtype(data[df_small.loc[i, \"variable\"]]):\n",
    "#                     for j in range(i):\n",
    "#                         # Wenn dieselbe Variable betroffen ist\n",
    "#                         if df_small.loc[i, \"variable\"] == df_small.loc[j, \"variable\"]:\n",
    "#                             v1 = data[df_small.loc[i, \"variable\"]] <= df_small.loc[i, \"threshold\"]\n",
    "#                             v2 = data[df_small.loc[j, \"variable\"]] <= df_small.loc[j, \"threshold\"]\n",
    "#                             tab = pd.crosstab(v1, v2)\n",
    "                            \n",
    "#                             if tab.to_numpy().trace() == tab.to_numpy().sum():\n",
    "#                                 df_small.loc[j, \"pleft\"] += df_small.loc[i, \"pleft\"]\n",
    "#                                 df_small.loc[j, \"pright\"] += df_small.loc[i, \"pright\"]\n",
    "#                                 drop_rule = True\n",
    "\n",
    "#                 # Regel entfernen oder zum nächsten Eintrag gehen\n",
    "#                 if drop_rule:\n",
    "#                     df_small = df_small.drop(index=i).reset_index(drop=True)\n",
    "#                 else:\n",
    "#                     i += 1\n",
    "\n",
    "#         return df_small\n",
    "\n",
    "\n",
    "#     def calculateGrove(self):\n",
    "#         explanation = []\n",
    "#         data = self.data\n",
    "#         dtrain = xgb.DMatrix(data=data, label=self.surrTar)\n",
    "#         booster = self.surrGrove.get_booster()\n",
    "#         booster_json = booster.get_dump(dump_format=\"json\")\n",
    "#         parsed_trees = [json.loads(tree) for tree in booster_json]\n",
    "#         cumulative_rules_list = self.extract_rules(parsed_trees)\n",
    "        \n",
    "#         for nt in self.ntrees:\n",
    "#             predictions = booster.predict(dtrain, iteration_range=(0, nt))\n",
    "#             upsilon, rho = self.upsilon(pexp=predictions)\n",
    "#             df_small_list = []  # Liste für die bereinigten DataFrames\n",
    "            \n",
    "#             for i in range(len(cumulative_rules_list)):\n",
    "#                 intercept_df = pd.DataFrame({\n",
    "#                     \"variable\": [\"Intercept\"],\n",
    "#                     \"threshold\": [None],\n",
    "#                     \"levels_left\": [None],\n",
    "#                     \"pleft\": [self.surrGrove.predict(data.iloc[[0]])[0]],\n",
    "#                     \"pright\": [self.surrGrove.predict(data.iloc[[0]])[0]]\n",
    "#                 })\n",
    "#                 df = pd.DataFrame(cumulative_rules_list[i])\n",
    "#                 df = pd.concat([intercept_df, df], ignore_index=True)\n",
    "                \n",
    "#                 # redundante Regeln entfernen\n",
    "#                 df_cleaned = self.remove_redundant_rules(df, data)\n",
    "#                 df_small_list.append(df_cleaned)\n",
    "#             print(f\"df_small_list: {df_small_list}\")\n",
    "#             # Alle DataFrames in df_small_list zusammenführen\n",
    "#             if df_small_list:  # Prüfen, ob Liste nicht leer ist\n",
    "#                 df_small = pd.concat(df_small_list, ignore_index=True)\n",
    "#             else:\n",
    "#                 df_small = pd.DataFrame()  # Leerer DataFrame, falls keine Daten\n",
    "            \n",
    "#             if \"levels_left\" in df_small.columns:\n",
    "#                 df_small[\"levels_left\"] = df_small[\"levels_left\"].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "#             # Gruppieren und Aggregieren\n",
    "#             if not df_small.empty:\n",
    "#                 df_small = df_small.groupby([\"variable\", \"threshold\", \"levels_left\"], as_index=False).agg({\n",
    "#                     \"pleft\": \"sum\",\n",
    "#                     \"pright\": \"sum\"\n",
    "#                 })\n",
    "#             if not df_small.empty:\n",
    "#                 num_rules = len(df_small)  # Anzahl der nicht-redundanten Regeln\n",
    "#             else:\n",
    "#                 num_rules = 0  # Falls df_small leer ist\n",
    "\n",
    "#             explanation.append({\n",
    "#                 \"trees\": nt,\n",
    "#                 \"rules\": num_rules,\n",
    "#                 \"upsilon\": upsilon,\n",
    "#                 \"cor\": rho\n",
    "#             })\n",
    "#             # Hinzufügen der Ergebnisse zur Erklärung\n",
    "            \n",
    "#             self.rules.append(df_small)\n",
    "\n",
    "#         self.explanation = pd.DataFrame(explanation)\n",
    "#         self.result = [self.explanation, self.rules, self.groves, self.model]\n",
    "    \n",
    "    \n",
    "    # TODO Zählung fixen\n",
    "    # def calculateGrove(self):\n",
    "    #     explanation = []\n",
    "    #     data = self.data\n",
    "    #     dtrain = xgb.DMatrix(data=data, label=self.surrTar)\n",
    "    #     booster = self.surrGrove.get_booster()\n",
    "    #     booster_json = booster.get_dump(dump_format=\"json\")\n",
    "    #     parsed_trees = [json.loads(tree) for tree in booster_json]\n",
    "    #     cumulative_rules_list = self.extract_rules(parsed_trees)\n",
    "    #     df_small_list = []  # Liste für alle DataFrames mit bereinigten Regeln\n",
    "    #     j=0\n",
    "    #     for nt in self.ntrees:\n",
    "            \n",
    "    #         predictions = booster.predict(dtrain, iteration_range=(0, nt))\n",
    "    #         upsilon, rho = self.upsilon(pexp=predictions)\n",
    "            \n",
    "    #         # Für jede Baumanzahl die Regeln und ihre Bereinigung durchführen\n",
    "    #         df_small = pd.DataFrame()\n",
    "            \n",
    "    #         for i in range(len(cumulative_rules_list)):\n",
    "    #             intercept_df = pd.DataFrame({\n",
    "    #                 \"variable\": [\"Intercept\"],\n",
    "    #                 \"threshold\": [None],\n",
    "    #                 \"levels_left\": [None],\n",
    "    #                 \"pleft\": [self.surrGrove.predict(data.iloc[[0]])[0]],\n",
    "    #                 \"pright\": [self.surrGrove.predict(data.iloc[[0]])[0]]\n",
    "    #             })\n",
    "    #             df = pd.DataFrame(cumulative_rules_list[i])\n",
    "    #             df = pd.concat([intercept_df, df], ignore_index=True)\n",
    "                \n",
    "    #             # Redundante Regeln entfernen und die bereinigte Liste anfügen\n",
    "    #             df_cleaned = self.remove_redundant_rules(df, data)  # Dynamische Bereinigung pro Iteration\n",
    "    #             if isinstance(df_small_list[j],None): \n",
    "    #                 df_small_list.append(pd.DataFrame({\n",
    "    #                     \"nt\": [nt],\n",
    "    #                     \"rules\": [df_cleaned]}, index=[j]))  # Liste aller bereinigten Regeln sammeln\n",
    "            \n",
    "    #         print(f\"df_small_list: {df_small_list}\")\n",
    "    #         # Alle bereinigten DataFrames zusammenführen\n",
    "    #         if df_small_list:\n",
    "    #             df_small = pd.concat(df_small_list, ignore_index=True)\n",
    "            \n",
    "    #         df_small['levels_left'] = df_small['levels_left'].fillna('None')\n",
    "    #         # Ersetze Listen durch 'None' oder einen anderen Platzhalter\n",
    "    #         df_small['levels_left'] = df_small['levels_left'].apply(lambda x: 'None' if isinstance(x, list) else x)\n",
    "\n",
    "    #         # Gruppieren und Aggregieren\n",
    "    #         if not df_small.empty:\n",
    "    #             df_small = df_small.groupby([\"variable\", \"threshold\", \"levels_left\"], as_index=False).agg({\n",
    "    #                 \"pleft\": \"sum\",\n",
    "    #                 \"pright\": \"sum\"\n",
    "    #             })\n",
    "            \n",
    "    #         # Anzahl der nicht-redundanten Regeln\n",
    "    #         num_rules = len(df_small)\n",
    "\n",
    "    #         # Ergebnisse zur Erklärung hinzufügen\n",
    "    #         explanation.append({\n",
    "    #             \"trees\": nt,\n",
    "    #             \"rules\": num_rules,  # Hier wird die Anzahl der nicht-redundanten Regeln gespeichert\n",
    "    #             \"upsilon\": upsilon,\n",
    "    #             \"cor\": rho\n",
    "    #         })\n",
    "\n",
    "    #         self.rules.append(df_small)\n",
    "    #         j += 1\n",
    "\n",
    "    #     self.explanation = pd.DataFrame(explanation)\n",
    "    #     self.result = [self.explanation, self.rules, self.groves, self.model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Structure:\n",
      "Node 0:\n",
      "  Feature used for split: 0\n",
      "  Threshold for split: 1.5\n",
      "  Value: 0.0000\n",
      "  Left child node: 1\n",
      "  Node 1:\n",
      "    Feature used for split: Leaf node\n",
      "    Threshold for split: N/A\n",
      "    Value: -1.7500\n",
      "  Right child node: 2\n",
      "  Node 2:\n",
      "    Feature used for split: 0\n",
      "    Threshold for split: 3.5\n",
      "    Value: 0.5833\n",
      "    Left child node: 3\n",
      "    Node 3:\n",
      "      Feature used for split: 0\n",
      "      Threshold for split: 2.5\n",
      "      Value: 0.0000\n",
      "      Left child node: 4\n",
      "      Node 4:\n",
      "        Feature used for split: Leaf node\n",
      "        Threshold for split: N/A\n",
      "        Value: 0.2500\n",
      "      Right child node: 5\n",
      "      Node 5:\n",
      "        Feature used for split: Leaf node\n",
      "        Threshold for split: N/A\n",
      "        Value: -0.2500\n",
      "    Right child node: 6\n",
      "    Node 6:\n",
      "      Feature used for split: Leaf node\n",
      "      Threshold for split: N/A\n",
      "      Value: 1.7500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Beispiel-Daten erstellen\n",
    "X = np.array([[1], [2], [3], [4]])\n",
    "y = np.array([1.5, 3.5, 3.0, 5.0])\n",
    "\n",
    "# GradientBoostingRegressor mit max_depth=3\n",
    "gbr = GradientBoostingRegressor(n_estimators=1, max_depth=3, random_state=42)\n",
    "gbr.fit(X, y)\n",
    "\n",
    "# Zugriff auf den ersten Baum\n",
    "first_tree = gbr.estimators_[0, 0].tree_\n",
    "\n",
    "# Rekursive Funktion zur Darstellung der Baumstruktur\n",
    "def print_tree_structure(tree, node_id=0, depth=0):\n",
    "    indent = \"  \" * depth\n",
    "    feature = tree.feature[node_id]\n",
    "    threshold = tree.threshold[node_id]\n",
    "    left_child = tree.children_left[node_id]\n",
    "    right_child = tree.children_right[node_id]\n",
    "\n",
    "    print(f\"{indent}Node {node_id}:\")\n",
    "    print(f\"{indent}  Feature used for split: {feature if feature != -2 else 'Leaf node'}\")\n",
    "    print(f\"{indent}  Threshold for split: {threshold if feature != -2 else 'N/A'}\")\n",
    "    print(f\"{indent}  Value: {tree.value[node_id].flatten()[0]:.4f}\")\n",
    "\n",
    "    if left_child != -1:  # Wenn ein linker Kindknoten existiert\n",
    "        print(f\"{indent}  Left child node: {left_child}\")\n",
    "        print_tree_structure(tree, left_child, depth + 1)\n",
    "    if right_child != -1:  # Wenn ein rechter Kindknoten existiert\n",
    "        print(f\"{indent}  Right child node: {right_child}\")\n",
    "        print_tree_structure(tree, right_child, depth + 1)\n",
    "\n",
    "# Baumstruktur ausgeben\n",
    "print(\"Tree Structure:\")\n",
    "print_tree_structure(first_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten geladen:\n",
      "   Feature1  Feature2  Target\n",
      "0        48        72      48\n",
      "1       100        84      60\n",
      "2        64        42       0\n",
      "3        24        57      16\n",
      "4        73        71      32\n",
      "Die Vorhersagen wurden erfolgreich zu 'predictions.csv' hinzugefügt.\n",
      "df_small_list: [    variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.406700   2.174700\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900,     variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.186400   1.845200\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900\n",
      "4   Feature1         9        None  -0.876600   0.137600\n",
      "5   Feature1        91        None  -0.140600   0.615200\n",
      "6   Feature1        86        None  -0.109900   0.372600,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.880800   1.386600\n",
      "2    Feature1        28        None  -1.021800   0.502200\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.140600   0.615200\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.084100   0.199800\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.714900   1.123700\n",
      "2    Feature1        28        None  -0.811600   0.402800\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.118200   0.512100\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.143400   0.341000\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.156600   0.043800\n",
      "13   Feature1        99        None  -0.022900   0.233300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.068500  -0.042000\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.054100   0.051000,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.533100   0.844500\n",
      "2    Feature1        28        None  -0.666700   0.330300\n",
      "3    Feature2        61        None   0.334800  -0.530400\n",
      "4    Feature1         9        None  -0.810000   0.125400\n",
      "5    Feature1        91        None  -0.104300   0.448500\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.027000   0.056100\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.029000  -0.027600\n",
      "28   Feature1        70        None  -0.020200   0.040000\n",
      "29   Feature1        23        None  -0.045300   0.015400,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.397100   0.633300\n",
      "2    Feature1        28        None  -0.462100   0.231200\n",
      "3    Feature2        61        None   0.280600  -0.447800\n",
      "4    Feature1         9        None  -0.724300   0.111500\n",
      "5    Feature1        91        None  -0.080800   0.340800\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.451400  -0.030300\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.046500   0.081300\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.039900   0.080900\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.085100  -0.080900\n",
      "28   Feature1        70        None  -0.034300   0.067900\n",
      "29   Feature1        23        None  -0.112600   0.038900\n",
      "30   Feature1        34        None  -0.056000   0.035100\n",
      "31   Feature2        96        None   0.006400  -0.080200\n",
      "32   Feature1        73        None  -0.011000   0.022900\n",
      "33   Feature1        53        None  -0.044300   0.053500\n",
      "34   Feature1        68        None  -0.025100   0.043700\n",
      "35   Feature2        25        None   0.052400  -0.013400\n",
      "36   Feature1        52        None  -0.017100   0.019900\n",
      "37   Feature2        91        None   0.007700  -0.048000\n",
      "38   Feature1        31        None  -0.041100   0.022800\n",
      "39   Feature1        25        None  -0.023200   0.009800\n",
      "40   Feature1         4        None  -0.048100   0.004400\n",
      "41   Feature2        84        None  -0.007200   0.029400\n",
      "42   Feature2        72        None   0.008400  -0.019100\n",
      "43   Feature1        96        None  -0.006700   0.048700\n",
      "44   Feature1       100        None  -0.002600   0.058600\n",
      "45   Feature1        67        None  -0.041400   0.068900\n",
      "46   Feature1        33        None  -0.017700   0.010600]\n",
      "df_small_list: [    variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.406700   2.174700\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900,     variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.186400   1.845200\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900\n",
      "4   Feature1         9        None  -0.876600   0.137600\n",
      "5   Feature1        91        None  -0.140600   0.615200\n",
      "6   Feature1        86        None  -0.109900   0.372600,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.880800   1.386600\n",
      "2    Feature1        28        None  -1.021800   0.502200\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.140600   0.615200\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.084100   0.199800\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.714900   1.123700\n",
      "2    Feature1        28        None  -0.811600   0.402800\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.118200   0.512100\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.143400   0.341000\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.156600   0.043800\n",
      "13   Feature1        99        None  -0.022900   0.233300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.068500  -0.042000\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.054100   0.051000,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.533100   0.844500\n",
      "2    Feature1        28        None  -0.666700   0.330300\n",
      "3    Feature2        61        None   0.334800  -0.530400\n",
      "4    Feature1         9        None  -0.810000   0.125400\n",
      "5    Feature1        91        None  -0.104300   0.448500\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.027000   0.056100\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.029000  -0.027600\n",
      "28   Feature1        70        None  -0.020200   0.040000\n",
      "29   Feature1        23        None  -0.045300   0.015400,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.397100   0.633300\n",
      "2    Feature1        28        None  -0.462100   0.231200\n",
      "3    Feature2        61        None   0.280600  -0.447800\n",
      "4    Feature1         9        None  -0.724300   0.111500\n",
      "5    Feature1        91        None  -0.080800   0.340800\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.451400  -0.030300\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.046500   0.081300\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.039900   0.080900\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.085100  -0.080900\n",
      "28   Feature1        70        None  -0.034300   0.067900\n",
      "29   Feature1        23        None  -0.112600   0.038900\n",
      "30   Feature1        34        None  -0.056000   0.035100\n",
      "31   Feature2        96        None   0.006400  -0.080200\n",
      "32   Feature1        73        None  -0.011000   0.022900\n",
      "33   Feature1        53        None  -0.044300   0.053500\n",
      "34   Feature1        68        None  -0.025100   0.043700\n",
      "35   Feature2        25        None   0.052400  -0.013400\n",
      "36   Feature1        52        None  -0.017100   0.019900\n",
      "37   Feature2        91        None   0.007700  -0.048000\n",
      "38   Feature1        31        None  -0.041100   0.022800\n",
      "39   Feature1        25        None  -0.023200   0.009800\n",
      "40   Feature1         4        None  -0.048100   0.004400\n",
      "41   Feature2        84        None  -0.007200   0.029400\n",
      "42   Feature2        72        None   0.008400  -0.019100\n",
      "43   Feature1        96        None  -0.006700   0.048700\n",
      "44   Feature1       100        None  -0.002600   0.058600\n",
      "45   Feature1        67        None  -0.041400   0.068900\n",
      "46   Feature1        33        None  -0.017700   0.010600]\n",
      "df_small_list: [    variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.406700   2.174700\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900,     variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.186400   1.845200\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900\n",
      "4   Feature1         9        None  -0.876600   0.137600\n",
      "5   Feature1        91        None  -0.140600   0.615200\n",
      "6   Feature1        86        None  -0.109900   0.372600,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.880800   1.386600\n",
      "2    Feature1        28        None  -1.021800   0.502200\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.140600   0.615200\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.084100   0.199800\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.714900   1.123700\n",
      "2    Feature1        28        None  -0.811600   0.402800\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.118200   0.512100\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.143400   0.341000\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.156600   0.043800\n",
      "13   Feature1        99        None  -0.022900   0.233300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.068500  -0.042000\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.054100   0.051000,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.533100   0.844500\n",
      "2    Feature1        28        None  -0.666700   0.330300\n",
      "3    Feature2        61        None   0.334800  -0.530400\n",
      "4    Feature1         9        None  -0.810000   0.125400\n",
      "5    Feature1        91        None  -0.104300   0.448500\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.027000   0.056100\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.029000  -0.027600\n",
      "28   Feature1        70        None  -0.020200   0.040000\n",
      "29   Feature1        23        None  -0.045300   0.015400,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.397100   0.633300\n",
      "2    Feature1        28        None  -0.462100   0.231200\n",
      "3    Feature2        61        None   0.280600  -0.447800\n",
      "4    Feature1         9        None  -0.724300   0.111500\n",
      "5    Feature1        91        None  -0.080800   0.340800\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.451400  -0.030300\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.046500   0.081300\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.039900   0.080900\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.085100  -0.080900\n",
      "28   Feature1        70        None  -0.034300   0.067900\n",
      "29   Feature1        23        None  -0.112600   0.038900\n",
      "30   Feature1        34        None  -0.056000   0.035100\n",
      "31   Feature2        96        None   0.006400  -0.080200\n",
      "32   Feature1        73        None  -0.011000   0.022900\n",
      "33   Feature1        53        None  -0.044300   0.053500\n",
      "34   Feature1        68        None  -0.025100   0.043700\n",
      "35   Feature2        25        None   0.052400  -0.013400\n",
      "36   Feature1        52        None  -0.017100   0.019900\n",
      "37   Feature2        91        None   0.007700  -0.048000\n",
      "38   Feature1        31        None  -0.041100   0.022800\n",
      "39   Feature1        25        None  -0.023200   0.009800\n",
      "40   Feature1         4        None  -0.048100   0.004400\n",
      "41   Feature2        84        None  -0.007200   0.029400\n",
      "42   Feature2        72        None   0.008400  -0.019100\n",
      "43   Feature1        96        None  -0.006700   0.048700\n",
      "44   Feature1       100        None  -0.002600   0.058600\n",
      "45   Feature1        67        None  -0.041400   0.068900\n",
      "46   Feature1        33        None  -0.017700   0.010600]\n",
      "df_small_list: [    variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.406700   2.174700\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900,     variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.186400   1.845200\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900\n",
      "4   Feature1         9        None  -0.876600   0.137600\n",
      "5   Feature1        91        None  -0.140600   0.615200\n",
      "6   Feature1        86        None  -0.109900   0.372600,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.880800   1.386600\n",
      "2    Feature1        28        None  -1.021800   0.502200\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.140600   0.615200\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.084100   0.199800\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.714900   1.123700\n",
      "2    Feature1        28        None  -0.811600   0.402800\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.118200   0.512100\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.143400   0.341000\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.156600   0.043800\n",
      "13   Feature1        99        None  -0.022900   0.233300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.068500  -0.042000\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.054100   0.051000,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.533100   0.844500\n",
      "2    Feature1        28        None  -0.666700   0.330300\n",
      "3    Feature2        61        None   0.334800  -0.530400\n",
      "4    Feature1         9        None  -0.810000   0.125400\n",
      "5    Feature1        91        None  -0.104300   0.448500\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.027000   0.056100\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.029000  -0.027600\n",
      "28   Feature1        70        None  -0.020200   0.040000\n",
      "29   Feature1        23        None  -0.045300   0.015400,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.397100   0.633300\n",
      "2    Feature1        28        None  -0.462100   0.231200\n",
      "3    Feature2        61        None   0.280600  -0.447800\n",
      "4    Feature1         9        None  -0.724300   0.111500\n",
      "5    Feature1        91        None  -0.080800   0.340800\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.451400  -0.030300\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.046500   0.081300\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.039900   0.080900\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.085100  -0.080900\n",
      "28   Feature1        70        None  -0.034300   0.067900\n",
      "29   Feature1        23        None  -0.112600   0.038900\n",
      "30   Feature1        34        None  -0.056000   0.035100\n",
      "31   Feature2        96        None   0.006400  -0.080200\n",
      "32   Feature1        73        None  -0.011000   0.022900\n",
      "33   Feature1        53        None  -0.044300   0.053500\n",
      "34   Feature1        68        None  -0.025100   0.043700\n",
      "35   Feature2        25        None   0.052400  -0.013400\n",
      "36   Feature1        52        None  -0.017100   0.019900\n",
      "37   Feature2        91        None   0.007700  -0.048000\n",
      "38   Feature1        31        None  -0.041100   0.022800\n",
      "39   Feature1        25        None  -0.023200   0.009800\n",
      "40   Feature1         4        None  -0.048100   0.004400\n",
      "41   Feature2        84        None  -0.007200   0.029400\n",
      "42   Feature2        72        None   0.008400  -0.019100\n",
      "43   Feature1        96        None  -0.006700   0.048700\n",
      "44   Feature1       100        None  -0.002600   0.058600\n",
      "45   Feature1        67        None  -0.041400   0.068900\n",
      "46   Feature1        33        None  -0.017700   0.010600]\n",
      "df_small_list: [    variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.406700   2.174700\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900,     variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.186400   1.845200\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900\n",
      "4   Feature1         9        None  -0.876600   0.137600\n",
      "5   Feature1        91        None  -0.140600   0.615200\n",
      "6   Feature1        86        None  -0.109900   0.372600,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.880800   1.386600\n",
      "2    Feature1        28        None  -1.021800   0.502200\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.140600   0.615200\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.084100   0.199800\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.714900   1.123700\n",
      "2    Feature1        28        None  -0.811600   0.402800\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.118200   0.512100\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.143400   0.341000\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.156600   0.043800\n",
      "13   Feature1        99        None  -0.022900   0.233300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.068500  -0.042000\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.054100   0.051000,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.533100   0.844500\n",
      "2    Feature1        28        None  -0.666700   0.330300\n",
      "3    Feature2        61        None   0.334800  -0.530400\n",
      "4    Feature1         9        None  -0.810000   0.125400\n",
      "5    Feature1        91        None  -0.104300   0.448500\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.027000   0.056100\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.029000  -0.027600\n",
      "28   Feature1        70        None  -0.020200   0.040000\n",
      "29   Feature1        23        None  -0.045300   0.015400,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.397100   0.633300\n",
      "2    Feature1        28        None  -0.462100   0.231200\n",
      "3    Feature2        61        None   0.280600  -0.447800\n",
      "4    Feature1         9        None  -0.724300   0.111500\n",
      "5    Feature1        91        None  -0.080800   0.340800\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.451400  -0.030300\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.046500   0.081300\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.039900   0.080900\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.085100  -0.080900\n",
      "28   Feature1        70        None  -0.034300   0.067900\n",
      "29   Feature1        23        None  -0.112600   0.038900\n",
      "30   Feature1        34        None  -0.056000   0.035100\n",
      "31   Feature2        96        None   0.006400  -0.080200\n",
      "32   Feature1        73        None  -0.011000   0.022900\n",
      "33   Feature1        53        None  -0.044300   0.053500\n",
      "34   Feature1        68        None  -0.025100   0.043700\n",
      "35   Feature2        25        None   0.052400  -0.013400\n",
      "36   Feature1        52        None  -0.017100   0.019900\n",
      "37   Feature2        91        None   0.007700  -0.048000\n",
      "38   Feature1        31        None  -0.041100   0.022800\n",
      "39   Feature1        25        None  -0.023200   0.009800\n",
      "40   Feature1         4        None  -0.048100   0.004400\n",
      "41   Feature2        84        None  -0.007200   0.029400\n",
      "42   Feature2        72        None   0.008400  -0.019100\n",
      "43   Feature1        96        None  -0.006700   0.048700\n",
      "44   Feature1       100        None  -0.002600   0.058600\n",
      "45   Feature1        67        None  -0.041400   0.068900\n",
      "46   Feature1        33        None  -0.017700   0.010600]\n",
      "df_small_list: [    variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.406700   2.174700\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900,     variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.186400   1.845200\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900\n",
      "4   Feature1         9        None  -0.876600   0.137600\n",
      "5   Feature1        91        None  -0.140600   0.615200\n",
      "6   Feature1        86        None  -0.109900   0.372600,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.880800   1.386600\n",
      "2    Feature1        28        None  -1.021800   0.502200\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.140600   0.615200\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.084100   0.199800\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.714900   1.123700\n",
      "2    Feature1        28        None  -0.811600   0.402800\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.118200   0.512100\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.143400   0.341000\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.156600   0.043800\n",
      "13   Feature1        99        None  -0.022900   0.233300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.068500  -0.042000\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.054100   0.051000,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.533100   0.844500\n",
      "2    Feature1        28        None  -0.666700   0.330300\n",
      "3    Feature2        61        None   0.334800  -0.530400\n",
      "4    Feature1         9        None  -0.810000   0.125400\n",
      "5    Feature1        91        None  -0.104300   0.448500\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.027000   0.056100\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.029000  -0.027600\n",
      "28   Feature1        70        None  -0.020200   0.040000\n",
      "29   Feature1        23        None  -0.045300   0.015400,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.397100   0.633300\n",
      "2    Feature1        28        None  -0.462100   0.231200\n",
      "3    Feature2        61        None   0.280600  -0.447800\n",
      "4    Feature1         9        None  -0.724300   0.111500\n",
      "5    Feature1        91        None  -0.080800   0.340800\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.451400  -0.030300\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.046500   0.081300\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.039900   0.080900\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.085100  -0.080900\n",
      "28   Feature1        70        None  -0.034300   0.067900\n",
      "29   Feature1        23        None  -0.112600   0.038900\n",
      "30   Feature1        34        None  -0.056000   0.035100\n",
      "31   Feature2        96        None   0.006400  -0.080200\n",
      "32   Feature1        73        None  -0.011000   0.022900\n",
      "33   Feature1        53        None  -0.044300   0.053500\n",
      "34   Feature1        68        None  -0.025100   0.043700\n",
      "35   Feature2        25        None   0.052400  -0.013400\n",
      "36   Feature1        52        None  -0.017100   0.019900\n",
      "37   Feature2        91        None   0.007700  -0.048000\n",
      "38   Feature1        31        None  -0.041100   0.022800\n",
      "39   Feature1        25        None  -0.023200   0.009800\n",
      "40   Feature1         4        None  -0.048100   0.004400\n",
      "41   Feature2        84        None  -0.007200   0.029400\n",
      "42   Feature2        72        None   0.008400  -0.019100\n",
      "43   Feature1        96        None  -0.006700   0.048700\n",
      "44   Feature1       100        None  -0.002600   0.058600\n",
      "45   Feature1        67        None  -0.041400   0.068900\n",
      "46   Feature1        33        None  -0.017700   0.010600]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[   trees  rules   upsilon       cor\n",
       " 0      4      0  0.896764  0.947322\n",
       " 1      8      0  0.951506  0.975972\n",
       " 2     16      0  0.975604  0.988134\n",
       " 3     32      0  0.988291  0.994147\n",
       " 4     64      0  0.994768  0.997393\n",
       " 5    128      0  0.997864  0.998934,\n",
       " [Empty DataFrame\n",
       "  Columns: [variable, threshold, levels_left, pleft, pright]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [variable, threshold, levels_left, pleft, pright]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [variable, threshold, levels_left, pleft, pright]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [variable, threshold, levels_left, pleft, pright]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [variable, threshold, levels_left, pleft, pright]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [variable, threshold, levels_left, pleft, pright]\n",
       "  Index: []],\n",
       " [],\n",
       " LinearRegression()]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Benötigte Bibliotheken importieren\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import json\n",
    "\n",
    "# Schritt 1: CSV-Datei einlesen (Daten aus der bestehenden Datei)\n",
    "data_path = \"../models/generated_data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Anzeige der ersten Zeilen, um sicherzustellen, dass die Daten korrekt geladen wurden\n",
    "print(\"Daten geladen:\")\n",
    "print(data.head())\n",
    "\n",
    "# Schritt 2: Lineares Regressionsmodell erstellen\n",
    "X = data[['Feature1', 'Feature2']]  # Unabhängige Variablen\n",
    "y = data['Target']  # Zielvariable\n",
    "\n",
    "# Modell erstellen und trainieren\n",
    "lm_model = LinearRegression()\n",
    "lm_model.fit(X, y)\n",
    "\n",
    "# Anzeige der Koeffizienten und des Intercepts\n",
    "# print(f\"Koeffizienten: {lm_model.coef_}\")\n",
    "# print(f\"Intercept: {lm_model.intercept_}\")\n",
    "\n",
    "# Schritt 3: Vorhersage mit dem Modell machen\n",
    "predictions_lm_new = lm_model.predict(X)\n",
    "\n",
    "# Die bestehende CSV-Datei einlesen\n",
    "predictions_df = pd.read_csv('../models/predictions.csv', dtype={'predicted_tar_lm': np.float64})\n",
    "\n",
    "# Vorhersagen für lm_model als neue Spalte hinzufügen\n",
    "predictions_df['predicted_tar_py'] = predictions_lm_new\n",
    "\n",
    "# Die aktualisierte Datei speichern (anfügen und nicht überschreiben)\n",
    "predictions_df.to_csv('../models/predictions.csv', index=False)  # Maximale Genauigkeit von 16 Dezimalstellen\n",
    "\n",
    "# Bestätigung der Speicherung\n",
    "print(\"Die Vorhersagen wurden erfolgreich zu 'predictions.csv' hinzugefügt.\")\n",
    "\n",
    "# Schritt 4: Berechnung der durchschnittlichen Abweichung\n",
    "# abweichung = np.mean(np.abs(y - predictions_lm_new))\n",
    "# print(f\"Durchschnittliche Abweichung: {abweichung}\")\n",
    "\n",
    "\n",
    "\n",
    "xg = grove(data = data.drop(\"Target\", axis=1), seed=42, model=lm_model)\n",
    "xg.calculateGrove()\n",
    "xg.get_result()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import platform\n",
    "# print(platform.architecture())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jpype\n",
    "# jpype.startJVM()  # Startet die JVM\n",
    "# print(\"JVM erfolgreich gestartet!\")\n",
    "# jpype.shutdownJVM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jpmml_evaluator import make_evaluator\n",
    "\n",
    "# # Teste, ob die JVM erfolgreich gestartet werden kann\n",
    "# try:\n",
    "#     evaluator = make_evaluator('../models/analyzed_model.pmml')  # Verwende einen einfachen PMML-Pfad\n",
    "#     evaluator.verify()\n",
    "#     print(\"JVM erfolgreich gestartet und PMML-Modell erfolgreich geladen.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Fehler: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"START\")\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from pypmml import Model\n",
    "\n",
    "# # Pfad zur PMML-Datei und zur CSV-Datei\n",
    "# pmml_file_path = '/mnt/data/analyzed_model.pmml'\n",
    "# csv_file_path = 'models/generated_data.csv'  # Passe den Pfad zur CSV-Datei bei Bedarf an\n",
    "\n",
    "# # Funktion zum Laden des Modells mit verbesserter Fehlerbehandlung\n",
    "# def load_model(file_path):\n",
    "#     try:\n",
    "#         # Modell mit pypmml laden\n",
    "#         loaded_model = Model.load(file_path)\n",
    "#         if loaded_model is not None:\n",
    "#             print(\"Modell erfolgreich geladen.\")\n",
    "#             return loaded_model\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden des PMML-Modells: {e}\")\n",
    "#     return None\n",
    "\n",
    "# # Modell laden\n",
    "# loaded_model = load_model(pmml_file_path)\n",
    "\n",
    "# if loaded_model is not None:\n",
    "#     # Lade die generierten Daten\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "    \n",
    "#     # Vorverarbeitung: Sicherstellen, dass kategorische Variablen als solche erkannt werden\n",
    "#     data['Geschlecht'] = data['Geschlecht'].astype('category')\n",
    "#     data['Kategorie'] = data['Kategorie'].astype('category')\n",
    "\n",
    "#     # Vorhersagen durchführen\n",
    "#     predictions = loaded_model.predict(data)\n",
    "#     print(predictions)  # Ergebnisse anzeigen\n",
    "    \n",
    "# else:\n",
    "#     print(\"Das Modell konnte nicht geladen werden.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.tree import DecisionTreeRegressor  # Verwende DecisionTreeRegressor\n",
    "# from sklearn2pmml.pipeline import PMMLPipeline\n",
    "# from sklearn2pmml import sklearn2pmml\n",
    "# from jpmml_evaluator import make_evaluator\n",
    "\n",
    "# # PMML-Dateipfad und CSV-Dateipfad\n",
    "# pmml_file_path = '../models/analyzed_model.pmml'\n",
    "# csv_file_path = '../models/generated_data.csv'\n",
    "\n",
    "# # Schritt 1: Modell erstellen, trainieren und als PMML speichern\n",
    "# def train_and_save_model():\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "#     X = data.drop(columns=['Zielwert'])  # Ersetze 'Zielwert' mit dem tatsächlichen Zielnamen\n",
    "#     y = data['Zielwert']  # Ersetze 'Zielwert' mit dem tatsächlichen Zielnamen\n",
    "\n",
    "#     # Umwandeln der kategorischen Variablen in Dummy-Variablen\n",
    "#     X = pd.get_dummies(X)\n",
    "\n",
    "#     # Pipeline erstellen und trainieren\n",
    "#     pipeline = PMMLPipeline([\n",
    "#         (\"regressor\", DecisionTreeRegressor())  # Verwende DecisionTreeRegressor\n",
    "#     ])\n",
    "#     pipeline.fit(X, y)\n",
    "\n",
    "#     # Modell in PMML-Datei speichern\n",
    "#     sklearn2pmml(pipeline, pmml_file_path, with_repr=True)\n",
    "#     print(f\"Modell erfolgreich gespeichert als {pmml_file_path}.\")\n",
    "\n",
    "# # Schritt 2: Modell laden\n",
    "# def load_model(file_path):\n",
    "#     try:\n",
    "#         evaluator = make_evaluator(file_path)\n",
    "#         evaluator.verify()  # Überprüfen des Modells\n",
    "#         print(\"Modell erfolgreich geladen mit jpmml-evaluator.\")\n",
    "#         return evaluator\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden des PMML-Modells mit jpmml-evaluator: {e}\")\n",
    "#     return None\n",
    "\n",
    "# # Schritt 3: Modell verwenden, um Vorhersagen zu machen\n",
    "# def make_predictions(evaluator):\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "#     # Umwandeln der kategorischen Variablen in Dummy-Variablen\n",
    "#     data = pd.get_dummies(data)\n",
    "\n",
    "#     # Vorhersagen durchführen\n",
    "#     predictions = evaluator.evaluate(data.to_dict(orient='records'))  # Daten ins Dictionary umwandeln\n",
    "\n",
    "#     # Die Ergebnisse hier direkt verwenden\n",
    "#     print(\"Vorhersagen:\", predictions)  # Vorhersagen ausgeben\n",
    "\n",
    "# # Hauptlogik\n",
    "# if __name__ == \"__main__\":\n",
    "#     train_and_save_model()  # Trainiere und speichere das Modell\n",
    "#     loaded_model = load_model(pmml_file_path)  # Lade das Modell\n",
    "\n",
    "#     if loaded_model is not None:\n",
    "#         make_predictions(loaded_model)  # Mache Vorhersagen\n",
    "#     else:\n",
    "#         print(\"Das Modell konnte nicht geladen werden.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from jpmml_evaluator import make_evaluator\n",
    "# from xgrove import grove  # Importiere die Grove-Klasse aus dem xgrove Paket\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Setze den Pfad für Graphviz\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "\n",
    "# def debug_model_loading(pmml_file_path):\n",
    "#     \"\"\"Versucht, das PMML-Modell zu laden und zu validieren.\"\"\"\n",
    "#     try:\n",
    "#         evaluator = make_evaluator(pmml_file_path)\n",
    "#         evaluator.verify()\n",
    "#         print(\"PMML-Modell erfolgreich geladen und verifiziert.\")\n",
    "#         return evaluator\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden des PMML-Modells: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def debug_data_loading(csv_file_path):\n",
    "#     \"\"\"Lädt die CSV-Daten und gibt eine Warnung, falls NaN-Werte vorhanden sind.\"\"\"\n",
    "#     try:\n",
    "#         data = pd.read_csv(csv_file_path)\n",
    "#         print(f\"Daten erfolgreich geladen: {data.head()}\")\n",
    "        \n",
    "#         # Überprüfen auf NaN-Werte und leere Strings\n",
    "#         print(f\"NaN-Werte in den Daten: {data.isna().sum()}\")\n",
    "#         print(f\"Leere Strings in den Daten: {(data == '').sum()}\")\n",
    "        \n",
    "#         # Entferne NaN-Werte\n",
    "#         if data.isna().sum().sum() > 0:\n",
    "#             print(\"Warnung: Es gibt NaN-Werte in den Eingabedaten. Diese werden entfernt.\")\n",
    "#             data = data.dropna()\n",
    "        \n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden der CSV-Datei: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def preprocess_data(data):\n",
    "#     \"\"\"Bereitet die Eingabedaten vor, indem sie skaliert werden, wenn nötig.\"\"\"\n",
    "#     # Überprüfen auf NaN-Werte nach Entfernen\n",
    "#     print(f\"Datenform nach NaN-Entfernung: {data.shape}\")\n",
    "\n",
    "#     # Skalierung der Daten, falls notwendig\n",
    "#     scaler = StandardScaler()\n",
    "#     data_scaled = data.copy()\n",
    "#     data_scaled['x'] = scaler.fit_transform(data[['x']])\n",
    "\n",
    "#     return data_scaled\n",
    "\n",
    "# def load_and_evaluate_model(pmml_file_path, csv_file_path):\n",
    "#     \"\"\"Lädt das PMML-Modell und erstellt ein Surrogat-Modell mit xgrove.\"\"\"\n",
    "    \n",
    "#     # 1. Lade die Trainingsdaten\n",
    "#     data = debug_data_loading(csv_file_path)\n",
    "#     if data is None:\n",
    "#         return\n",
    "\n",
    "#     # 2. Preprocessiere die Daten\n",
    "#     data = preprocess_data(data)\n",
    "\n",
    "#     # 3. Lade das PMML-Modell\n",
    "#     evaluator = debug_model_loading(pmml_file_path)\n",
    "#     if evaluator is None:\n",
    "#         return\n",
    "\n",
    "#     # 4. Generiere Surrogat-Zielwerte für die Daten\n",
    "#     surrogate_targets = []\n",
    "#     for i, row in data.iterrows():\n",
    "#         input_data = row.to_dict()  # Erstelle ein Dictionary für eine Zeile\n",
    "#         prediction = evaluator.evaluate(input_data)  # Einzeldatensatz bewerten\n",
    "#         surrogate_targets.append(prediction.get('Predicted_y', None))  # Nutze den Rückgabeschlüssel des Modells\n",
    "#         if i % 10 == 0:  # Debugging: Zeige alle 10 Zeilen\n",
    "#             print(f\"Verarbeite Zeile {i+1}/{len(data)}\")\n",
    "\n",
    "#     # 5. Überprüfe auf NaN-Werte in den Surrogat-Zielwerten\n",
    "#     print(\"Überprüfe auf NaN-Werte in den Surrogat-Zielwerten...\")\n",
    "#     surrogate_targets = [val for val in surrogate_targets if val is not None]  # Entferne NaN-Werte\n",
    "#     print(f\"Anzahl der gültigen Surrogat-Zielwerte: {len(surrogate_targets)}\")\n",
    "\n",
    "#     # Wenn nach der Bereinigung keine Surrogat-Zielwerte übrig sind, einen Fehler werfen\n",
    "#     if not surrogate_targets:\n",
    "#         raise ValueError(\"Fehler beim Erstellen der Surrogat-Zielwerte: Keine gültigen Zielwerte vorhanden.\")\n",
    "    \n",
    "#     # Surrogat-Targets in den DataFrame aufnehmen\n",
    "#     data['surrogatetarget'] = surrogate_targets\n",
    "#     print(f\"Surrogat-Zielwerte wurden erfolgreich zum Datensatz hinzugefügt. Datenform: {data.shape}\")\n",
    "\n",
    "#     # 6. Instanziiere die Grove-Klasse mit Surrogat-Targets und dem Modell\n",
    "#     grove_model = grove(model=evaluator, data=data, trained=True)\n",
    "    \n",
    "#     # Berechnung des Surrogat-Modells durchführen\n",
    "#     grove_model.calculateGrove()\n",
    "\n",
    "#     print(\"Berechnungen abgeschlossen.\")\n",
    "#     print(grove_model.get_result())\n",
    "\n",
    "#     # 7. Zusätzliche Modellattribute anzeigen (falls vorhanden)\n",
    "#     model_classes = evaluator.getModelClasses()  # Modellklassen, falls definiert\n",
    "#     print(f\"Model Klassen: {model_classes}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Definiere die Datei- und CSV-Pfade\n",
    "#     pmml_file_path = '../models/linear_model.pmml'\n",
    "#     csv_file_path = '../models/generated_data.csv'\n",
    "\n",
    "#     # Führe das Modell aus\n",
    "#     load_and_evaluate_model(pmml_file_path, csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pypmml import Model\n",
    "\n",
    "# # Lade das PMML-Modell\n",
    "# loaded_model = Model.load(\"random_forest_model.pmml\")\n",
    "\n",
    "# # Beispiel für eine Vorhersage\n",
    "# # Erstelle Beispiel-Daten als DataFrame\n",
    "# import pandas as pd\n",
    "# sample_data = pd.DataFrame({\n",
    "#     \"Sepal.Width\": [3.5],\n",
    "#     \"Petal.Length\": [1.4],\n",
    "#     \"Petal.Width\": [0.2],\n",
    "#     \"Species\": [\"setosa\"]\n",
    "# })\n",
    "\n",
    "# # Vorhersage\n",
    "# predictions = loaded_model.predict(sample_data)\n",
    "# print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# data = pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6]})\n",
    "# print(data.isna().sum())  # Zeigt dir die Anzahl der fehlenden Werte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lxml import etree\n",
    "\n",
    "# # Funktion zur Vorhersage basierend auf der Baumstruktur aus der XML-Datei\n",
    "# def predict_random_forest_from_xml(x_input, xml_tree):\n",
    "#     \"\"\"Trifft Vorhersage basierend auf einem Random Forest-Modell aus einer XML-Datei\"\"\"\n",
    "#     # Extrahiere alle Bäume (falls vorhanden)\n",
    "#     models = xml_tree.findall(\".//TreeModel\", namespaces=namespaces)\n",
    "\n",
    "#     # Liste zur Speicherung der Vorhersagen für jeden Baum\n",
    "#     predictions = []\n",
    "    \n",
    "#     for model in models:\n",
    "#         try:\n",
    "#             # Durchlaufe die Baumstruktur des aktuellen Baums\n",
    "#             prediction = traverse_tree_for_prediction(model, x_input)\n",
    "#             predictions.append(prediction)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Fehler beim Durchlaufen des Baums: {e}\")\n",
    "\n",
    "#     # Debug-Ausgabe der Vorhersagen\n",
    "#     print(f\"Vorhersagen von allen Bäumen: {predictions}\")\n",
    "    \n",
    "#     # Durchschnitt der Vorhersagen (für Regression) oder Mehrheitsvotum (für Klassifikation)\n",
    "#     if len(predictions) > 0:\n",
    "#         if len(set(predictions)) == 1:\n",
    "#             return predictions[0]  # Wenn alle Bäume dasselbe vorhersagen, gebe das Ergebnis zurück\n",
    "#         else:\n",
    "#             return max(set(predictions), key=predictions.count)  # Mehrheitsvotum für Klassifikation\n",
    "#     else:\n",
    "#         raise ValueError(\"Keine Vorhersagen von den Bäumen erhalten.\")\n",
    "\n",
    "# def traverse_tree_for_prediction(tree_model, x_input):\n",
    "#     \"\"\"Durchlaufe einen einzelnen Entscheidungsbaum und triff Vorhersage\"\"\"\n",
    "#     # Suche nach den Knoten des Entscheidungsbaums\n",
    "#     nodes = tree_model.findall(\".//Node\", namespaces=namespaces)\n",
    "    \n",
    "#     # Wenn keine Knoten vorhanden sind, dann gibt es ein Problem mit der Baumstruktur\n",
    "#     if not nodes:\n",
    "#         raise ValueError(\"Der Entscheidungsbaum enthält keine Knoten.\")\n",
    "    \n",
    "#     # Der erste Knoten ist immer die Wurzel\n",
    "#     current_node = nodes[0]\n",
    "    \n",
    "#     # Durchlaufe die Baumstruktur und gebe alle Knoten aus, um den Baum zu analysieren\n",
    "#     print(\"Baumstruktur:\")\n",
    "#     for node in nodes:\n",
    "#         print(node.attrib)\n",
    "    \n",
    "#     while True:\n",
    "#         # Hole die Bedingungen des aktuellen Knotens (if-Bedingung)\n",
    "#         if_condition = current_node.find(\".//True//SimplePredicate\", namespaces=namespaces)\n",
    "        \n",
    "#         if if_condition is not None:\n",
    "#             # Extrahiere die Bedingung und den Wert\n",
    "#             field = if_condition.attrib['field']\n",
    "#             value = float(if_condition.attrib['value'])\n",
    "            \n",
    "#             # Bestimme den Zweig des Baumes basierend auf der Bedingung\n",
    "#             if x_input <= value:\n",
    "#                 next_node_id = current_node.attrib['trueBranch']\n",
    "#             else:\n",
    "#                 next_node_id = current_node.attrib['falseBranch']\n",
    "#         else:\n",
    "#             # Wenn kein 'True'-Element gefunden wird, ist dies ein Blattknoten (Vorhersage)\n",
    "#             print(\"Blattknoten gefunden:\", current_node.attrib)  # Debug: Ausgabe der Attribute des Blattknotens\n",
    "            \n",
    "#             # Untersuche die Attribute des Blattknotens, um den Vorhersagewert zu finden\n",
    "#             if 'score' in current_node.attrib:\n",
    "#                 return int(current_node.attrib['score'])  # Verwende 'score' als Vorhersage (0 oder 1)\n",
    "#             else:\n",
    "#                 # Dies ist der Fall, wenn der Blattknoten keine Vorhersage enthält\n",
    "#                 raise ValueError(f\"Unklarer Blattknoten gefunden ohne Vorhersage-Attribut. Knoten: {current_node.attrib}\")\n",
    "        \n",
    "#         # Finde den nächsten Knoten\n",
    "#         next_node = next((node for node in nodes if node.attrib['id'] == next_node_id), None)\n",
    "        \n",
    "#         if next_node is None:\n",
    "#             raise ValueError(f\"Fehler: Der nächste Knoten (ID: {next_node_id}) konnte nicht gefunden werden.\")\n",
    "        \n",
    "#         current_node = next_node\n",
    "\n",
    "# # Lade die XML-Datei (Aktueller Pfad zu deiner Datei)\n",
    "# xml_file_path = \"../models/random_forest_model_pmml.xml\"  # Der tatsächliche Pfad zur XML-Datei\n",
    "# tree = etree.parse(xml_file_path)\n",
    "# root = tree.getroot()\n",
    "\n",
    "# # Definiere den Namensraum für XPath\n",
    "# namespaces = {\n",
    "#     'pmml': 'http://www.dmg.org/PMML-4_4'\n",
    "# }\n",
    "\n",
    "# # Extrahiere den Modelltyp\n",
    "# model_type = root.find(\".//pmml:MiningModel\", namespaces=namespaces)\n",
    "# if model_type is not None:\n",
    "#     print(f\"Modelltyp: {model_type.attrib.get('functionName')}\")\n",
    "\n",
    "# # Extrahiere die Eingabefelder aus dem XML\n",
    "# input_fields = root.findall(\".//pmml:DataField\", namespaces=namespaces)\n",
    "# print(\"Eingabefelder:\", [field.attrib.get('name') for field in input_fields])\n",
    "\n",
    "# # Extrahiere die Zielvariable aus dem MiningSchema\n",
    "# target_field = root.xpath(\".//pmml:MiningSchema/pmml:MiningField[@usageType='predicted']\", namespaces=namespaces)\n",
    "# if target_field:\n",
    "#     print(f\"Zielvariable: {target_field[0].attrib.get('name')}\")\n",
    "# else:\n",
    "#     print(\"Zielvariable nicht gefunden.\")\n",
    "\n",
    "# # Beispiel Vorhersage für eine Eingabe (z.B. x = 30)\n",
    "# x_input = 30\n",
    "# try:\n",
    "#     prediction = predict_random_forest_from_xml(x_input, root)\n",
    "#     print(f\"Vorhersage für x = {x_input}: Klasse {prediction}\")\n",
    "# except ValueError as e:\n",
    "#     print(f\"Fehler bei der Vorhersage: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lxml import etree\n",
    "\n",
    "# # Funktion zur Vorhersage basierend auf der Baumstruktur aus der PMML-Datei\n",
    "# def predict_random_forest_from_pmml(x_input, pmml_tree):\n",
    "#     \"\"\"Trifft Vorhersage basierend auf einem Random Forest-Modell aus PMML\"\"\"\n",
    "#     # Extrahiere alle Bäume (falls vorhanden)\n",
    "#     models = pmml_tree.findall(\".//pmml:TreeModel\", namespaces=namespaces)\n",
    "\n",
    "#     # Liste zur Speicherung der Vorhersagen für jeden Baum\n",
    "#     predictions = []\n",
    "    \n",
    "#     for model in models:\n",
    "#         # Durchlaufe die Baumstruktur des aktuellen Baums\n",
    "#         prediction = traverse_tree_for_prediction(model, x_input)\n",
    "#         predictions.append(prediction)\n",
    "    \n",
    "#     # Durchschnitt der Vorhersagen (für Regression) oder Mehrheitsvotum (für Klassifikation)\n",
    "#     if len(set(predictions)) == 1:\n",
    "#         return predictions[0]  # Wenn alle Bäume dasselbe vorhersagen, gebe das Ergebnis zurück\n",
    "#     else:\n",
    "#         return max(set(predictions), key=predictions.count)  # Mehrheitsvotum für Klassifikation\n",
    "\n",
    "# def traverse_tree_for_prediction(tree_model, x_input):\n",
    "#     \"\"\"Durchlaufe einen einzelnen Entscheidungsbaum und triff Vorhersage\"\"\"\n",
    "#     # Suche nach den Knoten des Entscheidungsbaums\n",
    "#     nodes = tree_model.findall(\".//pmml:Node\", namespaces=namespaces)\n",
    "    \n",
    "#     # Der erste Knoten ist immer die Wurzel\n",
    "#     current_node = nodes[0]\n",
    "    \n",
    "#     # Durchlaufe die Baumstruktur und gebe alle Knoten aus, um den Baum zu analysieren\n",
    "#     print(\"Baumstruktur:\")\n",
    "#     for node in nodes:\n",
    "#         print(node.attrib)\n",
    "    \n",
    "#     while True:\n",
    "#         # Hole die Bedingungen des aktuellen Knotens (if-Bedingung)\n",
    "#         if_condition = current_node.find(\".//pmml:True/pmml:SimplePredicate\", namespaces=namespaces)\n",
    "        \n",
    "#         if if_condition is not None:\n",
    "#             # Extrahiere die Bedingung und den Wert\n",
    "#             field = if_condition.attrib['field']\n",
    "#             value = float(if_condition.attrib['value'])\n",
    "            \n",
    "#             # Bestimme den Zweig des Baumes basierend auf der Bedingung\n",
    "#             if x_input <= value:\n",
    "#                 next_node_id = current_node.attrib['trueBranch']\n",
    "#             else:\n",
    "#                 next_node_id = current_node.attrib['falseBranch']\n",
    "#         else:\n",
    "#             # Wenn kein 'True'-Element gefunden wird, ist dies ein Blattknoten (Vorhersage)\n",
    "#             print(\"Blattknoten gefunden:\", current_node.attrib)  # Debug: Ausgabe der Attribute des Blattknotens\n",
    "            \n",
    "#             # Untersuche die Attribute des Blattknotens, um den Vorhersagewert zu finden\n",
    "#             score = current_node.attrib.get('score', None)\n",
    "            \n",
    "#             if score is not None:\n",
    "#                 return int(score)  # Verwende 'score' als Vorhersage (0 oder 1)\n",
    "#             else:\n",
    "#                 # Falls der Blattknoten keinen 'score' hat, gehe davon aus, dass er ein innerer Knoten ist\n",
    "#                 print(f\"Blattknoten ohne 'score' gefunden (ID: {current_node.attrib['id']}). Weiter mit nächstem Knoten.\")\n",
    "#                 # Gehe zur nächsten Node, falls keine Vorhersage im aktuellen Knoten\n",
    "#                 next_node_id = current_node.attrib.get('trueBranch', None) or current_node.attrib.get('falseBranch', None)\n",
    "#                 if next_node_id:\n",
    "#                     # Suche den nächsten Knoten\n",
    "#                     current_node = next((node for node in nodes if node.attrib['id'] == next_node_id), None)\n",
    "#                     continue\n",
    "#                 else:\n",
    "#                     raise ValueError(f\"Kein gültiger 'trueBranch' oder 'falseBranch' im Blattknoten gefunden. Knoten: {current_node.attrib}\")\n",
    "\n",
    "#         # Finde den nächsten Knoten\n",
    "#         next_node = next((node for node in nodes if node.attrib['id'] == next_node_id), None)\n",
    "        \n",
    "#         if next_node is None:\n",
    "#             raise ValueError(f\"Fehler: Der nächste Knoten (ID: {next_node_id}) konnte nicht gefunden werden.\")\n",
    "        \n",
    "#         current_node = next_node\n",
    "\n",
    "# # Lade die PMML-Datei\n",
    "# pmml_file_path = \"models/random_forest_model_pmml.xml\"  # Der tatsächliche Pfad zur XML-Datei\n",
    "# tree = etree.parse(pmml_file_path)\n",
    "# root = tree.getroot()\n",
    "\n",
    "# # Definiere den Namensraum für XPath\n",
    "# namespaces = {\n",
    "#     'pmml': 'http://www.dmg.org/PMML-4_4'\n",
    "# }\n",
    "\n",
    "# # Extrahiere den Modelltyp\n",
    "# model_type = root.find(\".//pmml:MiningModel\", namespaces=namespaces)\n",
    "# if model_type is not None:\n",
    "#     print(f\"Modelltyp: {model_type.attrib.get('functionName')}\")\n",
    "\n",
    "# # Extrahiere die Eingabefelder aus dem XML\n",
    "# input_fields = root.findall(\".//pmml:DataField\", namespaces=namespaces)\n",
    "# print(\"Eingabefelder:\", [field.attrib.get('name') for field in input_fields])\n",
    "\n",
    "# # Extrahiere die Zielvariable aus dem MiningSchema\n",
    "# target_field = root.xpath(\".//pmml:MiningSchema/pmml:MiningField[@usageType='predicted']\", namespaces=namespaces)\n",
    "# if target_field:\n",
    "#     print(f\"Zielvariable: {target_field[0].attrib.get('name')}\")\n",
    "# else:\n",
    "#     print(\"Zielvariable nicht gefunden.\")\n",
    "\n",
    "# # Beispiel Vorhersage für eine Eingabe (z.B. x = 30)\n",
    "# x_input = 30\n",
    "# prediction = predict_random_forest_from_pmml(x_input, root)\n",
    "# print(f\"Vorhersage für x = {x_input}: Klasse {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from pypmml import Model  # Verwenden von pypmml\n",
    "\n",
    "# # Definiere den PMML-Dateipfad\n",
    "# pmml_path = \"../models/linear_model.pmml\"\n",
    "\n",
    "# # Lade das trainierte PMML-Modell (aus R gespeichert)\n",
    "# pmml_model = Model.load(pmml_path)  # Laden des trainierten Modells\n",
    "\n",
    "# # Neue Eingabedaten (die für die Vorhersagen verwendet werden)\n",
    "# input_data = pd.DataFrame({\n",
    "#     'Feature1': [0.5, -1.2, 0.3],\n",
    "#     'Feature2': [1.1, -0.8, 0.2]\n",
    "# })\n",
    "\n",
    "# # Vorhersagen machen\n",
    "# predictions = pmml_model.predict(input_data)\n",
    "\n",
    "# # Zeige die Vorhersagen an\n",
    "# print(f\"Vorhersagen: {predictions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Beispiel DataFrame mit zufälligen Werten\n",
    "# np.random.seed(42)\n",
    "# data = {\n",
    "#     'variable': np.random.choice(['Feature1', 'Feature2'], size=100),  # 'Feature1' oder 'Feature2'\n",
    "#     'upper_bound_left': np.random.uniform(-2, 2, size=100).round(2),  # Zufällige Werte für upper_bound_left\n",
    "#     'levels_left': [None] * 100,  # Alle Werte auf None gesetzt\n",
    "#     'pleft': np.random.uniform(-1, 1, size=100),  # Zufällige Werte für pleft\n",
    "#     'pright': np.random.uniform(-1, 1, size=100)  # Zufällige Werte für pright\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # Überprüfen auf NaN-Werte\n",
    "# print(f\"NaN counts in df before grouping:\\n{df.isna().sum()}\")\n",
    "\n",
    "# # Entfernen von NaN-Werten (falls nötig)\n",
    "# df_cleaned = df.dropna(subset=['variable', 'upper_bound_left', 'pleft', 'pright'])\n",
    "\n",
    "# # Gruppieren nach den Spalten 'variable', 'upper_bound_left' und 'levels_left'\n",
    "# # Dann berechnen wir die Summe von 'pleft' und 'pright' für jede Gruppe\n",
    "# # Setze 'levels_left' auf einen sinnvollen Standardwert (z. B. \"default\")\n",
    "# df['levels_left'] = df['levels_left'].fillna('default')\n",
    "\n",
    "# # Gruppieren nach 'variable', 'upper_bound_left' und 'levels_left'\n",
    "# df_grouped = df.groupby(['variable', 'upper_bound_left', 'levels_left'], as_index=False).agg({\n",
    "#     'pleft': 'sum',\n",
    "#     'pright': 'sum'\n",
    "# })\n",
    "\n",
    "# # Ergebnis anzeigen\n",
    "# print(df_grouped.head())\n",
    "\n",
    "\n",
    "# # Ergebnis anzeigen\n",
    "# print(df_grouped.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from jpmml_evaluator import make_evaluator\n",
    "# from xgrove import grove\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Setze den Pfad für Graphviz\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "\n",
    "# def debug_model_loading(pmml_file_path):\n",
    "#     \"\"\"Versucht, das PMML-Modell zu laden und zu validieren.\"\"\"\n",
    "#     try:\n",
    "#         evaluator = make_evaluator(pmml_file_path)\n",
    "#         evaluator.verify()\n",
    "#         print(\"PMML-Modell erfolgreich geladen und verifiziert.\")\n",
    "#         return evaluator\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden des PMML-Modells: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def debug_data_loading(csv_file_path):\n",
    "#     \"\"\"Lädt die CSV-Daten und gibt eine Warnung, falls NaN-Werte vorhanden sind.\"\"\"\n",
    "#     try:\n",
    "#         data = pd.read_csv(csv_file_path)\n",
    "#         print(f\"Daten erfolgreich geladen: {data.head()}\")\n",
    "        \n",
    "#         # Überprüfen auf NaN-Werte und leere Strings\n",
    "#         print(f\"NaN-Werte in den Daten: {data.isna().sum()}\")\n",
    "#         print(f\"Leere Strings in den Daten: {(data == '').sum()}\")\n",
    "        \n",
    "#         # Entferne NaN-Werte\n",
    "#         if data.isna().sum().sum() > 0:\n",
    "#             print(\"Warnung: Es gibt NaN-Werte in den Eingabedaten. Diese werden entfernt.\")\n",
    "#             data = data.dropna()\n",
    "        \n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden der CSV-Datei: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def preprocess_data(data):\n",
    "#     \"\"\"Bereitet die Eingabedaten vor, indem sie skaliert werden, wenn nötig.\"\"\"\n",
    "#     print(f\"Datenform nach NaN-Entfernung: {data.shape}\")\n",
    "\n",
    "#     # Skalierung der Daten, falls notwendig\n",
    "#     scaler = StandardScaler()\n",
    "#     data_scaled = data.copy()\n",
    "#     features = data.columns  # Hier wird davon ausgegangen, dass alle Spalten skaliert werden müssen.\n",
    "#     data_scaled[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "#     return data_scaled\n",
    "\n",
    "# def load_and_evaluate_model(pmml_file_path, csv_file_path):\n",
    "#     \"\"\"Lädt das PMML-Modell und erstellt ein Surrogat-Modell mit xgrove.\"\"\"\n",
    "    \n",
    "#     # 1. Lade die Trainingsdaten\n",
    "#     data = debug_data_loading(csv_file_path)\n",
    "#     if data is None:\n",
    "#         return\n",
    "\n",
    "#     # 2. Preprocessiere die Daten\n",
    "#     data = preprocess_data(data)\n",
    "\n",
    "#     # 3. Lade das PMML-Modell\n",
    "#     evaluator = debug_model_loading(pmml_file_path)\n",
    "#     if evaluator is None:\n",
    "#         return\n",
    "\n",
    "#     # 4. Generiere Surrogat-Zielwerte für die Daten\n",
    "#     surrogate_targets = []\n",
    "#     for i, row in data.iterrows():\n",
    "#         input_data = row.to_dict()  # Erstelle ein Dictionary für eine Zeile\n",
    "#         prediction = evaluator.evaluate(input_data)  # Einzeldatensatz bewerten\n",
    "#         surrogate_targets.append(prediction.get('Predicted_y', None))  # Nutze den Rückgabeschlüssel des Modells\n",
    "#         if i % 10 == 0:  # Debugging: Zeige alle 10 Zeilen\n",
    "#             print(f\"Verarbeite Zeile {i+1}/{len(data)}\")\n",
    "\n",
    "#     # 5. Überprüfe auf NaN-Werte in den Surrogat-Zielwerten\n",
    "#     print(\"Überprüfe auf NaN-Werte in den Surrogat-Zielwerten...\")\n",
    "#     surrogate_targets = [val for val in surrogate_targets if val is not None]  # Entferne NaN-Werte\n",
    "#     print(f\"Anzahl der gültigen Surrogat-Zielwerte: {len(surrogate_targets)}\")\n",
    "\n",
    "#     # Wenn nach der Bereinigung keine Surrogat-Zielwerte übrig sind, einen Fehler werfen\n",
    "#     if not surrogate_targets:\n",
    "#         raise ValueError(\"Fehler beim Erstellen der Surrogat-Zielwerte: Keine gültigen Zielwerte vorhanden.\")\n",
    "    \n",
    "#     # Surrogat-Targets in den DataFrame aufnehmen\n",
    "#     data['surrogatetarget'] = surrogate_targets\n",
    "#     print(f\"Surrogat-Zielwerte wurden erfolgreich zum Datensatz hinzugefügt. Datenform: {data.shape}\")\n",
    "\n",
    "#     # 6. Instanziiere die Grove-Klasse mit Surrogat-Targets und dem Modell\n",
    "#     grove_model = grove(model=evaluator, data=data, trained=True)\n",
    "    \n",
    "#     # Berechnung des Surrogat-Modells durchführen\n",
    "#     grove_model.calculateGrove()\n",
    "\n",
    "#     print(\"Berechnungen abgeschlossen.\")\n",
    "#     print(grove_model.get_result())\n",
    "\n",
    "#     # 7. Zusätzliche Modellattribute anzeigen (falls vorhanden)\n",
    "#     model_classes = evaluator.getModelClasses()  # Modellklassen, falls definiert\n",
    "#     print(f\"Model Klassen: {model_classes}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Definiere die Datei- und CSV-Pfade\n",
    "#     pmml_file_path = '../models/linear_model.pmml'\n",
    "#     csv_file_path = '../models/generated_data.csv'\n",
    "\n",
    "#     # Führe das Modell aus\n",
    "#     load_and_evaluate_model(pmml_file_path, csv_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
