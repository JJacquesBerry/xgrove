{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten geladen:\n",
      "   Feature1  Feature2  Target\n",
      "0        48        72      48\n",
      "1       100        84      60\n",
      "2        64        42       0\n",
      "3        24        57      16\n",
      "4        73        71      32\n",
      "Die Vorhersagen wurden erfolgreich zu 'predictions.csv' hinzugef√ºgt.\n",
      "df_small grouped:    variable  upper_bound_left levels_left   pleft  pright\n",
      "0  Feature1              22.0     default -1.2246  0.4082\n",
      "1  Feature1              58.0     default -1.4405  2.2532\n",
      "2  Feature2              60.5     default  0.4030 -0.6304\n",
      "df_small grouped:    variable  upper_bound_left levels_left   pleft  pright\n",
      "0  Feature1               6.0     default -0.6433  0.0795\n",
      "1  Feature1              22.0     default -1.2246  0.4082\n",
      "2  Feature1              37.5     default -0.3196  0.2315\n",
      "3  Feature1              58.0     default -1.2261  1.9179\n",
      "4  Feature1              90.5     default -0.1635  0.7984\n",
      "5  Feature2              60.5     default  0.4030 -0.6304\n",
      "df_small grouped:    variable  upper_bound_left levels_left   pleft  pright\n",
      "0  Feature1               6.0     default -0.6433  0.0795\n",
      "1  Feature1              22.0     default -0.9762  0.3254\n",
      "2  Feature1              30.0     default -0.1482  0.0798\n",
      "3  Feature1              37.5     default -0.3196  0.2315\n",
      "4  Feature1              40.5     default -0.1499  0.1226\n",
      "5  Feature1              58.0     default -0.8594  1.3444\n",
      "6  Feature1              77.0     default -0.1170  0.2865\n",
      "7  Feature1              90.5     default -0.1635  0.7984\n",
      "8  Feature2              28.5     default  0.2509 -0.0928\n",
      "9  Feature2              60.5     default  0.4030 -0.6304\n",
      "df_small grouped:     variable  upper_bound_left levels_left   pleft  pright\n",
      "0   Feature1               6.0     default -0.6433  0.0795\n",
      "1   Feature1              13.0     default -0.1576  0.0278\n",
      "2   Feature1              22.0     default -0.6450  0.2150\n",
      "3   Feature1              30.0     default -0.2516  0.1355\n",
      "4   Feature1              37.5     default -0.3196  0.2315\n",
      "5   Feature1              40.5     default -0.2054  0.1680\n",
      "6   Feature1              44.0     default -0.1021  0.0942\n",
      "7   Feature1              58.0     default -0.6919  1.0825\n",
      "8   Feature1              77.0     default -0.1925  0.4713\n",
      "9   Feature1              90.5     default -0.1635  0.7984\n",
      "10  Feature1              96.5     default -0.0188  0.1696\n",
      "11  Feature2              12.5     default  0.1934 -0.0239\n",
      "12  Feature2              28.5     default  0.2509 -0.0928\n",
      "13  Feature2              59.5     default -0.1102  0.1652\n",
      "14  Feature2              60.5     default  0.4030 -0.6304\n",
      "15  Feature2              87.5     default  0.0460 -0.2606\n",
      "df_small grouped:     variable  upper_bound_left levels_left   pleft  pright\n",
      "0   Feature1               6.0     default -0.6433  0.0795\n",
      "1   Feature1              13.0     default -0.1576  0.0278\n",
      "2   Feature1              14.5     default -0.0858  0.0163\n",
      "3   Feature1              16.0     default -0.0499  0.0102\n",
      "4   Feature1              22.0     default -0.4599  0.1533\n",
      "5   Feature1              24.5     default -0.0390  0.0159\n",
      "6   Feature1              27.0     default -0.0474  0.0223\n",
      "7   Feature1              30.0     default -0.2516  0.1355\n",
      "8   Feature1              37.5     default -0.3196  0.2315\n",
      "9   Feature1              40.5     default -0.2054  0.1680\n",
      "10  Feature1              44.0     default -0.1395  0.1288\n",
      "11  Feature1              50.5     default -0.0636  0.0748\n",
      "12  Feature1              58.0     default -0.5148  0.8054\n",
      "13  Feature1              71.0     default -0.0475  0.1010\n",
      "14  Feature1              72.5     default -0.0236  0.0526\n",
      "15  Feature1              77.0     default -0.2178  0.5333\n",
      "16  Feature1              81.5     default -0.0369  0.1051\n",
      "17  Feature1              85.5     default -0.0144  0.0510\n",
      "18  Feature1              90.5     default -0.1157  0.5646\n",
      "19  Feature1              95.0     default -0.0101  0.0817\n",
      "20  Feature1              96.5     default -0.0188  0.1696\n",
      "21  Feature2              12.5     default  0.1934 -0.0239\n",
      "22  Feature2              28.5     default  0.2509 -0.0928\n",
      "23  Feature2              35.0     default  0.0508 -0.0286\n",
      "24  Feature2              48.5     default  0.0469 -0.0451\n",
      "25  Feature2              59.5     default -0.1102  0.1652\n",
      "26  Feature2              60.5     default  0.3441 -0.5382\n",
      "27  Feature2              81.5     default  0.0188 -0.0753\n",
      "28  Feature2              87.5     default  0.0460 -0.2606\n",
      "df_small grouped:     variable  upper_bound_left levels_left   pleft  pright\n",
      "0   Feature1               6.0     default -0.5644  0.0698\n",
      "1   Feature1               8.5     default -0.0298  0.0045\n",
      "2   Feature1              13.0     default -0.1926  0.0340\n",
      "3   Feature1              14.5     default -0.0858  0.0163\n",
      "4   Feature1              16.0     default -0.0499  0.0102\n",
      "5   Feature1              18.0     default -0.0886  0.0236\n",
      "6   Feature1              22.0     default -0.3227  0.1076\n",
      "7   Feature1              24.5     default -0.0893  0.0364\n",
      "8   Feature1              27.0     default -0.0474  0.0223\n",
      "9   Feature1              30.0     default -0.2516  0.1355\n",
      "10  Feature1              37.5     default -0.3196  0.2315\n",
      "11  Feature1              40.5     default -0.2054  0.1680\n",
      "12  Feature1              44.0     default -0.1395  0.1288\n",
      "13  Feature1              50.5     default -0.0768  0.0903\n",
      "14  Feature1              52.5     default -0.0168  0.0206\n",
      "15  Feature1              53.5     default -0.0218  0.0277\n",
      "16  Feature1              58.0     default -0.3692  0.5779\n",
      "17  Feature1              65.5     default -0.0638  0.1085\n",
      "18  Feature1              67.5     default -0.0160  0.0284\n",
      "19  Feature1              71.0     default -0.0475  0.1010\n",
      "20  Feature1              72.5     default -0.0236  0.0526\n",
      "21  Feature1              77.0     default -0.2178  0.5333\n",
      "22  Feature1              81.5     default -0.0369  0.1051\n",
      "23  Feature1              84.0     default -0.0163  0.0546\n",
      "24  Feature1              85.5     default -0.0144  0.0510\n",
      "25  Feature1              86.5     default -0.0109  0.0409\n",
      "26  Feature1              90.5     default -0.0861  0.4200\n",
      "27  Feature1              91.5     default -0.0056  0.0373\n",
      "28  Feature1              95.0     default -0.0160  0.1295\n",
      "29  Feature1              96.5     default -0.0188  0.1696\n",
      "30  Feature2              12.5     default  0.1934 -0.0239\n",
      "31  Feature2              15.5     default  0.0316 -0.0060\n",
      "32  Feature2              19.5     default  0.0236 -0.0048\n",
      "33  Feature2              28.5     default  0.2509 -0.0928\n",
      "34  Feature2              29.5     default -0.0408  0.0159\n",
      "35  Feature2              33.5     default  0.0128 -0.0069\n",
      "36  Feature2              35.0     default  0.0508 -0.0286\n",
      "37  Feature2              48.5     default  0.1065 -0.1024\n",
      "38  Feature2              59.5     default -0.1102  0.1652\n",
      "39  Feature2              60.5     default  0.2902 -0.4537\n",
      "40  Feature2              61.5     default -0.0396  0.0705\n",
      "41  Feature2              71.5     default  0.0249 -0.0578\n",
      "42  Feature2              78.0     default  0.0135 -0.0428\n",
      "43  Feature2              79.5     default  0.0111 -0.0373\n",
      "44  Feature2              81.5     default  0.0188 -0.0753\n",
      "45  Feature2              87.5     default  0.0460 -0.2606\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ben√∂tigte Bibliotheken importieren\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import xgrove as xg\n",
    "\n",
    "# Schritt 1: CSV-Datei einlesen (Daten aus der bestehenden Datei)\n",
    "data_path = \"../models/generated_data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Anzeige der ersten Zeilen, um sicherzustellen, dass die Daten korrekt geladen wurden\n",
    "print(\"Daten geladen:\")\n",
    "print(data.head())\n",
    "\n",
    "# Schritt 2: Lineares Regressionsmodell erstellen\n",
    "X = data[['Feature1', 'Feature2']]  # Unabh√§ngige Variablen\n",
    "y = data['Target']  # Zielvariable\n",
    "\n",
    "# Modell erstellen und trainieren\n",
    "lm_model = LinearRegression()\n",
    "lm_model.fit(X, y)\n",
    "\n",
    "# Anzeige der Koeffizienten und des Intercepts\n",
    "# print(f\"Koeffizienten: {lm_model.coef_}\")\n",
    "# print(f\"Intercept: {lm_model.intercept_}\")\n",
    "\n",
    "# Schritt 3: Vorhersage mit dem Modell machen\n",
    "predictions_lm_new = lm_model.predict(X)\n",
    "\n",
    "# Die bestehende CSV-Datei einlesen\n",
    "predictions_df = pd.read_csv('../models/predictions.csv', dtype={'predicted_tar_lm': np.float64})\n",
    "\n",
    "# Vorhersagen f√ºr lm_model als neue Spalte hinzuf√ºgen\n",
    "predictions_df['predicted_tar_py'] = predictions_lm_new\n",
    "\n",
    "# Die aktualisierte Datei speichern (anf√ºgen und nicht √ºberschreiben)\n",
    "predictions_df.to_csv('../models/predictions.csv', index=False)  # Maximale Genauigkeit von 16 Dezimalstellen\n",
    "\n",
    "# Best√§tigung der Speicherung\n",
    "print(\"Die Vorhersagen wurden erfolgreich zu 'predictions.csv' hinzugef√ºgt.\")\n",
    "\n",
    "# Schritt 4: Berechnung der durchschnittlichen Abweichung\n",
    "# abweichung = np.mean(np.abs(y - predictions_lm_new))\n",
    "# print(f\"Durchschnittliche Abweichung: {abweichung}\")\n",
    "\n",
    "grove = xg.grove(data = data.drop(\"Target\", axis=1), seed=42, model=lm_model)\n",
    "grove.calculateGrove()\n",
    "grove.get_result()\n",
    "grove.plot_xgrove()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASE: 0.021999999999999985\n",
      "ASE0: 7.760000000000001\n",
      "Upsilon: 0.9971649484536083\n",
      "Correlation: 0.998665120881617\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Simulierte Testdaten\n",
    "surrTar = np.array([3, 2, 7, 8, 1])  # tats√§chliche Zielwerte\n",
    "pexp = np.array([2.8, 2.1, 6.9, 8.1, 1.2])  # Vorhersagen des Modells\n",
    "\n",
    "# Berechnung von ASE und ASE0\n",
    "ASE = np.mean((surrTar - pexp) ** 2)\n",
    "ASE0 = np.mean((surrTar - np.mean(surrTar)) ** 2)\n",
    "\n",
    "# Berechnung von Upsilon\n",
    "upsilon = 1 - ASE / ASE0\n",
    "\n",
    "# Korrelation\n",
    "# correlation = np.corrcoef(surrTar, pexp)[0, 1]\n",
    "correlation, _ = pearsonr(surrTar, pexp)\n",
    "\n",
    "print(f\"ASE: {ASE}\")\n",
    "print(f\"ASE0: {ASE0}\")\n",
    "print(f\"Upsilon: {upsilon}\")\n",
    "print(f\"Correlation: {correlation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from pypmml import Model  # Importiere pypmml f√ºr das Modell\n",
    "# import xgrove.grove as grove\n",
    "\n",
    "# # Definiere den PMML-Dateipfad und den CSV-Datenpfad\n",
    "# pmml_path = \"../models/linear_model.pmml\"\n",
    "# data_path = \"../models/generated_data.csv\"\n",
    "\n",
    "# # Lade das trainierte PMML-Modell (aus R gespeichert)\n",
    "# pmml_model = Model.load(pmml_path)  # Laden des trainierten Modells\n",
    "\n",
    "# # Lade die Eingabedaten aus der CSV-Datei\n",
    "# input_data = pd.read_csv(data_path)\n",
    "\n",
    "# # Entferne die Zielvariable 'Target' aus den Eingabedaten\n",
    "# target = input_data[\"Target\"]\n",
    "# input_data = input_data.drop(columns=[\"Target\"])\n",
    "\n",
    "# # Erstelle ein grove-Objekt mit dem geladenen Modell und den bearbeiteten Eingabedaten\n",
    "# grove_instance = grove(model=pmml_model, \n",
    "#                        data=input_data, \n",
    "#                        b_frac=1,  \n",
    "#                        tar = target, \n",
    "#                        seed=42)\n",
    "\n",
    "# # F√ºhre die Berechnung durch\n",
    "# grove_instance.calculateGrove()\n",
    "\n",
    "# # Beispielwerte der Mittelwerte und Standardabweichungen (ersetzen durch die aus R exportierten Werte)\n",
    "# means_r = [input_data.iloc[0], input_data.iloc[1]]  # Ersetze durch die Mittelwerte der Spalten aus R\n",
    "# sds_r = [input_data.iloc[0], input_data.iloc[1]]     # Ersetze durch die Standardabweichungen der Spalten aus R\n",
    "\n",
    "# # Skalierung der Daten in Python\n",
    "# input_data_scaled = (input_data - means_r) / sds_r\n",
    "\n",
    "# # Ausgabe des Resultats und der Explanation\n",
    "# # print(\"Result:\")\n",
    "# # print(grove_instance.result)\n",
    "\n",
    "# print(\"\\nExplanation:\")\n",
    "# print(grove_instance.explanation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ben√∂tigte Bibliotheken importieren\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # Schritt 1: CSV-Datei einlesen (Daten aus der bestehenden Datei)\n",
    "# data_path = \"../models/generated_data.csv\"\n",
    "# data = pd.read_csv(data_path)\n",
    "\n",
    "# # Anzeige der ersten Zeilen, um sicherzustellen, dass die Daten korrekt geladen wurden\n",
    "# print(\"Daten geladen:\")\n",
    "# print(data.head())\n",
    "\n",
    "# # Schritt 2: Lineares Regressionsmodell erstellen\n",
    "# X = data[['Feature1', 'Feature2']]  # Unabh√§ngige Variablen\n",
    "# y = data['Target']  # Zielvariable\n",
    "\n",
    "# # Modell erstellen und trainieren\n",
    "# lm_model = LinearRegression()\n",
    "# lm_model.fit(X, y)\n",
    "\n",
    "# # Anzeige der Koeffizienten und des Intercepts\n",
    "# print(f\"Koeffizienten: {lm_model.coef_}\")\n",
    "# print(f\"Intercept: {lm_model.intercept_}\")\n",
    "\n",
    "# # Schritt 3: Vorhersage mit dem Modell machen\n",
    "# predictions = lm_model.predict(X)\n",
    "\n",
    "# # Schritt 4: Berechnung der durchschnittlichen Abweichung\n",
    "# abweichung = np.mean(np.abs(y - predictions))\n",
    "# print(f\"Durchschnittliche Abweichung: {abweichung}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import statistics\n",
    "# from xgboost import XGBRegressor, DMatrix\n",
    "# import xgboost as xgb\n",
    "# import json\n",
    "\n",
    "# class grove():\n",
    "#     def __init__(self, \n",
    "#                  model, \n",
    "#                  data: pd.DataFrame,\n",
    "#                  ntrees: np.array = np.array([4, 8, 16, 32, 64, 128]), \n",
    "#                  pfun=None, \n",
    "#                  shrink: float = 1, \n",
    "#                  b_frac: float = 1, \n",
    "#                  seed: int = 42,\n",
    "#                  grove_rate: float = 1,\n",
    "#                  trained: bool = False,\n",
    "#                  tar=None):\n",
    "#         self.model = model\n",
    "#         self.data = self.encodeCategorical(data)\n",
    "#         self.ntrees = ntrees\n",
    "#         self.pfun = pfun\n",
    "#         self.shrink = shrink\n",
    "#         self.b_frac = b_frac\n",
    "#         self.seed = seed\n",
    "#         self.grove_rate = grove_rate\n",
    "#         self.trained = trained\n",
    "#         self.tar = tar\n",
    "#         self.surrTar = self.getSurrogateTarget(pfun=self.pfun, tar=self.tar)\n",
    "#         self.surrGrove = self.getGBM()\n",
    "#         self.predictions = []\n",
    "#         self.explanation = []\n",
    "#         self.groves = []\n",
    "#         self.rules = []\n",
    "#         self.result = []\n",
    "\n",
    "#     def encodeCategorical(self, data):\n",
    "#         categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n",
    "#         return pd.get_dummies(data, columns=categorical_columns)\n",
    "\n",
    "#     def getSurrogateTarget(self, pfun, tar):\n",
    "#         if tar is None:\n",
    "#             return self.model.predict(self.data) if self.pfun is None else pfun(model=self.model, data=self.data)\n",
    "#         else:\n",
    "#             return tar\n",
    "\n",
    "#     def getGBM(self):\n",
    "#         params = {\n",
    "#             'objective': 'reg:squarederror',  # Ziel f√ºr Regression (quadratische Fehler)\n",
    "#             'max_depth': 1,                   # Maximale Baumtiefe\n",
    "#             'eta': self.shrink,               # Lernrate (Shrinkage)\n",
    "#             'eval_metric': 'rmse',            # Evaluierungsmetrik (Root Mean Squared Error)\n",
    "#             'subsample': self.b_frac,         # Anteil der Trainingsdaten, der verwendet wird\n",
    "#             'random_state': self.seed         # Zufallsgenerator-Seed\n",
    "#         }\n",
    "\n",
    "#         # XGBRegressor mit den definierten Parametern\n",
    "#         grove = XGBRegressor(\n",
    "#             n_estimators=int(max(self.ntrees)),  # Anzahl der B√§ume\n",
    "#             **params  # √úbergibt das Dictionary mit den Parametern\n",
    "#         )\n",
    "#         grove.fit(self.data, self.surrTar)\n",
    "\n",
    "        \n",
    "#         # if np.array_equal(np.array(self.surrTar), np.array(self.model.predict(self.data))):\n",
    "#         #     print(\"HALLELUJA ITS THE SAME\")\n",
    "#         # else:\n",
    "#         #     print(f\"given target: {self.tar}\")\n",
    "#         #     print(f\"generated target: {self.model.predict(self.data)}\")\n",
    "#         return grove\n",
    "    \n",
    "#     def upsilon(self, pexp):\n",
    "#         surrTar_series = pd.Series(self.surrTar)\n",
    "#         pexp_series = pd.Series(pexp)\n",
    "#         print(f\"pexp: {pexp}\")\n",
    "#         ASE = statistics.mean((surrTar_series - pexp_series) ** 2)\n",
    "#         ASE0 = statistics.mean((surrTar_series - statistics.mean(surrTar_series)) ** 2)\n",
    "#         ups = 1 - ASE / ASE0\n",
    "#         rho = surrTar_series.corr(pexp_series)\n",
    "#         return ups, rho\n",
    "\n",
    "#     def get_result(self):\n",
    "#         return [self.explanation, self.rules, self.groves, self.model]\n",
    "    \n",
    "#     # def consolidate_rules(self, df_small):\n",
    "#     #         # Zugriff auf self.rules und self.data (Daten m√ºssen vorhanden sein)\n",
    "#     #         data = self.data  \n",
    "#     #         i = 1\n",
    "#     #         while i < len(df_small):\n",
    "#     #             drop_rule = False\n",
    "#     #             # √úberpr√ºfen, ob der Datentyp der Spalte numerisch ist\n",
    "#     #             if pd.api.types.is_numeric_dtype(data[df_small.iloc[i][\"variable\"]]):\n",
    "#     #                 for j in range(i):\n",
    "#     #                     # √úberpr√ºfen, ob die Variable und die Obergrenze gleich sind\n",
    "#     #                     if df_small.iloc[i][\"variable\"] == df_small.iloc[j][\"variable\"]:\n",
    "#     #                         if df_small.iloc[i][\"upper_bound_left\"] == df_small.iloc[j][\"upper_bound_left\"]:\n",
    "#     #                             # Berechnung der crosstab-Tabelle\n",
    "#     #                             v1 = data[df_small.iloc[i][\"variable\"]] <= df_small.iloc[i][\"upper_bound_left\"]\n",
    "#     #                             v2 = data[df_small.iloc[j][\"variable\"]] <= df_small.iloc[j][\"upper_bound_left\"]\n",
    "#     #                             tab = pd.crosstab(v1, v2)\n",
    "                                \n",
    "#     #                             # √úberpr√ºfen, ob alle Werte in der Diagonalen √ºbereinstimmen\n",
    "#     #                             if tab.to_numpy().diagonal().sum() == tab.sum().sum():\n",
    "#     #                                 # Konsolidierung der Werte in den Spalten 'pleft' und 'pright'\n",
    "#     #                                 df_small.at[j, \"pleft\"] += df_small.at[i, \"pleft\"]\n",
    "#     #                                 df_small.at[j, \"pright\"] += df_small.at[i, \"pright\"]\n",
    "#     #                                 drop_rule = True\n",
    "#     #                                 break\n",
    "\n",
    "#     #             # L√∂schen der redundanten Regel\n",
    "#     #             if drop_rule:\n",
    "#     #                 df_small = df_small.drop(i).reset_index(drop=True)\n",
    "#     #             else:\n",
    "#     #                 i += 1\n",
    "\n",
    "#     #         return df_small\n",
    "    \n",
    "#     def extract_rules(self, booster_json):\n",
    "#         rules = []  # Liste, die alle getrennten Regelsets speichert\n",
    "\n",
    "#         # Iteriere durch die ntrees_list und hole die Regeln f√ºr jeden Baum-Index\n",
    "#         for nt in self.ntrees:\n",
    "#             tree_rules = []  # Hier speichern wir die Regeln f√ºr den aktuellen Wert von nt\n",
    "            \n",
    "#             # Iteriere durch alle B√§ume im booster_json\n",
    "#             for index, tree in enumerate(booster_json, start=1):  # start=1 sorgt daf√ºr, dass der Baumindex bei 1 beginnt\n",
    "#                 # print(f\"DEBUG: Baum {index} - Typ von tree: {type(tree)}\")  # Gib den Typ des Baums aus\n",
    "                \n",
    "#                 # print(tree)\n",
    "#                 if isinstance(tree, dict):\n",
    "#                     # print(tree)\n",
    "#                     if 'children' in tree:\n",
    "#                         # print(f\"DEBUG: Baum {index} : {tree}\")\n",
    "#                         # print(f\"DEBUG: Baum {index} und sein split: {tree['split']}\")\n",
    "#                         # print(f\"DEBUG: Baum {index} hat 'children': {tree['children']}\")  # Zeige die Kinder des Baums an\n",
    "#                         # Jeden Split in den Kindern durchgehen und Regel extrahieren\n",
    "                        \n",
    "#                         # print(f\"split_node: {split_node}\")\n",
    "\n",
    "#                         left_value = None\n",
    "#                         right_value = None\n",
    "\n",
    "#                     # Gehe durch die Kindknoten und finde die Blattwerte\n",
    "#                         for child in tree['children']:\n",
    "#                             if 'leaf' in child:\n",
    "#                                 if child['nodeid'] == tree['yes']:  # Pr√ºfe, ob dies der \"yes\"-Pfad ist\n",
    "#                                     left_value = round(child['leaf'], 4)\n",
    "#                                     # print(f\"DEBUG: Left leaf gefunden - Wert: {left_value}\")\n",
    "#                                 elif child['nodeid'] == tree['no']:  # Pr√ºfe, ob dies der \"no\"-Pfad ist\n",
    "#                                     right_value = round(child['leaf'],4)\n",
    "#                                     # print(f\"DEBUG: Right leaf gefunden - Wert: {right_value}\")\n",
    "                        \n",
    "#                             rule = {\n",
    "#                                 'variable': tree.get('split', None),\n",
    "#                                 'threshold': tree.get('split_condition', None),\n",
    "#                                 'pleft': left_value,\n",
    "#                                 'pright': right_value\n",
    "#                             }\n",
    "#                         tree_rules.append(rule)\n",
    "#                     else:\n",
    "#                         print(f\"DEBUG: Baum {index} hat keine 'children'.\")  # Wenn keine 'children' da sind\n",
    "#                 else:\n",
    "#                     print(f\"DEBUG: Baum {index} ist kein Dictionary, sondern: {type(tree)}\")  # Baum ist kein dict\n",
    "\n",
    "#                 # Wenn der aktuelle Baum-Index die Anzahl von `nt` √ºberschreitet, beende den Loop\n",
    "#                 if index >= nt:\n",
    "#                     break  # Wir haben genug B√§ume extrahiert, also abbrechen\n",
    "            \n",
    "#             # F√ºge die extrahierten Regeln f√ºr diesen `nt`-Wert zur Gesamtregel-Liste hinzu\n",
    "#             print(f\"tree_rules {index}: {len(tree_rules)}\")\n",
    "#             rules.append(tree_rules)\n",
    "#         outer_shape = len(rules)\n",
    "\n",
    "#         # Anzahl der inneren Listen\n",
    "#         inner_shapes = [len(inner) for inner in rules]\n",
    "#         print(f\"all the Rules: {rules}\")\n",
    "        \n",
    "#         return rules\n",
    "\n",
    "\n",
    "#     def calculateGrove(self):\n",
    "#         explanation = []\n",
    "#         cumulative_rules_list = []\n",
    "#         data = self.data\n",
    "#         dtrain = xgb.DMatrix(data=data, label=self.surrTar)\n",
    "#         # cumulative_rules = pd.DataFrame()\n",
    "#         booster = self.surrGrove.get_booster()\n",
    "#         tree_json = booster.trees_to_dataframe()\n",
    "#         booster_json = booster.get_dump(dump_format=\"json\")\n",
    "#         parsed_trees = [json.loads(tree) for tree in booster_json]\n",
    "#         # print(f\"boosterjson: {booster_json}\")\n",
    "#         # print(f\"parsed_trees: {parsed_trees}\")\n",
    "#         tree1 = booster[0].get_dump(with_stats = True)[0]\n",
    "        \n",
    "#         # print(f\"tree1 = {tree1}\")\n",
    "        \n",
    "#         # for node in tree_json[tree_json['Tree'] == 0].itertuples():\n",
    "#         #     print(f\"Node ID: {node.ID}, Feature: {node.Feature}, Split: {node.Split}, \"\n",
    "#         #         f\"Gain: {node.Gain}, Cover: {node.Cover}\")\n",
    "            \n",
    "#         cumulative_rules_list = self.extract_rules(parsed_trees)\n",
    "        \n",
    "#         rules_df = pd.DataFrame()\n",
    "#         # print(f\"rules_df: {rules_df}\")\n",
    "        \n",
    "#         for nt in self.ntrees:\n",
    "#             # Berechnung von Vorhersagen, Upsilon und Korrelation\n",
    "#             predictions = booster.predict(dtrain, nt)\n",
    "#             upsilon, rho = self.upsilon(pexp=predictions)\n",
    "\n",
    "#             # Initialisierung von tempor√§ren Variablen\n",
    "#             vars_temp, splits_temp, csplits_left_temp, pleft_temp, pright_temp = [], [], [], [], []\n",
    "\n",
    "#             # Verarbeitung der Regeln aus cumulative_rules\n",
    "#             for rule_set in cumulative_rules_list:\n",
    "#                 for entry in rule_set:\n",
    "#                     var_name = entry['variable']\n",
    "#                     threshold = entry[\"threshold\"]\n",
    "#                     pleft = entry[\"pleft\"]\n",
    "#                     pright = entry[\"pright\"]\n",
    "#                     vars_temp.append(var_name)\n",
    "\n",
    "#                     if pd.api.types.is_string_dtype(data[var_name]):\n",
    "#                         levels = data[var_name].unique()\n",
    "#                         csplits_left_temp.append(\" | \".join(map(str, levels)))\n",
    "#                         splits_temp.append(\"\")\n",
    "#                     else:\n",
    "#                         splits_temp.append(threshold)\n",
    "#                         csplits_left_temp.append(pd.NA)\n",
    "                    \n",
    "#                     pleft_temp.append(pleft)\n",
    "#                     pright_temp.append(pright)\n",
    "\n",
    "#             # Erstellen des DataFrame f√ºr Regeln\n",
    "#             df = pd.DataFrame({\n",
    "#                 \"variable\": vars_temp,\n",
    "#                 \"upper_bound_left\": splits_temp,\n",
    "#                 \"levels_left\": csplits_left_temp,\n",
    "#                 \"pleft\": pleft_temp,\n",
    "#                 \"pright\": pright_temp\n",
    "#             })\n",
    "\n",
    "#             # Hinzuf√ºgen eines Intercept-Eintrags\n",
    "#             intercept_df = pd.DataFrame({\n",
    "#                 \"variable\": [\"Intercept\"],\n",
    "#                 \"upper_bound_left\": [pd.NA],\n",
    "#                 \"levels_left\": [pd.NA],\n",
    "#                 \"pleft\": [self.surrGrove.predict(data.iloc[[0]])[0]],\n",
    "#                 \"pright\": [self.surrGrove.predict(data.iloc[[0]])[0]]\n",
    "#             })\n",
    "\n",
    "#             # Konsolidierung und Gruppierung der Regeln\n",
    "#             df = pd.concat([intercept_df, df], ignore_index=True)\n",
    "#             # df = df.dropna(subset=[\"upper_bound_left\", \"levels_left\"], how=\"any\")\n",
    "#             df_small = df.groupby([\"variable\", \"upper_bound_left\", \"levels_left\"], as_index=False).agg({\n",
    "#                 \"pleft\": \"sum\",\n",
    "#                 \"pright\": \"sum\"\n",
    "#             })\n",
    "\n",
    "#             # Debugging-Ausgabe\n",
    "#             print(f\"DEBUG: Konsolidierte Regeln f√ºr nt={nt} B√§ume:\\n{df_small.head()}\")\n",
    "\n",
    "#             # Ergebnis sammeln\n",
    "#             explanation.append({\n",
    "#                 \"trees\": nt,\n",
    "#                 \"rules\": len(df_small),\n",
    "#                 \"upsilon\": upsilon,\n",
    "#                 \"cor\": rho\n",
    "#             })\n",
    "#             self.rules.append(df_small)\n",
    "\n",
    "#         # Zusammenfassen der Ergebnisse\n",
    "#         self.explanation = pd.DataFrame(explanation)\n",
    "#         self.groves = rules_df\n",
    "#         self.result = self.get_result()\n",
    "#         print(\"DEBUG: Berechnung abgeschlossen. Ergebnisdaten verf√ºgbar.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import statistics\n",
    "# from xgboost import XGBRegressor, DMatrix\n",
    "# import xgboost as xgb\n",
    "# import json\n",
    "\n",
    "# class grove:\n",
    "#     def __init__(self, \n",
    "#                  model, \n",
    "#                  data: pd.DataFrame,\n",
    "#                  ntrees: np.array = np.array([4, 8, 16, 32, 64, 128]), \n",
    "#                  pfun=None, \n",
    "#                  shrink: float = 1, \n",
    "#                  b_frac: float = 1, \n",
    "#                  seed: int = 42,\n",
    "#                  grove_rate: float = 1,\n",
    "#                  trained: bool = False,\n",
    "#                  tar=None):\n",
    "#         self.model = model\n",
    "#         self.data = self.encodeCategorical(data)\n",
    "#         self.ntrees = ntrees\n",
    "#         self.pfun = pfun\n",
    "#         self.shrink = shrink\n",
    "#         self.b_frac = b_frac\n",
    "#         self.seed = seed\n",
    "#         self.grove_rate = grove_rate\n",
    "#         self.trained = trained\n",
    "#         self.tar = tar\n",
    "#         self.surrTar = self.getSurrogateTarget(pfun=self.pfun, tar=self.tar)\n",
    "#         self.surrGrove = self.getGBM()\n",
    "#         self.predictions = []\n",
    "#         self.explanation = []\n",
    "#         self.groves = []\n",
    "#         self.rules = []\n",
    "#         self.result = []\n",
    "\n",
    "#     def encodeCategorical(self, data):\n",
    "#         categorical_columns = data.select_dtypes(include=['object', 'category']).columns\n",
    "#         return pd.get_dummies(data, columns=categorical_columns)\n",
    "\n",
    "#     def getSurrogateTarget(self, pfun, tar):\n",
    "#         if tar is None:\n",
    "#             return self.model.predict(self.data) if self.pfun is None else pfun(model=self.model, data=self.data)\n",
    "#         else:\n",
    "#             return tar\n",
    "    \n",
    "#     def get_result(self):\n",
    "#         return [self.explanation, self.rules, self.groves, self.model]\n",
    "\n",
    "#     def getGBM(self):\n",
    "#         params = {\n",
    "#             'objective': 'reg:squarederror',  \n",
    "#             'max_depth': 1,                   \n",
    "#             'eta': self.shrink,               \n",
    "#             'eval_metric': 'rmse',            \n",
    "#             'subsample': self.b_frac,         \n",
    "#             'random_state': self.seed,\n",
    "#             'gamma': 0         \n",
    "#         }\n",
    "\n",
    "#         grove = XGBRegressor(\n",
    "#             n_estimators=int(max(self.ntrees)),  \n",
    "#             **params\n",
    "#         )\n",
    "#         grove.fit(self.data, self.surrTar)\n",
    "#         return grove\n",
    "    \n",
    "#     def upsilon(self, pexp):\n",
    "#         surrTar_series = pd.Series(self.surrTar)\n",
    "#         pexp_series = pd.Series(pexp)\n",
    "#         ASE = statistics.mean((surrTar_series - pexp_series) ** 2)\n",
    "#         ASE0 = statistics.mean((surrTar_series - statistics.mean(surrTar_series)) ** 2)\n",
    "#         ups = 1 - ASE / ASE0\n",
    "#         rho = surrTar_series.corr(pexp_series)\n",
    "#         return ups, rho\n",
    "\n",
    "#     def extract_rules(self, booster_json):\n",
    "#         rules = []\n",
    "#         for nt in self.ntrees:\n",
    "#             tree_rules = []\n",
    "#             for index, tree in enumerate(booster_json, start=1):\n",
    "#                 if isinstance(tree, dict) and 'children' in tree:\n",
    "#                     left_value, right_value = None, None\n",
    "#                     for child in tree['children']:\n",
    "#                         if 'leaf' in child:\n",
    "#                             if child['nodeid'] == tree['yes']:\n",
    "#                                 left_value = round(child['leaf'], 4)\n",
    "#                             elif child['nodeid'] == tree['no']:\n",
    "#                                 right_value = round(child['leaf'], 4)\n",
    "#                     rule = {\n",
    "#                         'variable': tree.get('split', None),\n",
    "#                         'threshold': tree.get('split_condition', None),\n",
    "#                         \"levels_left\": None,\n",
    "#                         'pleft': left_value,\n",
    "#                         'pright': right_value\n",
    "#                     }\n",
    "#                     tree_rules.append(rule)\n",
    "#                 if index >= nt:\n",
    "#                     break\n",
    "#             rules.append(tree_rules)\n",
    "#         return rules\n",
    "\n",
    "#     def remove_redundant_rules(self, df_small, data):\n",
    "#         \"\"\"\n",
    "#         Entfernt redundante Regeln aus dem DataFrame df_small basierend auf denselben Variablen und Trennbedingungen.\n",
    "        \n",
    "#         Args:\n",
    "#             df_small (pd.DataFrame): DataFrame mit Regeldefinitionen.\n",
    "#             data (pd.DataFrame): Original-Datensatz, um Variablenbedingungen zu √ºberpr√ºfen.\n",
    "        \n",
    "#         Returns:\n",
    "#             pd.DataFrame: Aktualisiertes df_small ohne redundante Regeln.\n",
    "#         \"\"\"\n",
    "#         if len(df_small) > 1:\n",
    "#             i = 1  # Start mit der zweiten Regel (Index in Python ist 0-basiert)\n",
    "\n",
    "#             while i < len(df_small):\n",
    "#                 drop_rule = False\n",
    "#                 # √úberpr√ºfen, ob die Variable numerisch ist\n",
    "#                 if pd.api.types.is_numeric_dtype(data[df_small.loc[i, \"variable\"]]):\n",
    "#                     for j in range(i):\n",
    "#                         # Wenn dieselbe Variable betroffen ist\n",
    "#                         if df_small.loc[i, \"variable\"] == df_small.loc[j, \"variable\"]:\n",
    "#                             v1 = data[df_small.loc[i, \"variable\"]] <= df_small.loc[i, \"threshold\"]\n",
    "#                             v2 = data[df_small.loc[j, \"variable\"]] <= df_small.loc[j, \"threshold\"]\n",
    "#                             tab = pd.crosstab(v1, v2)\n",
    "                            \n",
    "#                             if tab.to_numpy().trace() == tab.to_numpy().sum():\n",
    "#                                 df_small.loc[j, \"pleft\"] += df_small.loc[i, \"pleft\"]\n",
    "#                                 df_small.loc[j, \"pright\"] += df_small.loc[i, \"pright\"]\n",
    "#                                 drop_rule = True\n",
    "\n",
    "#                 # Regel entfernen oder zum n√§chsten Eintrag gehen\n",
    "#                 if drop_rule:\n",
    "#                     df_small = df_small.drop(index=i).reset_index(drop=True)\n",
    "#                 else:\n",
    "#                     i += 1\n",
    "\n",
    "#         return df_small\n",
    "\n",
    "\n",
    "#     def calculateGrove(self):\n",
    "#         explanation = []\n",
    "#         data = self.data\n",
    "#         dtrain = xgb.DMatrix(data=data, label=self.surrTar)\n",
    "#         booster = self.surrGrove.get_booster()\n",
    "#         booster_json = booster.get_dump(dump_format=\"json\")\n",
    "#         parsed_trees = [json.loads(tree) for tree in booster_json]\n",
    "#         cumulative_rules_list = self.extract_rules(parsed_trees)\n",
    "        \n",
    "#         for nt in self.ntrees:\n",
    "#             predictions = booster.predict(dtrain, iteration_range=(0, nt))\n",
    "#             upsilon, rho = self.upsilon(pexp=predictions)\n",
    "#             df_small_list = []  # Liste f√ºr die bereinigten DataFrames\n",
    "            \n",
    "#             for i in range(len(cumulative_rules_list)):\n",
    "#                 intercept_df = pd.DataFrame({\n",
    "#                     \"variable\": [\"Intercept\"],\n",
    "#                     \"threshold\": [None],\n",
    "#                     \"levels_left\": [None],\n",
    "#                     \"pleft\": [self.surrGrove.predict(data.iloc[[0]])[0]],\n",
    "#                     \"pright\": [self.surrGrove.predict(data.iloc[[0]])[0]]\n",
    "#                 })\n",
    "#                 df = pd.DataFrame(cumulative_rules_list[i])\n",
    "#                 df = pd.concat([intercept_df, df], ignore_index=True)\n",
    "                \n",
    "#                 # redundante Regeln entfernen\n",
    "#                 df_cleaned = self.remove_redundant_rules(df, data)\n",
    "#                 df_small_list.append(df_cleaned)\n",
    "#             print(f\"df_small_list: {df_small_list}\")\n",
    "#             # Alle DataFrames in df_small_list zusammenf√ºhren\n",
    "#             if df_small_list:  # Pr√ºfen, ob Liste nicht leer ist\n",
    "#                 df_small = pd.concat(df_small_list, ignore_index=True)\n",
    "#             else:\n",
    "#                 df_small = pd.DataFrame()  # Leerer DataFrame, falls keine Daten\n",
    "            \n",
    "#             if \"levels_left\" in df_small.columns:\n",
    "#                 df_small[\"levels_left\"] = df_small[\"levels_left\"].apply(lambda x: str(x) if isinstance(x, list) else x)\n",
    "\n",
    "#             # Gruppieren und Aggregieren\n",
    "#             if not df_small.empty:\n",
    "#                 df_small = df_small.groupby([\"variable\", \"threshold\", \"levels_left\"], as_index=False).agg({\n",
    "#                     \"pleft\": \"sum\",\n",
    "#                     \"pright\": \"sum\"\n",
    "#                 })\n",
    "#             if not df_small.empty:\n",
    "#                 num_rules = len(df_small)  # Anzahl der nicht-redundanten Regeln\n",
    "#             else:\n",
    "#                 num_rules = 0  # Falls df_small leer ist\n",
    "\n",
    "#             explanation.append({\n",
    "#                 \"trees\": nt,\n",
    "#                 \"rules\": num_rules,\n",
    "#                 \"upsilon\": upsilon,\n",
    "#                 \"cor\": rho\n",
    "#             })\n",
    "#             # Hinzuf√ºgen der Ergebnisse zur Erkl√§rung\n",
    "            \n",
    "#             self.rules.append(df_small)\n",
    "\n",
    "#         self.explanation = pd.DataFrame(explanation)\n",
    "#         self.result = [self.explanation, self.rules, self.groves, self.model]\n",
    "    \n",
    "    \n",
    "    # TODO Z√§hlung fixen\n",
    "    # def calculateGrove(self):\n",
    "    #     explanation = []\n",
    "    #     data = self.data\n",
    "    #     dtrain = xgb.DMatrix(data=data, label=self.surrTar)\n",
    "    #     booster = self.surrGrove.get_booster()\n",
    "    #     booster_json = booster.get_dump(dump_format=\"json\")\n",
    "    #     parsed_trees = [json.loads(tree) for tree in booster_json]\n",
    "    #     cumulative_rules_list = self.extract_rules(parsed_trees)\n",
    "    #     df_small_list = []  # Liste f√ºr alle DataFrames mit bereinigten Regeln\n",
    "    #     j=0\n",
    "    #     for nt in self.ntrees:\n",
    "            \n",
    "    #         predictions = booster.predict(dtrain, iteration_range=(0, nt))\n",
    "    #         upsilon, rho = self.upsilon(pexp=predictions)\n",
    "            \n",
    "    #         # F√ºr jede Baumanzahl die Regeln und ihre Bereinigung durchf√ºhren\n",
    "    #         df_small = pd.DataFrame()\n",
    "            \n",
    "    #         for i in range(len(cumulative_rules_list)):\n",
    "    #             intercept_df = pd.DataFrame({\n",
    "    #                 \"variable\": [\"Intercept\"],\n",
    "    #                 \"threshold\": [None],\n",
    "    #                 \"levels_left\": [None],\n",
    "    #                 \"pleft\": [self.surrGrove.predict(data.iloc[[0]])[0]],\n",
    "    #                 \"pright\": [self.surrGrove.predict(data.iloc[[0]])[0]]\n",
    "    #             })\n",
    "    #             df = pd.DataFrame(cumulative_rules_list[i])\n",
    "    #             df = pd.concat([intercept_df, df], ignore_index=True)\n",
    "                \n",
    "    #             # Redundante Regeln entfernen und die bereinigte Liste anf√ºgen\n",
    "    #             df_cleaned = self.remove_redundant_rules(df, data)  # Dynamische Bereinigung pro Iteration\n",
    "    #             if isinstance(df_small_list[j],None): \n",
    "    #                 df_small_list.append(pd.DataFrame({\n",
    "    #                     \"nt\": [nt],\n",
    "    #                     \"rules\": [df_cleaned]}, index=[j]))  # Liste aller bereinigten Regeln sammeln\n",
    "            \n",
    "    #         print(f\"df_small_list: {df_small_list}\")\n",
    "    #         # Alle bereinigten DataFrames zusammenf√ºhren\n",
    "    #         if df_small_list:\n",
    "    #             df_small = pd.concat(df_small_list, ignore_index=True)\n",
    "            \n",
    "    #         df_small['levels_left'] = df_small['levels_left'].fillna('None')\n",
    "    #         # Ersetze Listen durch 'None' oder einen anderen Platzhalter\n",
    "    #         df_small['levels_left'] = df_small['levels_left'].apply(lambda x: 'None' if isinstance(x, list) else x)\n",
    "\n",
    "    #         # Gruppieren und Aggregieren\n",
    "    #         if not df_small.empty:\n",
    "    #             df_small = df_small.groupby([\"variable\", \"threshold\", \"levels_left\"], as_index=False).agg({\n",
    "    #                 \"pleft\": \"sum\",\n",
    "    #                 \"pright\": \"sum\"\n",
    "    #             })\n",
    "            \n",
    "    #         # Anzahl der nicht-redundanten Regeln\n",
    "    #         num_rules = len(df_small)\n",
    "\n",
    "    #         # Ergebnisse zur Erkl√§rung hinzuf√ºgen\n",
    "    #         explanation.append({\n",
    "    #             \"trees\": nt,\n",
    "    #             \"rules\": num_rules,  # Hier wird die Anzahl der nicht-redundanten Regeln gespeichert\n",
    "    #             \"upsilon\": upsilon,\n",
    "    #             \"cor\": rho\n",
    "    #         })\n",
    "\n",
    "    #         self.rules.append(df_small)\n",
    "    #         j += 1\n",
    "\n",
    "    #     self.explanation = pd.DataFrame(explanation)\n",
    "    #     self.result = [self.explanation, self.rules, self.groves, self.model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Structure:\n",
      "Node 0:\n",
      "  Feature used for split: 0\n",
      "  Threshold for split: 1.5\n",
      "  Value: 0.0000\n",
      "  Left child node: 1\n",
      "  Node 1:\n",
      "    Feature used for split: Leaf node\n",
      "    Threshold for split: N/A\n",
      "    Value: -1.7500\n",
      "  Right child node: 2\n",
      "  Node 2:\n",
      "    Feature used for split: 0\n",
      "    Threshold for split: 3.5\n",
      "    Value: 0.5833\n",
      "    Left child node: 3\n",
      "    Node 3:\n",
      "      Feature used for split: 0\n",
      "      Threshold for split: 2.5\n",
      "      Value: 0.0000\n",
      "      Left child node: 4\n",
      "      Node 4:\n",
      "        Feature used for split: Leaf node\n",
      "        Threshold for split: N/A\n",
      "        Value: 0.2500\n",
      "      Right child node: 5\n",
      "      Node 5:\n",
      "        Feature used for split: Leaf node\n",
      "        Threshold for split: N/A\n",
      "        Value: -0.2500\n",
      "    Right child node: 6\n",
      "    Node 6:\n",
      "      Feature used for split: Leaf node\n",
      "      Threshold for split: N/A\n",
      "      Value: 1.7500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Beispiel-Daten erstellen\n",
    "X = np.array([[1], [2], [3], [4]])\n",
    "y = np.array([1.5, 3.5, 3.0, 5.0])\n",
    "\n",
    "# GradientBoostingRegressor mit max_depth=3\n",
    "gbr = GradientBoostingRegressor(n_estimators=1, max_depth=3, random_state=42)\n",
    "gbr.fit(X, y)\n",
    "\n",
    "# Zugriff auf den ersten Baum\n",
    "first_tree = gbr.estimators_[0, 0].tree_\n",
    "\n",
    "# Rekursive Funktion zur Darstellung der Baumstruktur\n",
    "def print_tree_structure(tree, node_id=0, depth=0):\n",
    "    indent = \"  \" * depth\n",
    "    feature = tree.feature[node_id]\n",
    "    threshold = tree.threshold[node_id]\n",
    "    left_child = tree.children_left[node_id]\n",
    "    right_child = tree.children_right[node_id]\n",
    "\n",
    "    print(f\"{indent}Node {node_id}:\")\n",
    "    print(f\"{indent}  Feature used for split: {feature if feature != -2 else 'Leaf node'}\")\n",
    "    print(f\"{indent}  Threshold for split: {threshold if feature != -2 else 'N/A'}\")\n",
    "    print(f\"{indent}  Value: {tree.value[node_id].flatten()[0]:.4f}\")\n",
    "\n",
    "    if left_child != -1:  # Wenn ein linker Kindknoten existiert\n",
    "        print(f\"{indent}  Left child node: {left_child}\")\n",
    "        print_tree_structure(tree, left_child, depth + 1)\n",
    "    if right_child != -1:  # Wenn ein rechter Kindknoten existiert\n",
    "        print(f\"{indent}  Right child node: {right_child}\")\n",
    "        print_tree_structure(tree, right_child, depth + 1)\n",
    "\n",
    "# Baumstruktur ausgeben\n",
    "print(\"Tree Structure:\")\n",
    "print_tree_structure(first_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daten geladen:\n",
      "   Feature1  Feature2  Target\n",
      "0        48        72      48\n",
      "1       100        84      60\n",
      "2        64        42       0\n",
      "3        24        57      16\n",
      "4        73        71      32\n",
      "Die Vorhersagen wurden erfolgreich zu 'predictions.csv' hinzugef√ºgt.\n",
      "df_small_list: [    variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.406700   2.174700\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900,     variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.186400   1.845200\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900\n",
      "4   Feature1         9        None  -0.876600   0.137600\n",
      "5   Feature1        91        None  -0.140600   0.615200\n",
      "6   Feature1        86        None  -0.109900   0.372600,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.880800   1.386600\n",
      "2    Feature1        28        None  -1.021800   0.502200\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.140600   0.615200\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.084100   0.199800\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.714900   1.123700\n",
      "2    Feature1        28        None  -0.811600   0.402800\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.118200   0.512100\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.143400   0.341000\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.156600   0.043800\n",
      "13   Feature1        99        None  -0.022900   0.233300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.068500  -0.042000\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.054100   0.051000,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.533100   0.844500\n",
      "2    Feature1        28        None  -0.666700   0.330300\n",
      "3    Feature2        61        None   0.334800  -0.530400\n",
      "4    Feature1         9        None  -0.810000   0.125400\n",
      "5    Feature1        91        None  -0.104300   0.448500\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.027000   0.056100\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.029000  -0.027600\n",
      "28   Feature1        70        None  -0.020200   0.040000\n",
      "29   Feature1        23        None  -0.045300   0.015400,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.397100   0.633300\n",
      "2    Feature1        28        None  -0.462100   0.231200\n",
      "3    Feature2        61        None   0.280600  -0.447800\n",
      "4    Feature1         9        None  -0.724300   0.111500\n",
      "5    Feature1        91        None  -0.080800   0.340800\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.451400  -0.030300\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.046500   0.081300\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.039900   0.080900\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.085100  -0.080900\n",
      "28   Feature1        70        None  -0.034300   0.067900\n",
      "29   Feature1        23        None  -0.112600   0.038900\n",
      "30   Feature1        34        None  -0.056000   0.035100\n",
      "31   Feature2        96        None   0.006400  -0.080200\n",
      "32   Feature1        73        None  -0.011000   0.022900\n",
      "33   Feature1        53        None  -0.044300   0.053500\n",
      "34   Feature1        68        None  -0.025100   0.043700\n",
      "35   Feature2        25        None   0.052400  -0.013400\n",
      "36   Feature1        52        None  -0.017100   0.019900\n",
      "37   Feature2        91        None   0.007700  -0.048000\n",
      "38   Feature1        31        None  -0.041100   0.022800\n",
      "39   Feature1        25        None  -0.023200   0.009800\n",
      "40   Feature1         4        None  -0.048100   0.004400\n",
      "41   Feature2        84        None  -0.007200   0.029400\n",
      "42   Feature2        72        None   0.008400  -0.019100\n",
      "43   Feature1        96        None  -0.006700   0.048700\n",
      "44   Feature1       100        None  -0.002600   0.058600\n",
      "45   Feature1        67        None  -0.041400   0.068900\n",
      "46   Feature1        33        None  -0.017700   0.010600]\n",
      "df_small_list: [    variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.406700   2.174700\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900,     variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.186400   1.845200\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900\n",
      "4   Feature1         9        None  -0.876600   0.137600\n",
      "5   Feature1        91        None  -0.140600   0.615200\n",
      "6   Feature1        86        None  -0.109900   0.372600,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.880800   1.386600\n",
      "2    Feature1        28        None  -1.021800   0.502200\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.140600   0.615200\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.084100   0.199800\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.714900   1.123700\n",
      "2    Feature1        28        None  -0.811600   0.402800\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.118200   0.512100\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.143400   0.341000\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.156600   0.043800\n",
      "13   Feature1        99        None  -0.022900   0.233300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.068500  -0.042000\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.054100   0.051000,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.533100   0.844500\n",
      "2    Feature1        28        None  -0.666700   0.330300\n",
      "3    Feature2        61        None   0.334800  -0.530400\n",
      "4    Feature1         9        None  -0.810000   0.125400\n",
      "5    Feature1        91        None  -0.104300   0.448500\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.027000   0.056100\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.029000  -0.027600\n",
      "28   Feature1        70        None  -0.020200   0.040000\n",
      "29   Feature1        23        None  -0.045300   0.015400,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.397100   0.633300\n",
      "2    Feature1        28        None  -0.462100   0.231200\n",
      "3    Feature2        61        None   0.280600  -0.447800\n",
      "4    Feature1         9        None  -0.724300   0.111500\n",
      "5    Feature1        91        None  -0.080800   0.340800\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.451400  -0.030300\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.046500   0.081300\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.039900   0.080900\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.085100  -0.080900\n",
      "28   Feature1        70        None  -0.034300   0.067900\n",
      "29   Feature1        23        None  -0.112600   0.038900\n",
      "30   Feature1        34        None  -0.056000   0.035100\n",
      "31   Feature2        96        None   0.006400  -0.080200\n",
      "32   Feature1        73        None  -0.011000   0.022900\n",
      "33   Feature1        53        None  -0.044300   0.053500\n",
      "34   Feature1        68        None  -0.025100   0.043700\n",
      "35   Feature2        25        None   0.052400  -0.013400\n",
      "36   Feature1        52        None  -0.017100   0.019900\n",
      "37   Feature2        91        None   0.007700  -0.048000\n",
      "38   Feature1        31        None  -0.041100   0.022800\n",
      "39   Feature1        25        None  -0.023200   0.009800\n",
      "40   Feature1         4        None  -0.048100   0.004400\n",
      "41   Feature2        84        None  -0.007200   0.029400\n",
      "42   Feature2        72        None   0.008400  -0.019100\n",
      "43   Feature1        96        None  -0.006700   0.048700\n",
      "44   Feature1       100        None  -0.002600   0.058600\n",
      "45   Feature1        67        None  -0.041400   0.068900\n",
      "46   Feature1        33        None  -0.017700   0.010600]\n",
      "df_small_list: [    variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.406700   2.174700\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900,     variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.186400   1.845200\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900\n",
      "4   Feature1         9        None  -0.876600   0.137600\n",
      "5   Feature1        91        None  -0.140600   0.615200\n",
      "6   Feature1        86        None  -0.109900   0.372600,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.880800   1.386600\n",
      "2    Feature1        28        None  -1.021800   0.502200\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.140600   0.615200\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.084100   0.199800\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.714900   1.123700\n",
      "2    Feature1        28        None  -0.811600   0.402800\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.118200   0.512100\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.143400   0.341000\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.156600   0.043800\n",
      "13   Feature1        99        None  -0.022900   0.233300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.068500  -0.042000\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.054100   0.051000,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.533100   0.844500\n",
      "2    Feature1        28        None  -0.666700   0.330300\n",
      "3    Feature2        61        None   0.334800  -0.530400\n",
      "4    Feature1         9        None  -0.810000   0.125400\n",
      "5    Feature1        91        None  -0.104300   0.448500\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.027000   0.056100\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.029000  -0.027600\n",
      "28   Feature1        70        None  -0.020200   0.040000\n",
      "29   Feature1        23        None  -0.045300   0.015400,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.397100   0.633300\n",
      "2    Feature1        28        None  -0.462100   0.231200\n",
      "3    Feature2        61        None   0.280600  -0.447800\n",
      "4    Feature1         9        None  -0.724300   0.111500\n",
      "5    Feature1        91        None  -0.080800   0.340800\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.451400  -0.030300\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.046500   0.081300\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.039900   0.080900\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.085100  -0.080900\n",
      "28   Feature1        70        None  -0.034300   0.067900\n",
      "29   Feature1        23        None  -0.112600   0.038900\n",
      "30   Feature1        34        None  -0.056000   0.035100\n",
      "31   Feature2        96        None   0.006400  -0.080200\n",
      "32   Feature1        73        None  -0.011000   0.022900\n",
      "33   Feature1        53        None  -0.044300   0.053500\n",
      "34   Feature1        68        None  -0.025100   0.043700\n",
      "35   Feature2        25        None   0.052400  -0.013400\n",
      "36   Feature1        52        None  -0.017100   0.019900\n",
      "37   Feature2        91        None   0.007700  -0.048000\n",
      "38   Feature1        31        None  -0.041100   0.022800\n",
      "39   Feature1        25        None  -0.023200   0.009800\n",
      "40   Feature1         4        None  -0.048100   0.004400\n",
      "41   Feature2        84        None  -0.007200   0.029400\n",
      "42   Feature2        72        None   0.008400  -0.019100\n",
      "43   Feature1        96        None  -0.006700   0.048700\n",
      "44   Feature1       100        None  -0.002600   0.058600\n",
      "45   Feature1        67        None  -0.041400   0.068900\n",
      "46   Feature1        33        None  -0.017700   0.010600]\n",
      "df_small_list: [    variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.406700   2.174700\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900,     variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.186400   1.845200\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900\n",
      "4   Feature1         9        None  -0.876600   0.137600\n",
      "5   Feature1        91        None  -0.140600   0.615200\n",
      "6   Feature1        86        None  -0.109900   0.372600,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.880800   1.386600\n",
      "2    Feature1        28        None  -1.021800   0.502200\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.140600   0.615200\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.084100   0.199800\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.714900   1.123700\n",
      "2    Feature1        28        None  -0.811600   0.402800\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.118200   0.512100\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.143400   0.341000\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.156600   0.043800\n",
      "13   Feature1        99        None  -0.022900   0.233300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.068500  -0.042000\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.054100   0.051000,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.533100   0.844500\n",
      "2    Feature1        28        None  -0.666700   0.330300\n",
      "3    Feature2        61        None   0.334800  -0.530400\n",
      "4    Feature1         9        None  -0.810000   0.125400\n",
      "5    Feature1        91        None  -0.104300   0.448500\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.027000   0.056100\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.029000  -0.027600\n",
      "28   Feature1        70        None  -0.020200   0.040000\n",
      "29   Feature1        23        None  -0.045300   0.015400,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.397100   0.633300\n",
      "2    Feature1        28        None  -0.462100   0.231200\n",
      "3    Feature2        61        None   0.280600  -0.447800\n",
      "4    Feature1         9        None  -0.724300   0.111500\n",
      "5    Feature1        91        None  -0.080800   0.340800\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.451400  -0.030300\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.046500   0.081300\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.039900   0.080900\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.085100  -0.080900\n",
      "28   Feature1        70        None  -0.034300   0.067900\n",
      "29   Feature1        23        None  -0.112600   0.038900\n",
      "30   Feature1        34        None  -0.056000   0.035100\n",
      "31   Feature2        96        None   0.006400  -0.080200\n",
      "32   Feature1        73        None  -0.011000   0.022900\n",
      "33   Feature1        53        None  -0.044300   0.053500\n",
      "34   Feature1        68        None  -0.025100   0.043700\n",
      "35   Feature2        25        None   0.052400  -0.013400\n",
      "36   Feature1        52        None  -0.017100   0.019900\n",
      "37   Feature2        91        None   0.007700  -0.048000\n",
      "38   Feature1        31        None  -0.041100   0.022800\n",
      "39   Feature1        25        None  -0.023200   0.009800\n",
      "40   Feature1         4        None  -0.048100   0.004400\n",
      "41   Feature2        84        None  -0.007200   0.029400\n",
      "42   Feature2        72        None   0.008400  -0.019100\n",
      "43   Feature1        96        None  -0.006700   0.048700\n",
      "44   Feature1       100        None  -0.002600   0.058600\n",
      "45   Feature1        67        None  -0.041400   0.068900\n",
      "46   Feature1        33        None  -0.017700   0.010600]\n",
      "df_small_list: [    variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.406700   2.174700\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900,     variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.186400   1.845200\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900\n",
      "4   Feature1         9        None  -0.876600   0.137600\n",
      "5   Feature1        91        None  -0.140600   0.615200\n",
      "6   Feature1        86        None  -0.109900   0.372600,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.880800   1.386600\n",
      "2    Feature1        28        None  -1.021800   0.502200\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.140600   0.615200\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.084100   0.199800\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.714900   1.123700\n",
      "2    Feature1        28        None  -0.811600   0.402800\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.118200   0.512100\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.143400   0.341000\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.156600   0.043800\n",
      "13   Feature1        99        None  -0.022900   0.233300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.068500  -0.042000\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.054100   0.051000,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.533100   0.844500\n",
      "2    Feature1        28        None  -0.666700   0.330300\n",
      "3    Feature2        61        None   0.334800  -0.530400\n",
      "4    Feature1         9        None  -0.810000   0.125400\n",
      "5    Feature1        91        None  -0.104300   0.448500\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.027000   0.056100\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.029000  -0.027600\n",
      "28   Feature1        70        None  -0.020200   0.040000\n",
      "29   Feature1        23        None  -0.045300   0.015400,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.397100   0.633300\n",
      "2    Feature1        28        None  -0.462100   0.231200\n",
      "3    Feature2        61        None   0.280600  -0.447800\n",
      "4    Feature1         9        None  -0.724300   0.111500\n",
      "5    Feature1        91        None  -0.080800   0.340800\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.451400  -0.030300\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.046500   0.081300\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.039900   0.080900\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.085100  -0.080900\n",
      "28   Feature1        70        None  -0.034300   0.067900\n",
      "29   Feature1        23        None  -0.112600   0.038900\n",
      "30   Feature1        34        None  -0.056000   0.035100\n",
      "31   Feature2        96        None   0.006400  -0.080200\n",
      "32   Feature1        73        None  -0.011000   0.022900\n",
      "33   Feature1        53        None  -0.044300   0.053500\n",
      "34   Feature1        68        None  -0.025100   0.043700\n",
      "35   Feature2        25        None   0.052400  -0.013400\n",
      "36   Feature1        52        None  -0.017100   0.019900\n",
      "37   Feature2        91        None   0.007700  -0.048000\n",
      "38   Feature1        31        None  -0.041100   0.022800\n",
      "39   Feature1        25        None  -0.023200   0.009800\n",
      "40   Feature1         4        None  -0.048100   0.004400\n",
      "41   Feature2        84        None  -0.007200   0.029400\n",
      "42   Feature2        72        None   0.008400  -0.019100\n",
      "43   Feature1        96        None  -0.006700   0.048700\n",
      "44   Feature1       100        None  -0.002600   0.058600\n",
      "45   Feature1        67        None  -0.041400   0.068900\n",
      "46   Feature1        33        None  -0.017700   0.010600]\n",
      "df_small_list: [    variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.406700   2.174700\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900,     variable threshold levels_left      pleft     pright\n",
      "0  Intercept      None        None  48.916519  48.916519\n",
      "1   Feature1        59        None  -1.186400   1.845200\n",
      "2   Feature1        28        None  -1.021800   0.502200\n",
      "3   Feature2        61        None   0.387100  -0.612900\n",
      "4   Feature1         9        None  -0.876600   0.137600\n",
      "5   Feature1        91        None  -0.140600   0.615200\n",
      "6   Feature1        86        None  -0.109900   0.372600,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.880800   1.386600\n",
      "2    Feature1        28        None  -1.021800   0.502200\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.140600   0.615200\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.084100   0.199800\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.714900   1.123700\n",
      "2    Feature1        28        None  -0.811600   0.402800\n",
      "3    Feature2        61        None   0.387100  -0.612900\n",
      "4    Feature1         9        None  -0.876600   0.137600\n",
      "5    Feature1        91        None  -0.118200   0.512100\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.143400   0.341000\n",
      "10   Feature1        39        None  -0.121400   0.087800\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.156600   0.043800\n",
      "13   Feature1        99        None  -0.022900   0.233300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.068500  -0.042000\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.054100   0.051000,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.533100   0.844500\n",
      "2    Feature1        28        None  -0.666700   0.330300\n",
      "3    Feature2        61        None   0.334800  -0.530400\n",
      "4    Feature1         9        None  -0.810000   0.125400\n",
      "5    Feature1        91        None  -0.104300   0.448500\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.567100  -0.039000\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.039800   0.067900\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.027000   0.056100\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.029000  -0.027600\n",
      "28   Feature1        70        None  -0.020200   0.040000\n",
      "29   Feature1        23        None  -0.045300   0.015400,      variable threshold levels_left      pleft     pright\n",
      "0   Intercept      None        None  48.916519  48.916519\n",
      "1    Feature1        59        None  -0.397100   0.633300\n",
      "2    Feature1        28        None  -0.462100   0.231200\n",
      "3    Feature2        61        None   0.280600  -0.447800\n",
      "4    Feature1         9        None  -0.724300   0.111500\n",
      "5    Feature1        91        None  -0.080800   0.340800\n",
      "6    Feature1        86        None  -0.109900   0.372600\n",
      "7    Feature2         9        None   0.451400  -0.030300\n",
      "8    Feature1        41        None  -0.210600   0.172100\n",
      "9    Feature1        79        None  -0.197600   0.470800\n",
      "10   Feature1        39        None  -0.163200   0.118700\n",
      "11   Feature2        83        None   0.039700  -0.154700\n",
      "12   Feature1        19        None  -0.267700   0.074400\n",
      "13   Feature1        99        None  -0.031100   0.312300\n",
      "14   Feature2        29        None   0.091100  -0.031600\n",
      "15   Feature2        60        None  -0.064700   0.097800\n",
      "16   Feature2        77        None   0.042700  -0.117400\n",
      "17   Feature2        62        None  -0.046500   0.081300\n",
      "18   Feature2        37        None   0.105600  -0.065200\n",
      "19   Feature1        48        None  -0.065700   0.061600\n",
      "20   Feature1        46        None  -0.106200   0.098800\n",
      "21   Feature1         3        None  -0.162400   0.011800\n",
      "22   Feature1        49        None  -0.075500   0.085200\n",
      "23   Feature1        72        None  -0.039900   0.080900\n",
      "24   Feature2        79        None   0.022600  -0.069100\n",
      "25   Feature2         5        None  -0.147900   0.005900\n",
      "26   Feature2        16        None   0.050500  -0.009300\n",
      "27   Feature2        51        None   0.085100  -0.080900\n",
      "28   Feature1        70        None  -0.034300   0.067900\n",
      "29   Feature1        23        None  -0.112600   0.038900\n",
      "30   Feature1        34        None  -0.056000   0.035100\n",
      "31   Feature2        96        None   0.006400  -0.080200\n",
      "32   Feature1        73        None  -0.011000   0.022900\n",
      "33   Feature1        53        None  -0.044300   0.053500\n",
      "34   Feature1        68        None  -0.025100   0.043700\n",
      "35   Feature2        25        None   0.052400  -0.013400\n",
      "36   Feature1        52        None  -0.017100   0.019900\n",
      "37   Feature2        91        None   0.007700  -0.048000\n",
      "38   Feature1        31        None  -0.041100   0.022800\n",
      "39   Feature1        25        None  -0.023200   0.009800\n",
      "40   Feature1         4        None  -0.048100   0.004400\n",
      "41   Feature2        84        None  -0.007200   0.029400\n",
      "42   Feature2        72        None   0.008400  -0.019100\n",
      "43   Feature1        96        None  -0.006700   0.048700\n",
      "44   Feature1       100        None  -0.002600   0.058600\n",
      "45   Feature1        67        None  -0.041400   0.068900\n",
      "46   Feature1        33        None  -0.017700   0.010600]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[   trees  rules   upsilon       cor\n",
       " 0      4      0  0.896764  0.947322\n",
       " 1      8      0  0.951506  0.975972\n",
       " 2     16      0  0.975604  0.988134\n",
       " 3     32      0  0.988291  0.994147\n",
       " 4     64      0  0.994768  0.997393\n",
       " 5    128      0  0.997864  0.998934,\n",
       " [Empty DataFrame\n",
       "  Columns: [variable, threshold, levels_left, pleft, pright]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [variable, threshold, levels_left, pleft, pright]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [variable, threshold, levels_left, pleft, pright]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [variable, threshold, levels_left, pleft, pright]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [variable, threshold, levels_left, pleft, pright]\n",
       "  Index: [],\n",
       "  Empty DataFrame\n",
       "  Columns: [variable, threshold, levels_left, pleft, pright]\n",
       "  Index: []],\n",
       " [],\n",
       " LinearRegression()]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ben√∂tigte Bibliotheken importieren\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import json\n",
    "\n",
    "# Schritt 1: CSV-Datei einlesen (Daten aus der bestehenden Datei)\n",
    "data_path = \"../models/generated_data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "# Anzeige der ersten Zeilen, um sicherzustellen, dass die Daten korrekt geladen wurden\n",
    "print(\"Daten geladen:\")\n",
    "print(data.head())\n",
    "\n",
    "# Schritt 2: Lineares Regressionsmodell erstellen\n",
    "X = data[['Feature1', 'Feature2']]  # Unabh√§ngige Variablen\n",
    "y = data['Target']  # Zielvariable\n",
    "\n",
    "# Modell erstellen und trainieren\n",
    "lm_model = LinearRegression()\n",
    "lm_model.fit(X, y)\n",
    "\n",
    "# Anzeige der Koeffizienten und des Intercepts\n",
    "# print(f\"Koeffizienten: {lm_model.coef_}\")\n",
    "# print(f\"Intercept: {lm_model.intercept_}\")\n",
    "\n",
    "# Schritt 3: Vorhersage mit dem Modell machen\n",
    "predictions_lm_new = lm_model.predict(X)\n",
    "\n",
    "# Die bestehende CSV-Datei einlesen\n",
    "predictions_df = pd.read_csv('../models/predictions.csv', dtype={'predicted_tar_lm': np.float64})\n",
    "\n",
    "# Vorhersagen f√ºr lm_model als neue Spalte hinzuf√ºgen\n",
    "predictions_df['predicted_tar_py'] = predictions_lm_new\n",
    "\n",
    "# Die aktualisierte Datei speichern (anf√ºgen und nicht √ºberschreiben)\n",
    "predictions_df.to_csv('../models/predictions.csv', index=False)  # Maximale Genauigkeit von 16 Dezimalstellen\n",
    "\n",
    "# Best√§tigung der Speicherung\n",
    "print(\"Die Vorhersagen wurden erfolgreich zu 'predictions.csv' hinzugef√ºgt.\")\n",
    "\n",
    "# Schritt 4: Berechnung der durchschnittlichen Abweichung\n",
    "# abweichung = np.mean(np.abs(y - predictions_lm_new))\n",
    "# print(f\"Durchschnittliche Abweichung: {abweichung}\")\n",
    "\n",
    "\n",
    "\n",
    "xg = grove(data = data.drop(\"Target\", axis=1), seed=42, model=lm_model)\n",
    "xg.calculateGrove()\n",
    "xg.get_result()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import platform\n",
    "# print(platform.architecture())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import jpype\n",
    "# jpype.startJVM()  # Startet die JVM\n",
    "# print(\"JVM erfolgreich gestartet!\")\n",
    "# jpype.shutdownJVM()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from jpmml_evaluator import make_evaluator\n",
    "\n",
    "# # Teste, ob die JVM erfolgreich gestartet werden kann\n",
    "# try:\n",
    "#     evaluator = make_evaluator('../models/analyzed_model.pmml')  # Verwende einen einfachen PMML-Pfad\n",
    "#     evaluator.verify()\n",
    "#     print(\"JVM erfolgreich gestartet und PMML-Modell erfolgreich geladen.\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Fehler: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"START\")\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# from pypmml import Model\n",
    "\n",
    "# # Pfad zur PMML-Datei und zur CSV-Datei\n",
    "# pmml_file_path = '/mnt/data/analyzed_model.pmml'\n",
    "# csv_file_path = 'models/generated_data.csv'  # Passe den Pfad zur CSV-Datei bei Bedarf an\n",
    "\n",
    "# # Funktion zum Laden des Modells mit verbesserter Fehlerbehandlung\n",
    "# def load_model(file_path):\n",
    "#     try:\n",
    "#         # Modell mit pypmml laden\n",
    "#         loaded_model = Model.load(file_path)\n",
    "#         if loaded_model is not None:\n",
    "#             print(\"Modell erfolgreich geladen.\")\n",
    "#             return loaded_model\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden des PMML-Modells: {e}\")\n",
    "#     return None\n",
    "\n",
    "# # Modell laden\n",
    "# loaded_model = load_model(pmml_file_path)\n",
    "\n",
    "# if loaded_model is not None:\n",
    "#     # Lade die generierten Daten\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "    \n",
    "#     # Vorverarbeitung: Sicherstellen, dass kategorische Variablen als solche erkannt werden\n",
    "#     data['Geschlecht'] = data['Geschlecht'].astype('category')\n",
    "#     data['Kategorie'] = data['Kategorie'].astype('category')\n",
    "\n",
    "#     # Vorhersagen durchf√ºhren\n",
    "#     predictions = loaded_model.predict(data)\n",
    "#     print(predictions)  # Ergebnisse anzeigen\n",
    "    \n",
    "# else:\n",
    "#     print(\"Das Modell konnte nicht geladen werden.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.tree import DecisionTreeRegressor  # Verwende DecisionTreeRegressor\n",
    "# from sklearn2pmml.pipeline import PMMLPipeline\n",
    "# from sklearn2pmml import sklearn2pmml\n",
    "# from jpmml_evaluator import make_evaluator\n",
    "\n",
    "# # PMML-Dateipfad und CSV-Dateipfad\n",
    "# pmml_file_path = '../models/analyzed_model.pmml'\n",
    "# csv_file_path = '../models/generated_data.csv'\n",
    "\n",
    "# # Schritt 1: Modell erstellen, trainieren und als PMML speichern\n",
    "# def train_and_save_model():\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "#     X = data.drop(columns=['Zielwert'])  # Ersetze 'Zielwert' mit dem tats√§chlichen Zielnamen\n",
    "#     y = data['Zielwert']  # Ersetze 'Zielwert' mit dem tats√§chlichen Zielnamen\n",
    "\n",
    "#     # Umwandeln der kategorischen Variablen in Dummy-Variablen\n",
    "#     X = pd.get_dummies(X)\n",
    "\n",
    "#     # Pipeline erstellen und trainieren\n",
    "#     pipeline = PMMLPipeline([\n",
    "#         (\"regressor\", DecisionTreeRegressor())  # Verwende DecisionTreeRegressor\n",
    "#     ])\n",
    "#     pipeline.fit(X, y)\n",
    "\n",
    "#     # Modell in PMML-Datei speichern\n",
    "#     sklearn2pmml(pipeline, pmml_file_path, with_repr=True)\n",
    "#     print(f\"Modell erfolgreich gespeichert als {pmml_file_path}.\")\n",
    "\n",
    "# # Schritt 2: Modell laden\n",
    "# def load_model(file_path):\n",
    "#     try:\n",
    "#         evaluator = make_evaluator(file_path)\n",
    "#         evaluator.verify()  # √úberpr√ºfen des Modells\n",
    "#         print(\"Modell erfolgreich geladen mit jpmml-evaluator.\")\n",
    "#         return evaluator\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden des PMML-Modells mit jpmml-evaluator: {e}\")\n",
    "#     return None\n",
    "\n",
    "# # Schritt 3: Modell verwenden, um Vorhersagen zu machen\n",
    "# def make_predictions(evaluator):\n",
    "#     data = pd.read_csv(csv_file_path)\n",
    "#     # Umwandeln der kategorischen Variablen in Dummy-Variablen\n",
    "#     data = pd.get_dummies(data)\n",
    "\n",
    "#     # Vorhersagen durchf√ºhren\n",
    "#     predictions = evaluator.evaluate(data.to_dict(orient='records'))  # Daten ins Dictionary umwandeln\n",
    "\n",
    "#     # Die Ergebnisse hier direkt verwenden\n",
    "#     print(\"Vorhersagen:\", predictions)  # Vorhersagen ausgeben\n",
    "\n",
    "# # Hauptlogik\n",
    "# if __name__ == \"__main__\":\n",
    "#     train_and_save_model()  # Trainiere und speichere das Modell\n",
    "#     loaded_model = load_model(pmml_file_path)  # Lade das Modell\n",
    "\n",
    "#     if loaded_model is not None:\n",
    "#         make_predictions(loaded_model)  # Mache Vorhersagen\n",
    "#     else:\n",
    "#         print(\"Das Modell konnte nicht geladen werden.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from jpmml_evaluator import make_evaluator\n",
    "# from xgrove import grove  # Importiere die Grove-Klasse aus dem xgrove Paket\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Setze den Pfad f√ºr Graphviz\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "\n",
    "# def debug_model_loading(pmml_file_path):\n",
    "#     \"\"\"Versucht, das PMML-Modell zu laden und zu validieren.\"\"\"\n",
    "#     try:\n",
    "#         evaluator = make_evaluator(pmml_file_path)\n",
    "#         evaluator.verify()\n",
    "#         print(\"PMML-Modell erfolgreich geladen und verifiziert.\")\n",
    "#         return evaluator\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden des PMML-Modells: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def debug_data_loading(csv_file_path):\n",
    "#     \"\"\"L√§dt die CSV-Daten und gibt eine Warnung, falls NaN-Werte vorhanden sind.\"\"\"\n",
    "#     try:\n",
    "#         data = pd.read_csv(csv_file_path)\n",
    "#         print(f\"Daten erfolgreich geladen: {data.head()}\")\n",
    "        \n",
    "#         # √úberpr√ºfen auf NaN-Werte und leere Strings\n",
    "#         print(f\"NaN-Werte in den Daten: {data.isna().sum()}\")\n",
    "#         print(f\"Leere Strings in den Daten: {(data == '').sum()}\")\n",
    "        \n",
    "#         # Entferne NaN-Werte\n",
    "#         if data.isna().sum().sum() > 0:\n",
    "#             print(\"Warnung: Es gibt NaN-Werte in den Eingabedaten. Diese werden entfernt.\")\n",
    "#             data = data.dropna()\n",
    "        \n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden der CSV-Datei: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def preprocess_data(data):\n",
    "#     \"\"\"Bereitet die Eingabedaten vor, indem sie skaliert werden, wenn n√∂tig.\"\"\"\n",
    "#     # √úberpr√ºfen auf NaN-Werte nach Entfernen\n",
    "#     print(f\"Datenform nach NaN-Entfernung: {data.shape}\")\n",
    "\n",
    "#     # Skalierung der Daten, falls notwendig\n",
    "#     scaler = StandardScaler()\n",
    "#     data_scaled = data.copy()\n",
    "#     data_scaled['x'] = scaler.fit_transform(data[['x']])\n",
    "\n",
    "#     return data_scaled\n",
    "\n",
    "# def load_and_evaluate_model(pmml_file_path, csv_file_path):\n",
    "#     \"\"\"L√§dt das PMML-Modell und erstellt ein Surrogat-Modell mit xgrove.\"\"\"\n",
    "    \n",
    "#     # 1. Lade die Trainingsdaten\n",
    "#     data = debug_data_loading(csv_file_path)\n",
    "#     if data is None:\n",
    "#         return\n",
    "\n",
    "#     # 2. Preprocessiere die Daten\n",
    "#     data = preprocess_data(data)\n",
    "\n",
    "#     # 3. Lade das PMML-Modell\n",
    "#     evaluator = debug_model_loading(pmml_file_path)\n",
    "#     if evaluator is None:\n",
    "#         return\n",
    "\n",
    "#     # 4. Generiere Surrogat-Zielwerte f√ºr die Daten\n",
    "#     surrogate_targets = []\n",
    "#     for i, row in data.iterrows():\n",
    "#         input_data = row.to_dict()  # Erstelle ein Dictionary f√ºr eine Zeile\n",
    "#         prediction = evaluator.evaluate(input_data)  # Einzeldatensatz bewerten\n",
    "#         surrogate_targets.append(prediction.get('Predicted_y', None))  # Nutze den R√ºckgabeschl√ºssel des Modells\n",
    "#         if i % 10 == 0:  # Debugging: Zeige alle 10 Zeilen\n",
    "#             print(f\"Verarbeite Zeile {i+1}/{len(data)}\")\n",
    "\n",
    "#     # 5. √úberpr√ºfe auf NaN-Werte in den Surrogat-Zielwerten\n",
    "#     print(\"√úberpr√ºfe auf NaN-Werte in den Surrogat-Zielwerten...\")\n",
    "#     surrogate_targets = [val for val in surrogate_targets if val is not None]  # Entferne NaN-Werte\n",
    "#     print(f\"Anzahl der g√ºltigen Surrogat-Zielwerte: {len(surrogate_targets)}\")\n",
    "\n",
    "#     # Wenn nach der Bereinigung keine Surrogat-Zielwerte √ºbrig sind, einen Fehler werfen\n",
    "#     if not surrogate_targets:\n",
    "#         raise ValueError(\"Fehler beim Erstellen der Surrogat-Zielwerte: Keine g√ºltigen Zielwerte vorhanden.\")\n",
    "    \n",
    "#     # Surrogat-Targets in den DataFrame aufnehmen\n",
    "#     data['surrogatetarget'] = surrogate_targets\n",
    "#     print(f\"Surrogat-Zielwerte wurden erfolgreich zum Datensatz hinzugef√ºgt. Datenform: {data.shape}\")\n",
    "\n",
    "#     # 6. Instanziiere die Grove-Klasse mit Surrogat-Targets und dem Modell\n",
    "#     grove_model = grove(model=evaluator, data=data, trained=True)\n",
    "    \n",
    "#     # Berechnung des Surrogat-Modells durchf√ºhren\n",
    "#     grove_model.calculateGrove()\n",
    "\n",
    "#     print(\"Berechnungen abgeschlossen.\")\n",
    "#     print(grove_model.get_result())\n",
    "\n",
    "#     # 7. Zus√§tzliche Modellattribute anzeigen (falls vorhanden)\n",
    "#     model_classes = evaluator.getModelClasses()  # Modellklassen, falls definiert\n",
    "#     print(f\"Model Klassen: {model_classes}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Definiere die Datei- und CSV-Pfade\n",
    "#     pmml_file_path = '../models/linear_model.pmml'\n",
    "#     csv_file_path = '../models/generated_data.csv'\n",
    "\n",
    "#     # F√ºhre das Modell aus\n",
    "#     load_and_evaluate_model(pmml_file_path, csv_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pypmml import Model\n",
    "\n",
    "# # Lade das PMML-Modell\n",
    "# loaded_model = Model.load(\"random_forest_model.pmml\")\n",
    "\n",
    "# # Beispiel f√ºr eine Vorhersage\n",
    "# # Erstelle Beispiel-Daten als DataFrame\n",
    "# import pandas as pd\n",
    "# sample_data = pd.DataFrame({\n",
    "#     \"Sepal.Width\": [3.5],\n",
    "#     \"Petal.Length\": [1.4],\n",
    "#     \"Petal.Width\": [0.2],\n",
    "#     \"Species\": [\"setosa\"]\n",
    "# })\n",
    "\n",
    "# # Vorhersage\n",
    "# predictions = loaded_model.predict(sample_data)\n",
    "# print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# data = pd.DataFrame({'x': [1, 2, 3], 'y': [4, 5, 6]})\n",
    "# print(data.isna().sum())  # Zeigt dir die Anzahl der fehlenden Werte\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lxml import etree\n",
    "\n",
    "# # Funktion zur Vorhersage basierend auf der Baumstruktur aus der XML-Datei\n",
    "# def predict_random_forest_from_xml(x_input, xml_tree):\n",
    "#     \"\"\"Trifft Vorhersage basierend auf einem Random Forest-Modell aus einer XML-Datei\"\"\"\n",
    "#     # Extrahiere alle B√§ume (falls vorhanden)\n",
    "#     models = xml_tree.findall(\".//TreeModel\", namespaces=namespaces)\n",
    "\n",
    "#     # Liste zur Speicherung der Vorhersagen f√ºr jeden Baum\n",
    "#     predictions = []\n",
    "    \n",
    "#     for model in models:\n",
    "#         try:\n",
    "#             # Durchlaufe die Baumstruktur des aktuellen Baums\n",
    "#             prediction = traverse_tree_for_prediction(model, x_input)\n",
    "#             predictions.append(prediction)\n",
    "#         except Exception as e:\n",
    "#             print(f\"Fehler beim Durchlaufen des Baums: {e}\")\n",
    "\n",
    "#     # Debug-Ausgabe der Vorhersagen\n",
    "#     print(f\"Vorhersagen von allen B√§umen: {predictions}\")\n",
    "    \n",
    "#     # Durchschnitt der Vorhersagen (f√ºr Regression) oder Mehrheitsvotum (f√ºr Klassifikation)\n",
    "#     if len(predictions) > 0:\n",
    "#         if len(set(predictions)) == 1:\n",
    "#             return predictions[0]  # Wenn alle B√§ume dasselbe vorhersagen, gebe das Ergebnis zur√ºck\n",
    "#         else:\n",
    "#             return max(set(predictions), key=predictions.count)  # Mehrheitsvotum f√ºr Klassifikation\n",
    "#     else:\n",
    "#         raise ValueError(\"Keine Vorhersagen von den B√§umen erhalten.\")\n",
    "\n",
    "# def traverse_tree_for_prediction(tree_model, x_input):\n",
    "#     \"\"\"Durchlaufe einen einzelnen Entscheidungsbaum und triff Vorhersage\"\"\"\n",
    "#     # Suche nach den Knoten des Entscheidungsbaums\n",
    "#     nodes = tree_model.findall(\".//Node\", namespaces=namespaces)\n",
    "    \n",
    "#     # Wenn keine Knoten vorhanden sind, dann gibt es ein Problem mit der Baumstruktur\n",
    "#     if not nodes:\n",
    "#         raise ValueError(\"Der Entscheidungsbaum enth√§lt keine Knoten.\")\n",
    "    \n",
    "#     # Der erste Knoten ist immer die Wurzel\n",
    "#     current_node = nodes[0]\n",
    "    \n",
    "#     # Durchlaufe die Baumstruktur und gebe alle Knoten aus, um den Baum zu analysieren\n",
    "#     print(\"Baumstruktur:\")\n",
    "#     for node in nodes:\n",
    "#         print(node.attrib)\n",
    "    \n",
    "#     while True:\n",
    "#         # Hole die Bedingungen des aktuellen Knotens (if-Bedingung)\n",
    "#         if_condition = current_node.find(\".//True//SimplePredicate\", namespaces=namespaces)\n",
    "        \n",
    "#         if if_condition is not None:\n",
    "#             # Extrahiere die Bedingung und den Wert\n",
    "#             field = if_condition.attrib['field']\n",
    "#             value = float(if_condition.attrib['value'])\n",
    "            \n",
    "#             # Bestimme den Zweig des Baumes basierend auf der Bedingung\n",
    "#             if x_input <= value:\n",
    "#                 next_node_id = current_node.attrib['trueBranch']\n",
    "#             else:\n",
    "#                 next_node_id = current_node.attrib['falseBranch']\n",
    "#         else:\n",
    "#             # Wenn kein 'True'-Element gefunden wird, ist dies ein Blattknoten (Vorhersage)\n",
    "#             print(\"Blattknoten gefunden:\", current_node.attrib)  # Debug: Ausgabe der Attribute des Blattknotens\n",
    "            \n",
    "#             # Untersuche die Attribute des Blattknotens, um den Vorhersagewert zu finden\n",
    "#             if 'score' in current_node.attrib:\n",
    "#                 return int(current_node.attrib['score'])  # Verwende 'score' als Vorhersage (0 oder 1)\n",
    "#             else:\n",
    "#                 # Dies ist der Fall, wenn der Blattknoten keine Vorhersage enth√§lt\n",
    "#                 raise ValueError(f\"Unklarer Blattknoten gefunden ohne Vorhersage-Attribut. Knoten: {current_node.attrib}\")\n",
    "        \n",
    "#         # Finde den n√§chsten Knoten\n",
    "#         next_node = next((node for node in nodes if node.attrib['id'] == next_node_id), None)\n",
    "        \n",
    "#         if next_node is None:\n",
    "#             raise ValueError(f\"Fehler: Der n√§chste Knoten (ID: {next_node_id}) konnte nicht gefunden werden.\")\n",
    "        \n",
    "#         current_node = next_node\n",
    "\n",
    "# # Lade die XML-Datei (Aktueller Pfad zu deiner Datei)\n",
    "# xml_file_path = \"../models/random_forest_model_pmml.xml\"  # Der tats√§chliche Pfad zur XML-Datei\n",
    "# tree = etree.parse(xml_file_path)\n",
    "# root = tree.getroot()\n",
    "\n",
    "# # Definiere den Namensraum f√ºr XPath\n",
    "# namespaces = {\n",
    "#     'pmml': 'http://www.dmg.org/PMML-4_4'\n",
    "# }\n",
    "\n",
    "# # Extrahiere den Modelltyp\n",
    "# model_type = root.find(\".//pmml:MiningModel\", namespaces=namespaces)\n",
    "# if model_type is not None:\n",
    "#     print(f\"Modelltyp: {model_type.attrib.get('functionName')}\")\n",
    "\n",
    "# # Extrahiere die Eingabefelder aus dem XML\n",
    "# input_fields = root.findall(\".//pmml:DataField\", namespaces=namespaces)\n",
    "# print(\"Eingabefelder:\", [field.attrib.get('name') for field in input_fields])\n",
    "\n",
    "# # Extrahiere die Zielvariable aus dem MiningSchema\n",
    "# target_field = root.xpath(\".//pmml:MiningSchema/pmml:MiningField[@usageType='predicted']\", namespaces=namespaces)\n",
    "# if target_field:\n",
    "#     print(f\"Zielvariable: {target_field[0].attrib.get('name')}\")\n",
    "# else:\n",
    "#     print(\"Zielvariable nicht gefunden.\")\n",
    "\n",
    "# # Beispiel Vorhersage f√ºr eine Eingabe (z.B. x = 30)\n",
    "# x_input = 30\n",
    "# try:\n",
    "#     prediction = predict_random_forest_from_xml(x_input, root)\n",
    "#     print(f\"Vorhersage f√ºr x = {x_input}: Klasse {prediction}\")\n",
    "# except ValueError as e:\n",
    "#     print(f\"Fehler bei der Vorhersage: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lxml import etree\n",
    "\n",
    "# # Funktion zur Vorhersage basierend auf der Baumstruktur aus der PMML-Datei\n",
    "# def predict_random_forest_from_pmml(x_input, pmml_tree):\n",
    "#     \"\"\"Trifft Vorhersage basierend auf einem Random Forest-Modell aus PMML\"\"\"\n",
    "#     # Extrahiere alle B√§ume (falls vorhanden)\n",
    "#     models = pmml_tree.findall(\".//pmml:TreeModel\", namespaces=namespaces)\n",
    "\n",
    "#     # Liste zur Speicherung der Vorhersagen f√ºr jeden Baum\n",
    "#     predictions = []\n",
    "    \n",
    "#     for model in models:\n",
    "#         # Durchlaufe die Baumstruktur des aktuellen Baums\n",
    "#         prediction = traverse_tree_for_prediction(model, x_input)\n",
    "#         predictions.append(prediction)\n",
    "    \n",
    "#     # Durchschnitt der Vorhersagen (f√ºr Regression) oder Mehrheitsvotum (f√ºr Klassifikation)\n",
    "#     if len(set(predictions)) == 1:\n",
    "#         return predictions[0]  # Wenn alle B√§ume dasselbe vorhersagen, gebe das Ergebnis zur√ºck\n",
    "#     else:\n",
    "#         return max(set(predictions), key=predictions.count)  # Mehrheitsvotum f√ºr Klassifikation\n",
    "\n",
    "# def traverse_tree_for_prediction(tree_model, x_input):\n",
    "#     \"\"\"Durchlaufe einen einzelnen Entscheidungsbaum und triff Vorhersage\"\"\"\n",
    "#     # Suche nach den Knoten des Entscheidungsbaums\n",
    "#     nodes = tree_model.findall(\".//pmml:Node\", namespaces=namespaces)\n",
    "    \n",
    "#     # Der erste Knoten ist immer die Wurzel\n",
    "#     current_node = nodes[0]\n",
    "    \n",
    "#     # Durchlaufe die Baumstruktur und gebe alle Knoten aus, um den Baum zu analysieren\n",
    "#     print(\"Baumstruktur:\")\n",
    "#     for node in nodes:\n",
    "#         print(node.attrib)\n",
    "    \n",
    "#     while True:\n",
    "#         # Hole die Bedingungen des aktuellen Knotens (if-Bedingung)\n",
    "#         if_condition = current_node.find(\".//pmml:True/pmml:SimplePredicate\", namespaces=namespaces)\n",
    "        \n",
    "#         if if_condition is not None:\n",
    "#             # Extrahiere die Bedingung und den Wert\n",
    "#             field = if_condition.attrib['field']\n",
    "#             value = float(if_condition.attrib['value'])\n",
    "            \n",
    "#             # Bestimme den Zweig des Baumes basierend auf der Bedingung\n",
    "#             if x_input <= value:\n",
    "#                 next_node_id = current_node.attrib['trueBranch']\n",
    "#             else:\n",
    "#                 next_node_id = current_node.attrib['falseBranch']\n",
    "#         else:\n",
    "#             # Wenn kein 'True'-Element gefunden wird, ist dies ein Blattknoten (Vorhersage)\n",
    "#             print(\"Blattknoten gefunden:\", current_node.attrib)  # Debug: Ausgabe der Attribute des Blattknotens\n",
    "            \n",
    "#             # Untersuche die Attribute des Blattknotens, um den Vorhersagewert zu finden\n",
    "#             score = current_node.attrib.get('score', None)\n",
    "            \n",
    "#             if score is not None:\n",
    "#                 return int(score)  # Verwende 'score' als Vorhersage (0 oder 1)\n",
    "#             else:\n",
    "#                 # Falls der Blattknoten keinen 'score' hat, gehe davon aus, dass er ein innerer Knoten ist\n",
    "#                 print(f\"Blattknoten ohne 'score' gefunden (ID: {current_node.attrib['id']}). Weiter mit n√§chstem Knoten.\")\n",
    "#                 # Gehe zur n√§chsten Node, falls keine Vorhersage im aktuellen Knoten\n",
    "#                 next_node_id = current_node.attrib.get('trueBranch', None) or current_node.attrib.get('falseBranch', None)\n",
    "#                 if next_node_id:\n",
    "#                     # Suche den n√§chsten Knoten\n",
    "#                     current_node = next((node for node in nodes if node.attrib['id'] == next_node_id), None)\n",
    "#                     continue\n",
    "#                 else:\n",
    "#                     raise ValueError(f\"Kein g√ºltiger 'trueBranch' oder 'falseBranch' im Blattknoten gefunden. Knoten: {current_node.attrib}\")\n",
    "\n",
    "#         # Finde den n√§chsten Knoten\n",
    "#         next_node = next((node for node in nodes if node.attrib['id'] == next_node_id), None)\n",
    "        \n",
    "#         if next_node is None:\n",
    "#             raise ValueError(f\"Fehler: Der n√§chste Knoten (ID: {next_node_id}) konnte nicht gefunden werden.\")\n",
    "        \n",
    "#         current_node = next_node\n",
    "\n",
    "# # Lade die PMML-Datei\n",
    "# pmml_file_path = \"models/random_forest_model_pmml.xml\"  # Der tats√§chliche Pfad zur XML-Datei\n",
    "# tree = etree.parse(pmml_file_path)\n",
    "# root = tree.getroot()\n",
    "\n",
    "# # Definiere den Namensraum f√ºr XPath\n",
    "# namespaces = {\n",
    "#     'pmml': 'http://www.dmg.org/PMML-4_4'\n",
    "# }\n",
    "\n",
    "# # Extrahiere den Modelltyp\n",
    "# model_type = root.find(\".//pmml:MiningModel\", namespaces=namespaces)\n",
    "# if model_type is not None:\n",
    "#     print(f\"Modelltyp: {model_type.attrib.get('functionName')}\")\n",
    "\n",
    "# # Extrahiere die Eingabefelder aus dem XML\n",
    "# input_fields = root.findall(\".//pmml:DataField\", namespaces=namespaces)\n",
    "# print(\"Eingabefelder:\", [field.attrib.get('name') for field in input_fields])\n",
    "\n",
    "# # Extrahiere die Zielvariable aus dem MiningSchema\n",
    "# target_field = root.xpath(\".//pmml:MiningSchema/pmml:MiningField[@usageType='predicted']\", namespaces=namespaces)\n",
    "# if target_field:\n",
    "#     print(f\"Zielvariable: {target_field[0].attrib.get('name')}\")\n",
    "# else:\n",
    "#     print(\"Zielvariable nicht gefunden.\")\n",
    "\n",
    "# # Beispiel Vorhersage f√ºr eine Eingabe (z.B. x = 30)\n",
    "# x_input = 30\n",
    "# prediction = predict_random_forest_from_pmml(x_input, root)\n",
    "# print(f\"Vorhersage f√ºr x = {x_input}: Klasse {prediction}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from pypmml import Model  # Verwenden von pypmml\n",
    "\n",
    "# # Definiere den PMML-Dateipfad\n",
    "# pmml_path = \"../models/linear_model.pmml\"\n",
    "\n",
    "# # Lade das trainierte PMML-Modell (aus R gespeichert)\n",
    "# pmml_model = Model.load(pmml_path)  # Laden des trainierten Modells\n",
    "\n",
    "# # Neue Eingabedaten (die f√ºr die Vorhersagen verwendet werden)\n",
    "# input_data = pd.DataFrame({\n",
    "#     'Feature1': [0.5, -1.2, 0.3],\n",
    "#     'Feature2': [1.1, -0.8, 0.2]\n",
    "# })\n",
    "\n",
    "# # Vorhersagen machen\n",
    "# predictions = pmml_model.predict(input_data)\n",
    "\n",
    "# # Zeige die Vorhersagen an\n",
    "# print(f\"Vorhersagen: {predictions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# # Beispiel DataFrame mit zuf√§lligen Werten\n",
    "# np.random.seed(42)\n",
    "# data = {\n",
    "#     'variable': np.random.choice(['Feature1', 'Feature2'], size=100),  # 'Feature1' oder 'Feature2'\n",
    "#     'upper_bound_left': np.random.uniform(-2, 2, size=100).round(2),  # Zuf√§llige Werte f√ºr upper_bound_left\n",
    "#     'levels_left': [None] * 100,  # Alle Werte auf None gesetzt\n",
    "#     'pleft': np.random.uniform(-1, 1, size=100),  # Zuf√§llige Werte f√ºr pleft\n",
    "#     'pright': np.random.uniform(-1, 1, size=100)  # Zuf√§llige Werte f√ºr pright\n",
    "# }\n",
    "\n",
    "# df = pd.DataFrame(data)\n",
    "\n",
    "# # √úberpr√ºfen auf NaN-Werte\n",
    "# print(f\"NaN counts in df before grouping:\\n{df.isna().sum()}\")\n",
    "\n",
    "# # Entfernen von NaN-Werten (falls n√∂tig)\n",
    "# df_cleaned = df.dropna(subset=['variable', 'upper_bound_left', 'pleft', 'pright'])\n",
    "\n",
    "# # Gruppieren nach den Spalten 'variable', 'upper_bound_left' und 'levels_left'\n",
    "# # Dann berechnen wir die Summe von 'pleft' und 'pright' f√ºr jede Gruppe\n",
    "# # Setze 'levels_left' auf einen sinnvollen Standardwert (z. B. \"default\")\n",
    "# df['levels_left'] = df['levels_left'].fillna('default')\n",
    "\n",
    "# # Gruppieren nach 'variable', 'upper_bound_left' und 'levels_left'\n",
    "# df_grouped = df.groupby(['variable', 'upper_bound_left', 'levels_left'], as_index=False).agg({\n",
    "#     'pleft': 'sum',\n",
    "#     'pright': 'sum'\n",
    "# })\n",
    "\n",
    "# # Ergebnis anzeigen\n",
    "# print(df_grouped.head())\n",
    "\n",
    "\n",
    "# # Ergebnis anzeigen\n",
    "# print(df_grouped.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from jpmml_evaluator import make_evaluator\n",
    "# from xgrove import grove\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# # Setze den Pfad f√ºr Graphviz\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'\n",
    "\n",
    "# def debug_model_loading(pmml_file_path):\n",
    "#     \"\"\"Versucht, das PMML-Modell zu laden und zu validieren.\"\"\"\n",
    "#     try:\n",
    "#         evaluator = make_evaluator(pmml_file_path)\n",
    "#         evaluator.verify()\n",
    "#         print(\"PMML-Modell erfolgreich geladen und verifiziert.\")\n",
    "#         return evaluator\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden des PMML-Modells: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def debug_data_loading(csv_file_path):\n",
    "#     \"\"\"L√§dt die CSV-Daten und gibt eine Warnung, falls NaN-Werte vorhanden sind.\"\"\"\n",
    "#     try:\n",
    "#         data = pd.read_csv(csv_file_path)\n",
    "#         print(f\"Daten erfolgreich geladen: {data.head()}\")\n",
    "        \n",
    "#         # √úberpr√ºfen auf NaN-Werte und leere Strings\n",
    "#         print(f\"NaN-Werte in den Daten: {data.isna().sum()}\")\n",
    "#         print(f\"Leere Strings in den Daten: {(data == '').sum()}\")\n",
    "        \n",
    "#         # Entferne NaN-Werte\n",
    "#         if data.isna().sum().sum() > 0:\n",
    "#             print(\"Warnung: Es gibt NaN-Werte in den Eingabedaten. Diese werden entfernt.\")\n",
    "#             data = data.dropna()\n",
    "        \n",
    "#         return data\n",
    "#     except Exception as e:\n",
    "#         print(f\"Fehler beim Laden der CSV-Datei: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def preprocess_data(data):\n",
    "#     \"\"\"Bereitet die Eingabedaten vor, indem sie skaliert werden, wenn n√∂tig.\"\"\"\n",
    "#     print(f\"Datenform nach NaN-Entfernung: {data.shape}\")\n",
    "\n",
    "#     # Skalierung der Daten, falls notwendig\n",
    "#     scaler = StandardScaler()\n",
    "#     data_scaled = data.copy()\n",
    "#     features = data.columns  # Hier wird davon ausgegangen, dass alle Spalten skaliert werden m√ºssen.\n",
    "#     data_scaled[features] = scaler.fit_transform(data[features])\n",
    "\n",
    "#     return data_scaled\n",
    "\n",
    "# def load_and_evaluate_model(pmml_file_path, csv_file_path):\n",
    "#     \"\"\"L√§dt das PMML-Modell und erstellt ein Surrogat-Modell mit xgrove.\"\"\"\n",
    "    \n",
    "#     # 1. Lade die Trainingsdaten\n",
    "#     data = debug_data_loading(csv_file_path)\n",
    "#     if data is None:\n",
    "#         return\n",
    "\n",
    "#     # 2. Preprocessiere die Daten\n",
    "#     data = preprocess_data(data)\n",
    "\n",
    "#     # 3. Lade das PMML-Modell\n",
    "#     evaluator = debug_model_loading(pmml_file_path)\n",
    "#     if evaluator is None:\n",
    "#         return\n",
    "\n",
    "#     # 4. Generiere Surrogat-Zielwerte f√ºr die Daten\n",
    "#     surrogate_targets = []\n",
    "#     for i, row in data.iterrows():\n",
    "#         input_data = row.to_dict()  # Erstelle ein Dictionary f√ºr eine Zeile\n",
    "#         prediction = evaluator.evaluate(input_data)  # Einzeldatensatz bewerten\n",
    "#         surrogate_targets.append(prediction.get('Predicted_y', None))  # Nutze den R√ºckgabeschl√ºssel des Modells\n",
    "#         if i % 10 == 0:  # Debugging: Zeige alle 10 Zeilen\n",
    "#             print(f\"Verarbeite Zeile {i+1}/{len(data)}\")\n",
    "\n",
    "#     # 5. √úberpr√ºfe auf NaN-Werte in den Surrogat-Zielwerten\n",
    "#     print(\"√úberpr√ºfe auf NaN-Werte in den Surrogat-Zielwerten...\")\n",
    "#     surrogate_targets = [val for val in surrogate_targets if val is not None]  # Entferne NaN-Werte\n",
    "#     print(f\"Anzahl der g√ºltigen Surrogat-Zielwerte: {len(surrogate_targets)}\")\n",
    "\n",
    "#     # Wenn nach der Bereinigung keine Surrogat-Zielwerte √ºbrig sind, einen Fehler werfen\n",
    "#     if not surrogate_targets:\n",
    "#         raise ValueError(\"Fehler beim Erstellen der Surrogat-Zielwerte: Keine g√ºltigen Zielwerte vorhanden.\")\n",
    "    \n",
    "#     # Surrogat-Targets in den DataFrame aufnehmen\n",
    "#     data['surrogatetarget'] = surrogate_targets\n",
    "#     print(f\"Surrogat-Zielwerte wurden erfolgreich zum Datensatz hinzugef√ºgt. Datenform: {data.shape}\")\n",
    "\n",
    "#     # 6. Instanziiere die Grove-Klasse mit Surrogat-Targets und dem Modell\n",
    "#     grove_model = grove(model=evaluator, data=data, trained=True)\n",
    "    \n",
    "#     # Berechnung des Surrogat-Modells durchf√ºhren\n",
    "#     grove_model.calculateGrove()\n",
    "\n",
    "#     print(\"Berechnungen abgeschlossen.\")\n",
    "#     print(grove_model.get_result())\n",
    "\n",
    "#     # 7. Zus√§tzliche Modellattribute anzeigen (falls vorhanden)\n",
    "#     model_classes = evaluator.getModelClasses()  # Modellklassen, falls definiert\n",
    "#     print(f\"Model Klassen: {model_classes}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # Definiere die Datei- und CSV-Pfade\n",
    "#     pmml_file_path = '../models/linear_model.pmml'\n",
    "#     csv_file_path = '../models/generated_data.csv'\n",
    "\n",
    "#     # F√ºhre das Modell aus\n",
    "#     load_and_evaluate_model(pmml_file_path, csv_file_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
